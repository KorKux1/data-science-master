{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Taller 2 - Fundamentos de Análitica: Object localization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Integrantes: \n",
    "- Cristhian Castillo.\n",
    "- Kevin Zarama.\n",
    "\n",
    "**Objetivo**: El objetivo de este notebook es obtener un modelo que permita localizar un número del 0 al 9, dentro de una imagen y predecir de que número se trata. Las imagenes contienen un solo número."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Tabla de Contenido<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Información-del-taller\" data-toc-modified-id=\"Información-del-taller-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Información del taller</a></span><ul class=\"toc-item\"><li><span><a href=\"#Puntos-a-Evaluar\" data-toc-modified-id=\"Puntos-a-Evaluar-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Puntos a Evaluar</a></span></li><li><span><a href=\"#Submission-Format\" data-toc-modified-id=\"Submission-Format-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Submission Format</a></span></li></ul></li><li><span><a href=\"#Packages-and-Functions\" data-toc-modified-id=\"Packages-and-Functions-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Packages and Functions</a></span><ul class=\"toc-item\"><li><span><a href=\"#Packages\" data-toc-modified-id=\"Packages-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Packages</a></span></li><li><span><a href=\"#Functions\" data-toc-modified-id=\"Functions-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Functions</a></span></li></ul></li><li><span><a href=\"#Project-Config\" data-toc-modified-id=\"Project-Config-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Project Config</a></span><ul class=\"toc-item\"><li><span><a href=\"#Configuring-GPU-or-CPU-usage-based-on-available-resources\" data-toc-modified-id=\"Configuring-GPU-or-CPU-usage-based-on-available-resources-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Configuring GPU or CPU usage based on available resources</a></span></li><li><span><a href=\"#Seed-Config\" data-toc-modified-id=\"Seed-Config-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Seed Config</a></span></li></ul></li><li><span><a href=\"#Creating-Dataset-Structure\" data-toc-modified-id=\"Creating-Dataset-Structure-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Creating Dataset Structure</a></span><ul class=\"toc-item\"><li><span><a href=\"#Load-dataset\" data-toc-modified-id=\"Load-dataset-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>Load dataset</a></span></li><li><span><a href=\"#Data-Overview\" data-toc-modified-id=\"Data-Overview-4.2\"><span class=\"toc-item-num\">4.2&nbsp;&nbsp;</span>Data Overview</a></span></li><li><span><a href=\"#Train-test-split\" data-toc-modified-id=\"Train-test-split-4.3\"><span class=\"toc-item-num\">4.3&nbsp;&nbsp;</span>Train test split</a></span></li><li><span><a href=\"#Constantes-del-proyecto\" data-toc-modified-id=\"Constantes-del-proyecto-4.4\"><span class=\"toc-item-num\">4.4&nbsp;&nbsp;</span>Constantes del proyecto</a></span></li><li><span><a href=\"#Manejo-de-las-imagenes-(Clases-y-Bounding-Boxes)\" data-toc-modified-id=\"Manejo-de-las-imagenes-(Clases-y-Bounding-Boxes)-4.5\"><span class=\"toc-item-num\">4.5&nbsp;&nbsp;</span>Manejo de las imagenes (Clases y Bounding Boxes)</a></span></li><li><span><a href=\"#Image-Normalization\" data-toc-modified-id=\"Image-Normalization-4.6\"><span class=\"toc-item-num\">4.6&nbsp;&nbsp;</span>Image Normalization</a></span></li><li><span><a href=\"#Image-To-Tensor\" data-toc-modified-id=\"Image-To-Tensor-4.7\"><span class=\"toc-item-num\">4.7&nbsp;&nbsp;</span>Image To Tensor</a></span></li></ul></li><li><span><a href=\"#Feature-Extractor-Model-(Backbone)\" data-toc-modified-id=\"Feature-Extractor-Model-(Backbone)-5\"><span class=\"toc-item-num\">5&nbsp;&nbsp;</span>Feature Extractor Model (Backbone)</a></span></li><li><span><a href=\"#Object-classification-Model\" data-toc-modified-id=\"Object-classification-Model-6\"><span class=\"toc-item-num\">6&nbsp;&nbsp;</span>Object classification Model</a></span></li><li><span><a href=\"#Bounding-box-prediction-Model\" data-toc-modified-id=\"Bounding-box-prediction-Model-7\"><span class=\"toc-item-num\">7&nbsp;&nbsp;</span>Bounding box prediction Model</a></span></li><li><span><a href=\"#Model-for-classification-and-objects-location\" data-toc-modified-id=\"Model-for-classification-and-objects-location-8\"><span class=\"toc-item-num\">8&nbsp;&nbsp;</span>Model for classification and objects location</a></span></li><li><span><a href=\"#Methods-for-training-the-model\" data-toc-modified-id=\"Methods-for-training-the-model-9\"><span class=\"toc-item-num\">9&nbsp;&nbsp;</span>Methods for training the model</a></span><ul class=\"toc-item\"><li><span><a href=\"#Loss-Function\" data-toc-modified-id=\"Loss-Function-9.1\"><span class=\"toc-item-num\">9.1&nbsp;&nbsp;</span>Loss Function</a></span></li><li><span><a href=\"#Metrics\" data-toc-modified-id=\"Metrics-9.2\"><span class=\"toc-item-num\">9.2&nbsp;&nbsp;</span>Metrics</a></span><ul class=\"toc-item\"><li><span><a href=\"#Accurancy-Metrics\" data-toc-modified-id=\"Accurancy-Metrics-9.2.1\"><span class=\"toc-item-num\">9.2.1&nbsp;&nbsp;</span>Accurancy Metrics</a></span></li><li><span><a href=\"#Intersection-over-Union-(IoU)-Metric\" data-toc-modified-id=\"Intersection-over-Union-(IoU)-Metric-9.2.2\"><span class=\"toc-item-num\">9.2.2&nbsp;&nbsp;</span>Intersection over Union (IoU) Metric</a></span></li></ul></li><li><span><a href=\"#Callbacks\" data-toc-modified-id=\"Callbacks-9.3\"><span class=\"toc-item-num\">9.3&nbsp;&nbsp;</span>Callbacks</a></span></li><li><span><a href=\"#Optimizer\" data-toc-modified-id=\"Optimizer-9.4\"><span class=\"toc-item-num\">9.4&nbsp;&nbsp;</span>Optimizer</a></span></li></ul></li><li><span><a href=\"#Base-Model\" data-toc-modified-id=\"Base-Model-10\"><span class=\"toc-item-num\">10&nbsp;&nbsp;</span>Base Model</a></span></li><li><span><a href=\"#Predictions-Visualization\" data-toc-modified-id=\"Predictions-Visualization-11\"><span class=\"toc-item-num\">11&nbsp;&nbsp;</span>Predictions Visualization</a></span></li><li><span><a href=\"#Transfer-Learning\" data-toc-modified-id=\"Transfer-Learning-12\"><span class=\"toc-item-num\">12&nbsp;&nbsp;</span>Transfer Learning</a></span><ul class=\"toc-item\"><li><span><a href=\"#Image-normalization-transforms\" data-toc-modified-id=\"Image-normalization-transforms-12.1\"><span class=\"toc-item-num\">12.1&nbsp;&nbsp;</span>Image normalization transforms</a></span></li><li><span><a href=\"#ResNet152\" data-toc-modified-id=\"ResNet152-12.2\"><span class=\"toc-item-num\">12.2&nbsp;&nbsp;</span>ResNet152</a></span></li><li><span><a href=\"#Model-for-classification-and-regression-using-transfer-learning\" data-toc-modified-id=\"Model-for-classification-and-regression-using-transfer-learning-12.3\"><span class=\"toc-item-num\">12.3&nbsp;&nbsp;</span>Model for classification and regression using transfer learning</a></span></li><li><span><a href=\"#Train-Model\" data-toc-modified-id=\"Train-Model-12.4\"><span class=\"toc-item-num\">12.4&nbsp;&nbsp;</span>Train Model</a></span></li><li><span><a href=\"#AlexNet\" data-toc-modified-id=\"AlexNet-12.5\"><span class=\"toc-item-num\">12.5&nbsp;&nbsp;</span>AlexNet</a></span></li><li><span><a href=\"#Model-for-classification-and-regression-using-transfer-learning\" data-toc-modified-id=\"Model-for-classification-and-regression-using-transfer-learning-12.6\"><span class=\"toc-item-num\">12.6&nbsp;&nbsp;</span>Model for classification and regression using transfer learning</a></span></li><li><span><a href=\"#Train-Model\" data-toc-modified-id=\"Train-Model-12.7\"><span class=\"toc-item-num\">12.7&nbsp;&nbsp;</span>Train Model</a></span></li></ul></li><li><span><a href=\"#Data-Augmentation\" data-toc-modified-id=\"Data-Augmentation-13\"><span class=\"toc-item-num\">13&nbsp;&nbsp;</span>Data Augmentation</a></span><ul class=\"toc-item\"><li><span><a href=\"#AlbumentationsWrapper\" data-toc-modified-id=\"AlbumentationsWrapper-13.1\"><span class=\"toc-item-num\">13.1&nbsp;&nbsp;</span>AlbumentationsWrapper</a></span></li><li><span><a href=\"#Train-data-augmentation\" data-toc-modified-id=\"Train-data-augmentation-13.2\"><span class=\"toc-item-num\">13.2&nbsp;&nbsp;</span>Train data augmentation</a></span></li></ul></li><li><span><a href=\"#Train-Models-with-Data-augmentation\" data-toc-modified-id=\"Train-Models-with-Data-augmentation-14\"><span class=\"toc-item-num\">14&nbsp;&nbsp;</span>Train Models with Data augmentation</a></span></li><li><span><a href=\"#Image-To-Tensor\" data-toc-modified-id=\"Image-To-Tensor-15\"><span class=\"toc-item-num\">15&nbsp;&nbsp;</span>Image To Tensor</a></span><ul class=\"toc-item\"><li><span><a href=\"#Image-normalization\" data-toc-modified-id=\"Image-normalization-15.1\"><span class=\"toc-item-num\">15.1&nbsp;&nbsp;</span>Image normalization</a></span></li><li><span><a href=\"#Data-augmentations\" data-toc-modified-id=\"Data-augmentations-15.2\"><span class=\"toc-item-num\">15.2&nbsp;&nbsp;</span>Data augmentations</a></span></li></ul></li><li><span><a href=\"#Model-for-classification-and-objects-location\" data-toc-modified-id=\"Model-for-classification-and-objects-location-16\"><span class=\"toc-item-num\">16&nbsp;&nbsp;</span>Model for classification and objects location</a></span></li><li><span><a href=\"#Metrics\" data-toc-modified-id=\"Metrics-17\"><span class=\"toc-item-num\">17&nbsp;&nbsp;</span>Metrics</a></span></li><li><span><a href=\"#Callbacks\" data-toc-modified-id=\"Callbacks-18\"><span class=\"toc-item-num\">18&nbsp;&nbsp;</span>Callbacks</a></span></li><li><span><a href=\"#Training-loop\" data-toc-modified-id=\"Training-loop-19\"><span class=\"toc-item-num\">19&nbsp;&nbsp;</span>Training loop</a></span></li><li><span><a href=\"#Run\" data-toc-modified-id=\"Run-20\"><span class=\"toc-item-num\">20&nbsp;&nbsp;</span>Run</a></span></li><li><span><a href=\"#Predictions-visualization\" data-toc-modified-id=\"Predictions-visualization-21\"><span class=\"toc-item-num\">21&nbsp;&nbsp;</span>Predictions visualization</a></span></li><li><span><a href=\"#Save-Model\" data-toc-modified-id=\"Save-Model-22\"><span class=\"toc-item-num\">22&nbsp;&nbsp;</span>Save Model</a></span></li><li><span><a href=\"#Submission\" data-toc-modified-id=\"Submission-23\"><span class=\"toc-item-num\">23&nbsp;&nbsp;</span>Submission</a></span></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Información del taller"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Puntos a Evaluar\n",
    "- **Custom CNN**: Create a custom Convolutional Neural Network model as a backbone (feature extractor) and train it from scratch (1.5 points)\n",
    "\n",
    "- **Bounding box prediction**: Implement a regression head that is fed with the features extracted from the convolutional backbone. (1 point)\n",
    "\n",
    "- **Object classification**: Implement a classification head that is fed with the features extracted from the convolutional backbone (1 point)\n",
    "\n",
    "- **Transfer learning**: Use two pretrained models as backbones and connect the previously created classification and regression heads in order to receive inputs from them. (1 point)\n",
    "\n",
    "- **Data augmentation**: Compare the use of different data augmentation techniques in order to see their impact in the performance of both tasks (classification and regression) (0.5 points)\n",
    "\n",
    "Be aware that you must follow a correct evaluation protocol in order to avoid data leakage from the test sets on the data processing steps. Mistakes will be punished (-0.5 points each).\n",
    "\n",
    "The evaluation metric for this competition is the dice coefficient for the bounding box regression task and accuracy for the object classification task.\n",
    "\n",
    "### Submission Format\n",
    "For every set in the dataset, submission files should contain the following columns:\n",
    "\n",
    "filename, the filename of the image\n",
    "class, the predicted class"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Packages and Functions"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-10T21:22:00.035334Z",
     "start_time": "2022-12-10T21:21:57.589116Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# General\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import sys\n",
    "import matplotlib.pyplot as plt\n",
    "import copy\n",
    "import typing as ty\n",
    "from multiprocessing import cpu_count\n",
    "import math\n",
    "import time\n",
    "\n",
    "\n",
    "# Sklearn\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "# Images\n",
    "from skimage import io\n",
    "import albumentations as A\n",
    "import torchvision\n",
    "import cv2\n",
    "from torchvision import ops, transforms\n",
    "from torchvision.models import resnet152, alexnet\n",
    "\n",
    "\n",
    "\n",
    "# Neural Networks\n",
    "import torch\n",
    "from torchsummary import summary\n",
    "from torch import nn\n",
    "from torchvision.transforms.functional import resize\n",
    "from torch import Tensor\n",
    "import torch.nn.functional as F\n",
    "from torch.optim import Optimizer\n",
    "from torch.utils.data import DataLoader\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.utils.data import SubsetRandomSampler"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-10T21:22:00.042697Z",
     "start_time": "2022-12-10T21:22:00.039456Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<matplotlib.pyplot._IonContext at 0x7f9208921700>"
      ]
     },
     "execution_count": 2,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "plt.ion()   # matplotlib interactive mode"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-10T21:22:00.049235Z",
     "start_time": "2022-12-10T21:22:00.047396Z"
    }
   },
   "outputs": [],
   "source": [
    "sys.path.append(\"custom_utils/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-10T21:22:00.063220Z",
     "start_time": "2022-12-10T21:22:00.053247Z"
    }
   },
   "outputs": [],
   "source": [
    "from bounding_boxes import MNISTDataset, normalize_bbox, draw_predictions, draw_bbox\n",
    "from models import FeatureExtractor, ClassificationHead, RegressionHead, train\n",
    "from constants import load_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-10T21:22:00.071582Z",
     "start_time": "2022-12-10T21:22:00.067532Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'constants' from '/workspace/study/datascience_master/Analytics Fundamentals 2/challenges/second_challange/constants.py'>"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "\n",
    "importlib.reload(sys.modules[\"bounding_boxes\"])\n",
    "importlib.reload(sys.modules[\"models\"])\n",
    "importlib.reload(sys.modules[\"constants\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Project Config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Configuring GPU or CPU usage based on available resources"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usaremos GPU en caso de que esté disponible, sino se usará la GPU para el procesamiento."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-10T21:22:00.176912Z",
     "start_time": "2022-12-10T21:22:00.075583Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Using {device}')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Probamos que funcione correctamente el uso del device."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-10T21:22:03.716243Z",
     "start_time": "2022-12-10T21:22:00.181071Z"
    }
   },
   "outputs": [],
   "source": [
    "test = torch.ones((100, 100)).to(device)\n",
    "del test\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Seed Config"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos una semilla para obtener los mismos resultados siempre que el notebook sea corrido. Esto nos ayudará a darnos una idea más clara de como el modelo va mejorando realmente."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-10T21:22:03.723501Z",
     "start_time": "2022-12-10T21:22:03.721118Z"
    }
   },
   "outputs": [],
   "source": [
    "seed = 42\n",
    "\n",
    "torch.backends.cudnn.enabled = True\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "if(device == 'cuda'):\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Creating Dataset Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-10T21:22:03.736577Z",
     "start_time": "2022-12-10T21:22:03.727747Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"datasets/train.csv\")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data Overview"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-10T21:22:03.754865Z",
     "start_time": "2022-12-10T21:22:03.746328Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>filename</th>\n",
       "      <th>class</th>\n",
       "      <th>xmin</th>\n",
       "      <th>ymin</th>\n",
       "      <th>xmax</th>\n",
       "      <th>ymax</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>converted_training12629.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0.34</td>\n",
       "      <td>0.28</td>\n",
       "      <td>0.62</td>\n",
       "      <td>0.56</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>converted_training37731.png</td>\n",
       "      <td>7</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.67</td>\n",
       "      <td>0.44</td>\n",
       "      <td>0.95</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>converted_training39992.png</td>\n",
       "      <td>1</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.30</td>\n",
       "      <td>0.75</td>\n",
       "      <td>0.58</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>converted_training8526.png</td>\n",
       "      <td>4</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.16</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.44</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>converted_training8280.png</td>\n",
       "      <td>4</td>\n",
       "      <td>0.17</td>\n",
       "      <td>0.22</td>\n",
       "      <td>0.45</td>\n",
       "      <td>0.50</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7995</th>\n",
       "      <td>converted_training31907.png</td>\n",
       "      <td>9</td>\n",
       "      <td>0.58</td>\n",
       "      <td>0.10</td>\n",
       "      <td>0.86</td>\n",
       "      <td>0.38</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7996</th>\n",
       "      <td>converted_training22702.png</td>\n",
       "      <td>0</td>\n",
       "      <td>0.20</td>\n",
       "      <td>0.54</td>\n",
       "      <td>0.48</td>\n",
       "      <td>0.82</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7997</th>\n",
       "      <td>converted_training24097.png</td>\n",
       "      <td>5</td>\n",
       "      <td>0.07</td>\n",
       "      <td>0.57</td>\n",
       "      <td>0.35</td>\n",
       "      <td>0.85</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7998</th>\n",
       "      <td>converted_training52223.png</td>\n",
       "      <td>9</td>\n",
       "      <td>0.08</td>\n",
       "      <td>0.41</td>\n",
       "      <td>0.36</td>\n",
       "      <td>0.69</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>7999</th>\n",
       "      <td>converted_training20994.png</td>\n",
       "      <td>9</td>\n",
       "      <td>0.19</td>\n",
       "      <td>0.50</td>\n",
       "      <td>0.47</td>\n",
       "      <td>0.78</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>8000 rows × 6 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                         filename  class  xmin  ymin  xmax  ymax\n",
       "0     converted_training12629.png      0  0.34  0.28  0.62  0.56\n",
       "1     converted_training37731.png      7  0.16  0.67  0.44  0.95\n",
       "2     converted_training39992.png      1  0.47  0.30  0.75  0.58\n",
       "3      converted_training8526.png      4  0.17  0.16  0.45  0.44\n",
       "4      converted_training8280.png      4  0.17  0.22  0.45  0.50\n",
       "...                           ...    ...   ...   ...   ...   ...\n",
       "7995  converted_training31907.png      9  0.58  0.10  0.86  0.38\n",
       "7996  converted_training22702.png      0  0.20  0.54  0.48  0.82\n",
       "7997  converted_training24097.png      5  0.07  0.57  0.35  0.85\n",
       "7998  converted_training52223.png      9  0.08  0.41  0.36  0.69\n",
       "7999  converted_training20994.png      9  0.19  0.50  0.47  0.78\n",
       "\n",
       "[8000 rows x 6 columns]"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-10T21:22:03.764744Z",
     "start_time": "2022-12-10T21:22:03.762192Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "Index(['filename', 'class', 'xmin', 'ymin', 'xmax', 'ymax'], dtype='object')"
      ]
     },
     "execution_count": 11,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df.columns"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "El dataset cuenta con 6 columnas:\n",
    "\n",
    "1. **filename**: Nombre del archivo que contiene la imagen del digito.\n",
    "2. **class:**: digito que aparece en la imagen.\n",
    "3. **xmin**: coordenada x del punto más cercano.\n",
    "4. **ymin**: coordenada del punto y más cercano.\n",
    "5. **xmax**: coordenada x del punto más alejado.\n",
    "6. **ymax**: coordenada y del punto más alejado.\n",
    "\n",
    "Con los dos puntos podemos generar el recuadro para encerrar los digitos dentro de un cuadrado."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Renombramos la variable class a class_id que es el nombre que manejaremos a lo largo del proyecto."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-10T21:22:03.774545Z",
     "start_time": "2022-12-10T21:22:03.772494Z"
    }
   },
   "outputs": [],
   "source": [
    "df.rename(columns={\"class\": \"class_id\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-04T20:09:14.418349Z",
     "start_time": "2022-12-04T20:09:14.406390Z"
    }
   },
   "source": [
    "### Train test split"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Separamos el dataset en datos de entrenamiento y prueba. Y estratificamos los datos para que cuenten con una cantidad de clases similar en los conjuntos de datos que obtendremos.\n",
    "\n",
    "Usaremos el 15% como datos de prueba."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-10T21:22:03.787856Z",
     "start_time": "2022-12-10T21:22:03.782899Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(\n",
    "    df, stratify=df['class_id'], test_size=0.15, random_state=seed\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-10T21:22:03.803857Z",
     "start_time": "2022-12-10T21:22:03.801432Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(6800, 6)\n",
      "(1200, 6)\n"
     ]
    }
   ],
   "source": [
    "print(train_df.shape)\n",
    "print(test_df.shape)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Revisamos como quedó la estratificación de los datos de entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-10T21:22:04.729147Z",
     "start_time": "2022-12-10T21:22:04.723903Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    730\n",
       "7    709\n",
       "9    698\n",
       "3    696\n",
       "2    678\n",
       "0    674\n",
       "6    671\n",
       "4    652\n",
       "5    649\n",
       "8    643\n",
       "Name: class_id, dtype: int64"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts(train_df['class_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-10T21:22:05.136899Z",
     "start_time": "2022-12-10T21:22:05.126678Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    10.735294\n",
       "7    10.426471\n",
       "9    10.264706\n",
       "3    10.235294\n",
       "2     9.970588\n",
       "0     9.911765\n",
       "6     9.867647\n",
       "4     9.588235\n",
       "5     9.544118\n",
       "8     9.455882\n",
       "Name: class_id, dtype: float64"
      ]
     },
     "execution_count": 16,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_df['class_id'].value_counts(1) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Vemos que cada clase ronda entre un 9.4% y 10.7% de los datos en el conjunto de entrenamiento."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Revisemos ahora los datos de prueba"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-10T21:22:06.798085Z",
     "start_time": "2022-12-10T21:22:06.794220Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    129\n",
       "7    125\n",
       "3    123\n",
       "9    123\n",
       "2    120\n",
       "0    119\n",
       "6    118\n",
       "4    115\n",
       "5    114\n",
       "8    114\n",
       "Name: class_id, dtype: int64"
      ]
     },
     "execution_count": 17,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "pd.value_counts(test_df['class_id'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-10T21:22:07.300137Z",
     "start_time": "2022-12-10T21:22:07.295848Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "1    10.750000\n",
       "7    10.416667\n",
       "3    10.250000\n",
       "9    10.250000\n",
       "2    10.000000\n",
       "0     9.916667\n",
       "6     9.833333\n",
       "4     9.583333\n",
       "5     9.500000\n",
       "8     9.500000\n",
       "Name: class_id, dtype: float64"
      ]
     },
     "execution_count": 18,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "test_df['class_id'].value_counts(1) * 100"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para el conjunto de datos de prueba tenemos un caso muy similar, por lo que la estratificación es adecuada ya que contamos con clases balanceadas en cada uno de los datasets."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Constantes del proyecto"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos las constantes del proyecto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-10T21:22:10.331753Z",
     "start_time": "2022-12-10T21:22:10.330015Z"
    }
   },
   "outputs": [],
   "source": [
    "config_dict = load_config()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-10T21:22:10.635258Z",
     "start_time": "2022-12-10T21:22:10.633426Z"
    }
   },
   "outputs": [],
   "source": [
    "config_dict['gray_scale'] = True if config_dict['num_channels'] == 1 else False"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Manejo de las imagenes (Clases y Bounding Boxes)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Haremos uso de la clase que se encarga de cargar las imagenes, los bounding boxes y transformarlas (en caso que se le pase un transformador), a modo de ejemplo de la tarea que se realiza en este notebook."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-10T21:22:30.448267Z",
     "start_time": "2022-12-10T21:22:30.431990Z"
    }
   },
   "outputs": [],
   "source": [
    "train_ds = MNISTDataset(train_df, root_dir=config_dict['train_images_dir'])\n",
    "\n",
    "# Mostraremos las 10 primeras imagenes\n",
    "num_imgs = 10\n",
    "start_idx = 0\n",
    "\n",
    "samples = [train_ds[i] for i in range(start_idx, num_imgs)]\n",
    "\n",
    "# Obtenemos las imagenes del conjunto.\n",
    "imgs = [s['image'] for s in samples]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-04T21:44:06.990304Z",
     "start_time": "2022-12-04T21:44:06.930989Z"
    }
   },
   "source": [
    "Visualizamos las imagenes antes de ser transformadas"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-10T21:22:31.539136Z",
     "start_time": "2022-12-10T21:22:31.174197Z"
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2160x720 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(30, num_imgs))\n",
    "\n",
    "for i, img in enumerate(imgs):\n",
    "    fig.add_subplot(1, num_imgs, i+1)\n",
    "    plt.imshow(img)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Obtenemos las clases y los boxes a las imagenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-10T21:22:32.236339Z",
     "start_time": "2022-12-10T21:22:32.234114Z"
    }
   },
   "outputs": [],
   "source": [
    "bboxes = [normalize_bbox(s['bbox'].squeeze()) for s in samples]\n",
    "classes = [s['class_id'] for s in samples]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Agregamos los boxes y las clases a las imagenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-10T21:22:33.118112Z",
     "start_time": "2022-12-10T21:22:33.114853Z"
    }
   },
   "outputs": [],
   "source": [
    "imgs = draw_predictions(imgs, classes, bboxes, [(0, 150, 0)], (90, 95))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-10T21:22:34.099553Z",
     "start_time": "2022-12-10T21:22:33.695950Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 2160x720 with 10 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig = plt.figure(figsize=(30, num_imgs))\n",
    "\n",
    "for i, img in enumerate(imgs):\n",
    "    fig.add_subplot(1, num_imgs, i+1)\n",
    "    plt.imshow(img)\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image Normalization"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Sacamos la media y la desviación de las imagenes que nos ayudará a normalizar las imagenes antes de pasarlas al modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-10T21:22:58.806369Z",
     "start_time": "2022-12-10T21:22:34.892655Z"
    }
   },
   "outputs": [],
   "source": [
    "means = None\n",
    "stds = None\n",
    "\n",
    "if means is None and stds is None:\n",
    "    means, stds = [], []\n",
    "    pixel_values = [\n",
    "        [], # R, size = H * W * num_images \n",
    "        [], # G size = H * W * num_images\n",
    "        [], # B size = H * W * num_images\n",
    "    ]\n",
    "\n",
    "    for x in train_ds:\n",
    "        img = x['image']\n",
    "\n",
    "        for channel in range(3):\n",
    "            channel_pixel_values = list(img[..., channel].flatten())\n",
    "            pixel_values[channel].extend(channel_pixel_values)\n",
    "\n",
    "    for channel in range(3):\n",
    "        means.append(np.mean(pixel_values[channel]))\n",
    "        stds.append(np.std(pixel_values[channel]))\n",
    "    \n",
    "    del pixel_values"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-10T21:22:58.839924Z",
     "start_time": "2022-12-10T21:22:58.837521Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "[2.619323970588235, 2.619323970588235, 2.619323970588235]\n",
      "[23.784977604424643, 23.784977604424643, 23.784977604424643]\n"
     ]
    }
   ],
   "source": [
    "print(means)\n",
    "print(stds)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos nuestro normalizador, que luego usaremos en las imagenes antes de pasarlas por los modelos."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-10T21:22:58.865457Z",
     "start_time": "2022-12-10T21:22:58.862854Z"
    }
   },
   "outputs": [],
   "source": [
    "class Normalizer(object):\n",
    "    \n",
    "    def __init__(self, stds, means):\n",
    "        \"\"\"\n",
    "        Arguments:\n",
    "        \n",
    "            stds: array of length 3 containing the standard deviation of each channel in RGB order.\n",
    "            means: array of length 3 containing the meeans of each channel in RGB order.\n",
    "        \"\"\"\n",
    "        self.stds = stds\n",
    "        self.means = means\n",
    "    \n",
    "    def __call__(self, sample):\n",
    "        \"\"\"\n",
    "        Sample: a dicitonary containing:\n",
    "            image: sample image in format (C, H, W)\n",
    "        Returns:\n",
    "            the image in (C, H, W) format with the channels normalized.\n",
    "        \"\"\"\n",
    "        image = sample['image']\n",
    "        \n",
    "        for channel in range(config_dict['num_channels']):\n",
    "            image[channel] = (image[channel] - means[channel]) / stds[channel]\n",
    "\n",
    "        sample['image'] = image\n",
    "        \n",
    "        return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image To Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos un transformador que se encarga de convertir las imagenes en tensores. Este transformador reordena los canales de entrada y hace un resize de las imagenes, con este transformador las imagenes ya podrán pasar por nuestro modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-10T21:22:58.893500Z",
     "start_time": "2022-12-10T21:22:58.890334Z"
    }
   },
   "outputs": [],
   "source": [
    "class ToTensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "    \n",
    "    def __init__(self, img_size, gray: False):\n",
    "        self.img_size = img_size\n",
    "        self.gray = gray\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image = sample['image']\n",
    "        # swap color axis because\n",
    "        # numpy image: H x W x C\n",
    "        # torch image: C x H x W\n",
    "        if(self.gray):\n",
    "            image = np.expand_dims(image, axis=2)\n",
    "            \n",
    "        image = image.transpose((2, 0, 1))\n",
    "        image = torch.from_numpy(image).float()\n",
    "        image = resize(image, (self.img_size, self.img_size))\n",
    "        sample.update({'image': image})\n",
    "        return sample\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos el conjunto de datos que usaremos para un primer entrenamiento del modelo, el cual recibirá las imagenes originales (redimensionadas) y transfer learning.\n",
    "\n",
    "Para las siguientes etapas agregaremos transfer learning y haremos un proceso de data augmentation para comparar los resultados."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-10T21:22:58.957361Z",
     "start_time": "2022-12-10T21:22:58.916876Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "train_ds = MNISTDataset(train_df,gray=config_dict['gray_scale'], root_dir=config_dict['train_images_dir'], transform=ToTensor(img_size=config_dict['img_size'], gray=config_dict['gray_scale']))\n",
    "train_data = torch.utils.data.DataLoader(train_ds, batch_size=config_dict['batch_size'])\n",
    "for x in train_data:\n",
    "    print(x['image'].size())\n",
    "    break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Feature Extractor Model (Backbone)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Para construir la arquitectura nos basaremos en la información encontrada en las siguiente fuente:\n",
    "- [25 Million Images! [0.99757] MNIST](https://www.kaggle.com/code/cdeotte/25-million-images-0-99757-mnist/notebook)\n",
    "En este articulo se mencionan varias arquitecturas que estaremos probando, en cada una de ellas dejaremos los créditos correspondientes. Revisamos los articulos de las arquitecturas que se mencionan, con el proposito de compreender como y porqué fueron construidas de esa forma.\n",
    "Algo importante de este articulo es que mencionan como aumentan un dataset de 42000 imagenes a 25 millones rotandolas, escalandolas y haciendo otro tipo de transformaciones.\n",
    "- [How to choose CNN Architecture MNIST](https://www.kaggle.com/code/cdeotte/how-to-choose-cnn-architecture-mnist/notebook) acá se realizan varios experimentos de arquitectura y se menciona \n",
    "- [MNIST Handwritten Digits Classification using a Convolutional Neural Network (CNN)](https://towardsdatascience.com/mnist-handwritten-digits-classification-using-a-convolutional-neural-network-cnn-af5fafbc35e9)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-10T21:22:58.997734Z",
     "start_time": "2022-12-10T21:22:58.990123Z"
    }
   },
   "outputs": [],
   "source": [
    "feature_extractor_model = FeatureExtractor(channels=config_dict['num_channels']).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-10T21:22:59.104969Z",
     "start_time": "2022-12-10T21:22:59.020256Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 26, 26]             320\n",
      "              ReLU-2           [-1, 32, 26, 26]               0\n",
      "       BatchNorm2d-3           [-1, 32, 26, 26]              64\n",
      "            Conv2d-4           [-1, 32, 24, 24]           9,248\n",
      "              ReLU-5           [-1, 32, 24, 24]               0\n",
      "       BatchNorm2d-6           [-1, 32, 24, 24]              64\n",
      "            Conv2d-7           [-1, 32, 12, 12]          25,632\n",
      "              ReLU-8           [-1, 32, 12, 12]               0\n",
      "       BatchNorm2d-9           [-1, 32, 12, 12]              64\n",
      "          Dropout-10           [-1, 32, 12, 12]               0\n",
      "           Conv2d-11           [-1, 64, 10, 10]          18,496\n",
      "             ReLU-12           [-1, 64, 10, 10]               0\n",
      "      BatchNorm2d-13           [-1, 64, 10, 10]             128\n",
      "           Conv2d-14             [-1, 64, 8, 8]          36,928\n",
      "             ReLU-15             [-1, 64, 8, 8]               0\n",
      "      BatchNorm2d-16             [-1, 64, 8, 8]             128\n",
      "           Conv2d-17             [-1, 64, 4, 4]         102,464\n",
      "             ReLU-18             [-1, 64, 4, 4]               0\n",
      "      BatchNorm2d-19             [-1, 64, 4, 4]             128\n",
      "          Dropout-20             [-1, 64, 4, 4]               0\n",
      "          Flatten-21                 [-1, 1024]               0\n",
      "================================================================\n",
      "Total params: 193,664\n",
      "Trainable params: 193,664\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 1.34\n",
      "Params size (MB): 0.74\n",
      "Estimated Total Size (MB): 2.08\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(feature_extractor_model, input_size=(config_dict['num_channels'], config_dict['img_size'], config_dict['img_size']), device=device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-10T21:22:59.130050Z",
     "start_time": "2022-12-10T21:22:59.128441Z"
    }
   },
   "outputs": [],
   "source": [
    "feature_extractor_output_shape = 1024"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Object classification Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos la cabeza de clasificación que tomará las salidas de nuestro feature extractor y clasificará las imagen según la probabilidad de que pertenezcan a una clase dada."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-10T21:22:59.155231Z",
     "start_time": "2022-12-10T21:22:59.152187Z"
    }
   },
   "outputs": [],
   "source": [
    "classifier = ClassificationHead(input_size=feature_extractor_output_shape, n_classes=config_dict['num_classes']).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-10T21:22:59.188040Z",
     "start_time": "2022-12-10T21:22:59.176973Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                  [-1, 128]         131,200\n",
      "              ReLU-2                  [-1, 128]               0\n",
      "       BatchNorm1d-3                  [-1, 128]             256\n",
      "           Dropout-4                  [-1, 128]               0\n",
      "            Linear-5                   [-1, 10]           1,290\n",
      "================================================================\n",
      "Total params: 132,746\n",
      "Trainable params: 132,746\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.00\n",
      "Params size (MB): 0.51\n",
      "Estimated Total Size (MB): 0.51\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(classifier, input_size=(feature_extractor_output_shape,), device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Bounding box prediction Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora definimos nuestra cabeza de regresión, que también tomara las salidas del feature extractor y calculará las coordenadas de los puntos para encerrar los digitos en un recuadro."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-10T21:22:59.217096Z",
     "start_time": "2022-12-10T21:22:59.210484Z"
    }
   },
   "outputs": [],
   "source": [
    "regressor = RegressionHead(input_size=feature_extractor_output_shape).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-10T21:22:59.246337Z",
     "start_time": "2022-12-10T21:22:59.241339Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                  [-1, 768]         787,200\n",
      "              ReLU-2                  [-1, 768]               0\n",
      "            Linear-3                  [-1, 256]         196,864\n",
      "              ReLU-4                  [-1, 256]               0\n",
      "            Linear-5                    [-1, 4]           1,028\n",
      "================================================================\n",
      "Total params: 985,092\n",
      "Trainable params: 985,092\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.02\n",
      "Params size (MB): 3.76\n",
      "Estimated Total Size (MB): 3.78\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(regressor, input_size=(feature_extractor_output_shape,), device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model for classification and objects location"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Ahora definimos el modelo que se encargará de clasificar y localizar las imagenes apoyandose del feature extractor, la cabeza de regresión y la cabeza de clasificación."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-10T21:23:05.850454Z",
     "start_time": "2022-12-10T21:23:05.847923Z"
    }
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, backbone: FeatureExtractor, classifier: ClassificationHead, regressor: RegressionHead):\n",
    "        super().__init__()\n",
    "        self.backbone = backbone\n",
    "        self.cls_head = classifier\n",
    "        self.reg_head = regressor\n",
    "        \n",
    "    def forward(self, x):\n",
    "        features = self.backbone(x)\n",
    "        cls_logits = self.cls_head(features)\n",
    "        pred_bbox = self.reg_head(features)\n",
    "        predictions = {'bbox': pred_bbox, 'class_id': cls_logits}\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-10T21:23:06.227745Z",
     "start_time": "2022-12-10T21:23:06.224638Z"
    }
   },
   "outputs": [],
   "source": [
    "model = Model(feature_extractor_model, classifier, regressor).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-10T21:23:06.730606Z",
     "start_time": "2022-12-10T21:23:06.719621Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 32, 26, 26]             320\n",
      "              ReLU-2           [-1, 32, 26, 26]               0\n",
      "       BatchNorm2d-3           [-1, 32, 26, 26]              64\n",
      "            Conv2d-4           [-1, 32, 24, 24]           9,248\n",
      "              ReLU-5           [-1, 32, 24, 24]               0\n",
      "       BatchNorm2d-6           [-1, 32, 24, 24]              64\n",
      "            Conv2d-7           [-1, 32, 12, 12]          25,632\n",
      "              ReLU-8           [-1, 32, 12, 12]               0\n",
      "       BatchNorm2d-9           [-1, 32, 12, 12]              64\n",
      "          Dropout-10           [-1, 32, 12, 12]               0\n",
      "           Conv2d-11           [-1, 64, 10, 10]          18,496\n",
      "             ReLU-12           [-1, 64, 10, 10]               0\n",
      "      BatchNorm2d-13           [-1, 64, 10, 10]             128\n",
      "           Conv2d-14             [-1, 64, 8, 8]          36,928\n",
      "             ReLU-15             [-1, 64, 8, 8]               0\n",
      "      BatchNorm2d-16             [-1, 64, 8, 8]             128\n",
      "           Conv2d-17             [-1, 64, 4, 4]         102,464\n",
      "             ReLU-18             [-1, 64, 4, 4]               0\n",
      "      BatchNorm2d-19             [-1, 64, 4, 4]             128\n",
      "          Dropout-20             [-1, 64, 4, 4]               0\n",
      "          Flatten-21                 [-1, 1024]               0\n",
      " FeatureExtractor-22                 [-1, 1024]               0\n",
      "           Linear-23                  [-1, 128]         131,200\n",
      "             ReLU-24                  [-1, 128]               0\n",
      "      BatchNorm1d-25                  [-1, 128]             256\n",
      "          Dropout-26                  [-1, 128]               0\n",
      "           Linear-27                   [-1, 10]           1,290\n",
      "ClassificationHead-28                   [-1, 10]               0\n",
      "           Linear-29                  [-1, 768]         787,200\n",
      "             ReLU-30                  [-1, 768]               0\n",
      "           Linear-31                  [-1, 256]         196,864\n",
      "             ReLU-32                  [-1, 256]               0\n",
      "           Linear-33                    [-1, 4]           1,028\n",
      "   RegressionHead-34                    [-1, 4]               0\n",
      "================================================================\n",
      "Total params: 1,311,502\n",
      "Trainable params: 1,311,502\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 1.36\n",
      "Params size (MB): 5.00\n",
      "Estimated Total Size (MB): 6.37\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(model, input_size=(config_dict['num_channels'], config_dict['img_size'], config_dict['img_size']), device=device)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Methods for training the model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Loss Function"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "La función de perdida es muy importante puesto que el modelo debe tanto clasificar como localizar los números. Para esto usamos dos funciones de perdidas una para la clasificación y otra para la regresión, luego de calculadas ambas funciones de perdida se ponderan para obtener una función de perdida que calcula el total, con esto podemos optimizar ambas tareas al mismo tiempo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-10T21:23:09.818498Z",
     "start_time": "2022-12-10T21:23:09.815631Z"
    }
   },
   "outputs": [],
   "source": [
    "def loss_fn(\n",
    "    y_true, \n",
    "    y_preds, \n",
    "    cls_loss_fn: CrossEntropyLoss, \n",
    "    bbox_loss_fn: ty.Callable[[ty.Dict[str, torch.Tensor]], torch.Tensor],  \n",
    "    alpha: float = 0.5\n",
    "):\n",
    "    cls_y_true, cls_y_pred = y_true['class_id'].long(), y_preds['class_id'].float().unsqueeze(-1)\n",
    "    reg_y_true, reg_y_pred = y_true['bbox'].float().squeeze(), y_preds['bbox'].float().squeeze()\n",
    "    \n",
    "    cls_loss = cls_loss_fn(cls_y_pred, cls_y_true)\n",
    "    # Play!!!\n",
    "    reg_loss = bbox_loss_fn(reg_y_pred, reg_y_true)\n",
    "    # Adds weights to both tasks\n",
    "    total_loss = (1 - alpha) * cls_loss + alpha * reg_loss\n",
    "    return dict(loss=total_loss, reg_loss=reg_loss,cls_loss=cls_loss)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Metrics"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos dos funciones para calcular las metricas de nuestros modelos que para el caso de la clasificación la metrica que se usa es el accuracy y para el caso de la regresión es el Intersection over Union."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Accurancy Metrics "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-10T21:23:10.944704Z",
     "start_time": "2022-12-10T21:23:10.942352Z"
    }
   },
   "outputs": [],
   "source": [
    "def accuracy(y_true: Tensor, y_pred: Tensor):\n",
    "    pred = torch.argmax(y_pred, axis=-1)\n",
    "    y_true = y_true.squeeze()\n",
    "    correct = torch.eq(pred, y_true).float()\n",
    "    total = torch.ones_like(correct)\n",
    "    result = torch.divide(torch.sum(correct), torch.sum(total))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "#### Intersection over Union (IoU) Metric"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-10T21:23:11.403395Z",
     "start_time": "2022-12-10T21:23:11.400977Z"
    }
   },
   "outputs": [],
   "source": [
    "def iou(y_true: Tensor, y_pred: Tensor):\n",
    "    pairwise_iou = torchvision.ops.box_iou(y_true.squeeze(), y_pred.squeeze())\n",
    "    result = torch.trace(pairwise_iou) / pairwise_iou.size()[0]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Callbacks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-10T21:27:53.302228Z",
     "start_time": "2022-12-10T21:27:53.298764Z"
    }
   },
   "outputs": [],
   "source": [
    "def printer(logs: ty.Dict[str, ty.Any]):\n",
    "    # print every 5 steps\n",
    "    if logs['iters'] % 5 != 0:\n",
    "        return\n",
    "    print('Iteration #: ',logs['iters'])\n",
    "    for name, value in logs.items():\n",
    "        if name == 'iters':\n",
    "            continue\n",
    "        \n",
    "        if type(value) in [float, int]:\n",
    "            value = round(value, 4)\n",
    "        elif type(value) is torch.Tensor:\n",
    "            value = value.detach().cpu().numpy()\n",
    "            value = np.round(value, 4)\n",
    "            value = torch.from_numpy(np.asarray(value))\n",
    "            value.to(device)\n",
    "            \n",
    "#             value = torch.round(value, decimals=4)\n",
    "        \n",
    "        print(f'\\t{name} = {value}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Optimizer"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-10T21:27:53.945111Z",
     "start_time": "2022-12-10T21:27:53.942958Z"
    }
   },
   "outputs": [],
   "source": [
    "optimizer = torch.optim.Adam(lr=config_dict['learning_rate'], params=model.parameters(), weight_decay=config_dict['weight_decay'])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Base Model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Corremos nuestro primer modelo que no tiene data augmentation y tampoco Transfer learning. También creamos un arreglo donde iremos guardando nuestros modelos."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Cargamos los datos para el entrenamiento"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-10T21:27:56.025615Z",
     "start_time": "2022-12-10T21:27:56.021751Z"
    },
    "code_folding": []
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    }
   ],
   "source": [
    "base_transform = torchvision.transforms.Compose(\n",
    "    [ToTensor(img_size=config_dict['img_size'], gray=config_dict['gray_scale'])]\n",
    ")\n",
    "\n",
    "train_ds = MNISTDataset(train_df, gray=config_dict['gray_scale'], root_dir=config_dict['train_images_dir'], transform=base_transform)\n",
    "test_ds = MNISTDataset(test_df, gray=config_dict['gray_scale'], root_dir=config_dict['train_images_dir'], transform=base_transform)\n",
    "\n",
    "train_data = DataLoader(train_ds, batch_size=config_dict['batch_size'], shuffle=True, num_workers=cpu_count())\n",
    "test_data = DataLoader(test_ds, batch_size=config_dict['batch_size'], num_workers=cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-12-10T18:08:42.973Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "train_result = train(\n",
    "    model,\n",
    "    optimizer,\n",
    "    train_data,\n",
    "    eval_datasets=[('val', test_data)],\n",
    "    loss_fn=loss_fn,\n",
    "    metrics={\n",
    "        'bbox': [('iou', iou)],\n",
    "        'class_id': [('accuracy', accuracy)]\n",
    "    },\n",
    "    callbacks=[printer],\n",
    "    device=device,\n",
    "    train_steps=config_dict['num_epochs'],\n",
    "    eval_steps=5,\n",
    ")\n",
    "\n",
    "model = train_result['model']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions Visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-10T01:50:37.958445Z",
     "start_time": "2022-12-10T01:50:37.369689Z"
    }
   },
   "outputs": [],
   "source": [
    "num_imgs = 20\n",
    "ncols = 10\n",
    "nrows = math.ceil(num_imgs / ncols)\n",
    "\n",
    "start_idx = 0\n",
    "\n",
    "inference_ds = MNISTDataset(test_df.iloc[start_idx:start_idx+num_imgs], gray=config_dict['gray_scale'], root_dir='datasets/images/train/')\n",
    "inference_data = DataLoader(inference_ds, batch_size=num_imgs, num_workers=1, shuffle=False)\n",
    "inference_batch = next(iter(inference_data))\n",
    "inference_imgs = np.empty((num_imgs, 1, 28, 28))\n",
    "\n",
    "transform = base_transform\n",
    "\n",
    "for i, img in enumerate(inference_batch['image']):\n",
    "    inference_imgs[i] = transform(dict(image=img.numpy()))['image'].numpy()\n",
    "\n",
    "preds = model(torch.tensor(inference_imgs).float().to(device))\n",
    "\n",
    "samples = [inference_ds[i] for i in range(start_idx, num_imgs)]\n",
    "\n",
    "imgs = [s['image'] for s in samples]\n",
    "bboxes = [normalize_bbox(s['bbox'].squeeze()) for s in samples]\n",
    "classes = [s['class_id'] for s in samples]\n",
    "\n",
    "pred_bboxes = preds['bbox'].detach().cpu().numpy()\n",
    "pred_bboxes = [normalize_bbox(bbox) for bbox in pred_bboxes]\n",
    "pred_classes = preds['class_id'].argmax(-1).detach().cpu().numpy()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-10T01:50:38.843099Z",
     "start_time": "2022-12-10T01:50:37.959787Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 4320x1440 with 20 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "imgs = draw_predictions(imgs, classes, bboxes, [(0, 150, 0)], (90, 95))\n",
    "# Red: predicted\n",
    "imgs = draw_predictions(imgs, pred_classes, pred_bboxes, [(200, 0, 0)], (10, 95))\n",
    "\n",
    "fig = plt.figure(figsize=(30*nrows, num_imgs))\n",
    "k, j = 1, 1\n",
    "\n",
    "for img in imgs:\n",
    "    if j > ncols and k < nrows:\n",
    "        k += 1\n",
    "        j = 1\n",
    "    fig.add_subplot(k, num_imgs, j)\n",
    "    plt.imshow(img)\n",
    "    j += 1\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Transfer Learning"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Usaremos modelos preentrenados como backbone para realizar la clasificación y regresión. Usaremos el modelo de RestNet y AlexNet para compararlo. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Los modelos deben recibir imagenes de entrada normalizadas con RGB de 3 canales de la forma  (3 x H x W) donde H y W deben ser de por lo menos 224. Las imagenes deben estar en un rango de [0,1] y normalizarse usando y."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image normalization transforms"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos un transformador para normalizar y tener las imagenes en el tamaño que se necesitan para el modelo."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-10T22:05:19.691252Z",
     "start_time": "2022-12-10T22:05:19.689086Z"
    }
   },
   "outputs": [],
   "source": [
    "config_dict['img_size'] = 224"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-10T21:29:52.916969Z",
     "start_time": "2022-12-10T21:29:52.914863Z"
    }
   },
   "outputs": [],
   "source": [
    "common_transforms = [\n",
    "    Normalizer(means=means, stds=stds) ,\n",
    "    ToTensor(img_size=config_dict['img_size'], gray=False),\n",
    "]\n",
    "\n",
    "train_transforms = torchvision.transforms.Compose(\n",
    "        common_transforms\n",
    ")\n",
    "\n",
    "eval_transforms = torchvision.transforms.Compose(common_transforms)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ResNet152"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-10T01:50:39.758442Z",
     "start_time": "2022-12-10T01:50:38.848639Z"
    }
   },
   "outputs": [],
   "source": [
    "resnet_pretrained = resnet152(pretrained=True, progress=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-10T01:50:39.931062Z",
     "start_time": "2022-12-10T01:50:39.759909Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
      "              ReLU-3         [-1, 64, 112, 112]               0\n",
      "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
      "            Conv2d-5           [-1, 64, 56, 56]           4,096\n",
      "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
      "              ReLU-7           [-1, 64, 56, 56]               0\n",
      "            Conv2d-8           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
      "             ReLU-10           [-1, 64, 56, 56]               0\n",
      "           Conv2d-11          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-12          [-1, 256, 56, 56]             512\n",
      "           Conv2d-13          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-14          [-1, 256, 56, 56]             512\n",
      "             ReLU-15          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-16          [-1, 256, 56, 56]               0\n",
      "           Conv2d-17           [-1, 64, 56, 56]          16,384\n",
      "      BatchNorm2d-18           [-1, 64, 56, 56]             128\n",
      "             ReLU-19           [-1, 64, 56, 56]               0\n",
      "           Conv2d-20           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-21           [-1, 64, 56, 56]             128\n",
      "             ReLU-22           [-1, 64, 56, 56]               0\n",
      "           Conv2d-23          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-24          [-1, 256, 56, 56]             512\n",
      "             ReLU-25          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-26          [-1, 256, 56, 56]               0\n",
      "           Conv2d-27           [-1, 64, 56, 56]          16,384\n",
      "      BatchNorm2d-28           [-1, 64, 56, 56]             128\n",
      "             ReLU-29           [-1, 64, 56, 56]               0\n",
      "           Conv2d-30           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-31           [-1, 64, 56, 56]             128\n",
      "             ReLU-32           [-1, 64, 56, 56]               0\n",
      "           Conv2d-33          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-34          [-1, 256, 56, 56]             512\n",
      "             ReLU-35          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-36          [-1, 256, 56, 56]               0\n",
      "           Conv2d-37          [-1, 128, 56, 56]          32,768\n",
      "      BatchNorm2d-38          [-1, 128, 56, 56]             256\n",
      "             ReLU-39          [-1, 128, 56, 56]               0\n",
      "           Conv2d-40          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-41          [-1, 128, 28, 28]             256\n",
      "             ReLU-42          [-1, 128, 28, 28]               0\n",
      "           Conv2d-43          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-44          [-1, 512, 28, 28]           1,024\n",
      "           Conv2d-45          [-1, 512, 28, 28]         131,072\n",
      "      BatchNorm2d-46          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-47          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-48          [-1, 512, 28, 28]               0\n",
      "           Conv2d-49          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-50          [-1, 128, 28, 28]             256\n",
      "             ReLU-51          [-1, 128, 28, 28]               0\n",
      "           Conv2d-52          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-53          [-1, 128, 28, 28]             256\n",
      "             ReLU-54          [-1, 128, 28, 28]               0\n",
      "           Conv2d-55          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-56          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-57          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-58          [-1, 512, 28, 28]               0\n",
      "           Conv2d-59          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-60          [-1, 128, 28, 28]             256\n",
      "             ReLU-61          [-1, 128, 28, 28]               0\n",
      "           Conv2d-62          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-63          [-1, 128, 28, 28]             256\n",
      "             ReLU-64          [-1, 128, 28, 28]               0\n",
      "           Conv2d-65          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-66          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-67          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-68          [-1, 512, 28, 28]               0\n",
      "           Conv2d-69          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-70          [-1, 128, 28, 28]             256\n",
      "             ReLU-71          [-1, 128, 28, 28]               0\n",
      "           Conv2d-72          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-73          [-1, 128, 28, 28]             256\n",
      "             ReLU-74          [-1, 128, 28, 28]               0\n",
      "           Conv2d-75          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-76          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-77          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-78          [-1, 512, 28, 28]               0\n",
      "           Conv2d-79          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-80          [-1, 128, 28, 28]             256\n",
      "             ReLU-81          [-1, 128, 28, 28]               0\n",
      "           Conv2d-82          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-83          [-1, 128, 28, 28]             256\n",
      "             ReLU-84          [-1, 128, 28, 28]               0\n",
      "           Conv2d-85          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-86          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-87          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-88          [-1, 512, 28, 28]               0\n",
      "           Conv2d-89          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-90          [-1, 128, 28, 28]             256\n",
      "             ReLU-91          [-1, 128, 28, 28]               0\n",
      "           Conv2d-92          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-93          [-1, 128, 28, 28]             256\n",
      "             ReLU-94          [-1, 128, 28, 28]               0\n",
      "           Conv2d-95          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-96          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-97          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-98          [-1, 512, 28, 28]               0\n",
      "           Conv2d-99          [-1, 128, 28, 28]          65,536\n",
      "     BatchNorm2d-100          [-1, 128, 28, 28]             256\n",
      "            ReLU-101          [-1, 128, 28, 28]               0\n",
      "          Conv2d-102          [-1, 128, 28, 28]         147,456\n",
      "     BatchNorm2d-103          [-1, 128, 28, 28]             256\n",
      "            ReLU-104          [-1, 128, 28, 28]               0\n",
      "          Conv2d-105          [-1, 512, 28, 28]          65,536\n",
      "     BatchNorm2d-106          [-1, 512, 28, 28]           1,024\n",
      "            ReLU-107          [-1, 512, 28, 28]               0\n",
      "      Bottleneck-108          [-1, 512, 28, 28]               0\n",
      "          Conv2d-109          [-1, 128, 28, 28]          65,536\n",
      "     BatchNorm2d-110          [-1, 128, 28, 28]             256\n",
      "            ReLU-111          [-1, 128, 28, 28]               0\n",
      "          Conv2d-112          [-1, 128, 28, 28]         147,456\n",
      "     BatchNorm2d-113          [-1, 128, 28, 28]             256\n",
      "            ReLU-114          [-1, 128, 28, 28]               0\n",
      "          Conv2d-115          [-1, 512, 28, 28]          65,536\n",
      "     BatchNorm2d-116          [-1, 512, 28, 28]           1,024\n",
      "            ReLU-117          [-1, 512, 28, 28]               0\n",
      "      Bottleneck-118          [-1, 512, 28, 28]               0\n",
      "          Conv2d-119          [-1, 256, 28, 28]         131,072\n",
      "     BatchNorm2d-120          [-1, 256, 28, 28]             512\n",
      "            ReLU-121          [-1, 256, 28, 28]               0\n",
      "          Conv2d-122          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-123          [-1, 256, 14, 14]             512\n",
      "            ReLU-124          [-1, 256, 14, 14]               0\n",
      "          Conv2d-125         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-126         [-1, 1024, 14, 14]           2,048\n",
      "          Conv2d-127         [-1, 1024, 14, 14]         524,288\n",
      "     BatchNorm2d-128         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-129         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-130         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-131          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-132          [-1, 256, 14, 14]             512\n",
      "            ReLU-133          [-1, 256, 14, 14]               0\n",
      "          Conv2d-134          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-135          [-1, 256, 14, 14]             512\n",
      "            ReLU-136          [-1, 256, 14, 14]               0\n",
      "          Conv2d-137         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-138         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-139         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-140         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-141          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-142          [-1, 256, 14, 14]             512\n",
      "            ReLU-143          [-1, 256, 14, 14]               0\n",
      "          Conv2d-144          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-145          [-1, 256, 14, 14]             512\n",
      "            ReLU-146          [-1, 256, 14, 14]               0\n",
      "          Conv2d-147         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-148         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-149         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-150         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-151          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-152          [-1, 256, 14, 14]             512\n",
      "            ReLU-153          [-1, 256, 14, 14]               0\n",
      "          Conv2d-154          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-155          [-1, 256, 14, 14]             512\n",
      "            ReLU-156          [-1, 256, 14, 14]               0\n",
      "          Conv2d-157         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-158         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-159         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-160         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-161          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-162          [-1, 256, 14, 14]             512\n",
      "            ReLU-163          [-1, 256, 14, 14]               0\n",
      "          Conv2d-164          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-165          [-1, 256, 14, 14]             512\n",
      "            ReLU-166          [-1, 256, 14, 14]               0\n",
      "          Conv2d-167         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-168         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-169         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-170         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-171          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-172          [-1, 256, 14, 14]             512\n",
      "            ReLU-173          [-1, 256, 14, 14]               0\n",
      "          Conv2d-174          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-175          [-1, 256, 14, 14]             512\n",
      "            ReLU-176          [-1, 256, 14, 14]               0\n",
      "          Conv2d-177         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-178         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-179         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-180         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-181          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-182          [-1, 256, 14, 14]             512\n",
      "            ReLU-183          [-1, 256, 14, 14]               0\n",
      "          Conv2d-184          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-185          [-1, 256, 14, 14]             512\n",
      "            ReLU-186          [-1, 256, 14, 14]               0\n",
      "          Conv2d-187         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-188         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-189         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-190         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-191          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-192          [-1, 256, 14, 14]             512\n",
      "            ReLU-193          [-1, 256, 14, 14]               0\n",
      "          Conv2d-194          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-195          [-1, 256, 14, 14]             512\n",
      "            ReLU-196          [-1, 256, 14, 14]               0\n",
      "          Conv2d-197         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-198         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-199         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-200         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-201          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-202          [-1, 256, 14, 14]             512\n",
      "            ReLU-203          [-1, 256, 14, 14]               0\n",
      "          Conv2d-204          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-205          [-1, 256, 14, 14]             512\n",
      "            ReLU-206          [-1, 256, 14, 14]               0\n",
      "          Conv2d-207         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-208         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-209         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-210         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-211          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-212          [-1, 256, 14, 14]             512\n",
      "            ReLU-213          [-1, 256, 14, 14]               0\n",
      "          Conv2d-214          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-215          [-1, 256, 14, 14]             512\n",
      "            ReLU-216          [-1, 256, 14, 14]               0\n",
      "          Conv2d-217         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-218         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-219         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-220         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-221          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-222          [-1, 256, 14, 14]             512\n",
      "            ReLU-223          [-1, 256, 14, 14]               0\n",
      "          Conv2d-224          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-225          [-1, 256, 14, 14]             512\n",
      "            ReLU-226          [-1, 256, 14, 14]               0\n",
      "          Conv2d-227         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-228         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-229         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-230         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-231          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-232          [-1, 256, 14, 14]             512\n",
      "            ReLU-233          [-1, 256, 14, 14]               0\n",
      "          Conv2d-234          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-235          [-1, 256, 14, 14]             512\n",
      "            ReLU-236          [-1, 256, 14, 14]               0\n",
      "          Conv2d-237         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-238         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-239         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-240         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-241          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-242          [-1, 256, 14, 14]             512\n",
      "            ReLU-243          [-1, 256, 14, 14]               0\n",
      "          Conv2d-244          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-245          [-1, 256, 14, 14]             512\n",
      "            ReLU-246          [-1, 256, 14, 14]               0\n",
      "          Conv2d-247         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-248         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-249         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-250         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-251          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-252          [-1, 256, 14, 14]             512\n",
      "            ReLU-253          [-1, 256, 14, 14]               0\n",
      "          Conv2d-254          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-255          [-1, 256, 14, 14]             512\n",
      "            ReLU-256          [-1, 256, 14, 14]               0\n",
      "          Conv2d-257         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-258         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-259         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-260         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-261          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-262          [-1, 256, 14, 14]             512\n",
      "            ReLU-263          [-1, 256, 14, 14]               0\n",
      "          Conv2d-264          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-265          [-1, 256, 14, 14]             512\n",
      "            ReLU-266          [-1, 256, 14, 14]               0\n",
      "          Conv2d-267         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-268         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-269         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-270         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-271          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-272          [-1, 256, 14, 14]             512\n",
      "            ReLU-273          [-1, 256, 14, 14]               0\n",
      "          Conv2d-274          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-275          [-1, 256, 14, 14]             512\n",
      "            ReLU-276          [-1, 256, 14, 14]               0\n",
      "          Conv2d-277         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-278         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-279         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-280         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-281          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-282          [-1, 256, 14, 14]             512\n",
      "            ReLU-283          [-1, 256, 14, 14]               0\n",
      "          Conv2d-284          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-285          [-1, 256, 14, 14]             512\n",
      "            ReLU-286          [-1, 256, 14, 14]               0\n",
      "          Conv2d-287         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-288         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-289         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-290         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-291          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-292          [-1, 256, 14, 14]             512\n",
      "            ReLU-293          [-1, 256, 14, 14]               0\n",
      "          Conv2d-294          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-295          [-1, 256, 14, 14]             512\n",
      "            ReLU-296          [-1, 256, 14, 14]               0\n",
      "          Conv2d-297         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-298         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-299         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-300         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-301          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-302          [-1, 256, 14, 14]             512\n",
      "            ReLU-303          [-1, 256, 14, 14]               0\n",
      "          Conv2d-304          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-305          [-1, 256, 14, 14]             512\n",
      "            ReLU-306          [-1, 256, 14, 14]               0\n",
      "          Conv2d-307         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-308         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-309         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-310         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-311          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-312          [-1, 256, 14, 14]             512\n",
      "            ReLU-313          [-1, 256, 14, 14]               0\n",
      "          Conv2d-314          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-315          [-1, 256, 14, 14]             512\n",
      "            ReLU-316          [-1, 256, 14, 14]               0\n",
      "          Conv2d-317         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-318         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-319         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-320         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-321          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-322          [-1, 256, 14, 14]             512\n",
      "            ReLU-323          [-1, 256, 14, 14]               0\n",
      "          Conv2d-324          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-325          [-1, 256, 14, 14]             512\n",
      "            ReLU-326          [-1, 256, 14, 14]               0\n",
      "          Conv2d-327         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-328         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-329         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-330         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-331          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-332          [-1, 256, 14, 14]             512\n",
      "            ReLU-333          [-1, 256, 14, 14]               0\n",
      "          Conv2d-334          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-335          [-1, 256, 14, 14]             512\n",
      "            ReLU-336          [-1, 256, 14, 14]               0\n",
      "          Conv2d-337         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-338         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-339         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-340         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-341          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-342          [-1, 256, 14, 14]             512\n",
      "            ReLU-343          [-1, 256, 14, 14]               0\n",
      "          Conv2d-344          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-345          [-1, 256, 14, 14]             512\n",
      "            ReLU-346          [-1, 256, 14, 14]               0\n",
      "          Conv2d-347         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-348         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-349         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-350         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-351          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-352          [-1, 256, 14, 14]             512\n",
      "            ReLU-353          [-1, 256, 14, 14]               0\n",
      "          Conv2d-354          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-355          [-1, 256, 14, 14]             512\n",
      "            ReLU-356          [-1, 256, 14, 14]               0\n",
      "          Conv2d-357         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-358         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-359         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-360         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-361          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-362          [-1, 256, 14, 14]             512\n",
      "            ReLU-363          [-1, 256, 14, 14]               0\n",
      "          Conv2d-364          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-365          [-1, 256, 14, 14]             512\n",
      "            ReLU-366          [-1, 256, 14, 14]               0\n",
      "          Conv2d-367         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-368         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-369         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-370         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-371          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-372          [-1, 256, 14, 14]             512\n",
      "            ReLU-373          [-1, 256, 14, 14]               0\n",
      "          Conv2d-374          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-375          [-1, 256, 14, 14]             512\n",
      "            ReLU-376          [-1, 256, 14, 14]               0\n",
      "          Conv2d-377         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-378         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-379         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-380         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-381          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-382          [-1, 256, 14, 14]             512\n",
      "            ReLU-383          [-1, 256, 14, 14]               0\n",
      "          Conv2d-384          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-385          [-1, 256, 14, 14]             512\n",
      "            ReLU-386          [-1, 256, 14, 14]               0\n",
      "          Conv2d-387         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-388         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-389         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-390         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-391          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-392          [-1, 256, 14, 14]             512\n",
      "            ReLU-393          [-1, 256, 14, 14]               0\n",
      "          Conv2d-394          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-395          [-1, 256, 14, 14]             512\n",
      "            ReLU-396          [-1, 256, 14, 14]               0\n",
      "          Conv2d-397         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-398         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-399         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-400         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-401          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-402          [-1, 256, 14, 14]             512\n",
      "            ReLU-403          [-1, 256, 14, 14]               0\n",
      "          Conv2d-404          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-405          [-1, 256, 14, 14]             512\n",
      "            ReLU-406          [-1, 256, 14, 14]               0\n",
      "          Conv2d-407         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-408         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-409         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-410         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-411          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-412          [-1, 256, 14, 14]             512\n",
      "            ReLU-413          [-1, 256, 14, 14]               0\n",
      "          Conv2d-414          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-415          [-1, 256, 14, 14]             512\n",
      "            ReLU-416          [-1, 256, 14, 14]               0\n",
      "          Conv2d-417         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-418         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-419         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-420         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-421          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-422          [-1, 256, 14, 14]             512\n",
      "            ReLU-423          [-1, 256, 14, 14]               0\n",
      "          Conv2d-424          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-425          [-1, 256, 14, 14]             512\n",
      "            ReLU-426          [-1, 256, 14, 14]               0\n",
      "          Conv2d-427         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-428         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-429         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-430         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-431          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-432          [-1, 256, 14, 14]             512\n",
      "            ReLU-433          [-1, 256, 14, 14]               0\n",
      "          Conv2d-434          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-435          [-1, 256, 14, 14]             512\n",
      "            ReLU-436          [-1, 256, 14, 14]               0\n",
      "          Conv2d-437         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-438         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-439         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-440         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-441          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-442          [-1, 256, 14, 14]             512\n",
      "            ReLU-443          [-1, 256, 14, 14]               0\n",
      "          Conv2d-444          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-445          [-1, 256, 14, 14]             512\n",
      "            ReLU-446          [-1, 256, 14, 14]               0\n",
      "          Conv2d-447         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-448         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-449         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-450         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-451          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-452          [-1, 256, 14, 14]             512\n",
      "            ReLU-453          [-1, 256, 14, 14]               0\n",
      "          Conv2d-454          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-455          [-1, 256, 14, 14]             512\n",
      "            ReLU-456          [-1, 256, 14, 14]               0\n",
      "          Conv2d-457         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-458         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-459         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-460         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-461          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-462          [-1, 256, 14, 14]             512\n",
      "            ReLU-463          [-1, 256, 14, 14]               0\n",
      "          Conv2d-464          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-465          [-1, 256, 14, 14]             512\n",
      "            ReLU-466          [-1, 256, 14, 14]               0\n",
      "          Conv2d-467         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-468         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-469         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-470         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-471          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-472          [-1, 256, 14, 14]             512\n",
      "            ReLU-473          [-1, 256, 14, 14]               0\n",
      "          Conv2d-474          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-475          [-1, 256, 14, 14]             512\n",
      "            ReLU-476          [-1, 256, 14, 14]               0\n",
      "          Conv2d-477         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-478         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-479         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-480         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-481          [-1, 512, 14, 14]         524,288\n",
      "     BatchNorm2d-482          [-1, 512, 14, 14]           1,024\n",
      "            ReLU-483          [-1, 512, 14, 14]               0\n",
      "          Conv2d-484            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-485            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-486            [-1, 512, 7, 7]               0\n",
      "          Conv2d-487           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-488           [-1, 2048, 7, 7]           4,096\n",
      "          Conv2d-489           [-1, 2048, 7, 7]       2,097,152\n",
      "     BatchNorm2d-490           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-491           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-492           [-1, 2048, 7, 7]               0\n",
      "          Conv2d-493            [-1, 512, 7, 7]       1,048,576\n",
      "     BatchNorm2d-494            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-495            [-1, 512, 7, 7]               0\n",
      "          Conv2d-496            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-497            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-498            [-1, 512, 7, 7]               0\n",
      "          Conv2d-499           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-500           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-501           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-502           [-1, 2048, 7, 7]               0\n",
      "          Conv2d-503            [-1, 512, 7, 7]       1,048,576\n",
      "     BatchNorm2d-504            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-505            [-1, 512, 7, 7]               0\n",
      "          Conv2d-506            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-507            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-508            [-1, 512, 7, 7]               0\n",
      "          Conv2d-509           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-510           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-511           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-512           [-1, 2048, 7, 7]               0\n",
      "AdaptiveAvgPool2d-513           [-1, 2048, 1, 1]               0\n",
      "          Linear-514                 [-1, 1000]       2,049,000\n",
      "================================================================\n",
      "Total params: 60,192,808\n",
      "Trainable params: 60,192,808\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 606.59\n",
      "Params size (MB): 229.62\n",
      "Estimated Total Size (MB): 836.78\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(resnet_pretrained, input_size=(3,224,224))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model for classification and regression using transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-10T21:30:48.597458Z",
     "start_time": "2022-12-10T21:30:48.594264Z"
    }
   },
   "outputs": [],
   "source": [
    "class TransferLearningBackbone(nn.Module):\n",
    "    def __init__(self, pretrained_model):\n",
    "        super(TransferLearningBackbone, self).__init__()\n",
    "        self.features = list(pretrained_model.children())[:-1]\n",
    "        self.features = nn.Sequential(*self.features)\n",
    "        self.pooling = pretrained_model.avgpool\n",
    "        self.flatten = nn.Flatten()\n",
    "\n",
    "    def forward(self, x):\n",
    "        out = self.features(x)\n",
    "        out = self.pooling(out)\n",
    "        out = self.flatten(out)\n",
    "        return out "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-10T01:50:40.076956Z",
     "start_time": "2022-12-10T01:50:39.936805Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
      "              ReLU-3         [-1, 64, 112, 112]               0\n",
      "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
      "            Conv2d-5           [-1, 64, 56, 56]           4,096\n",
      "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
      "              ReLU-7           [-1, 64, 56, 56]               0\n",
      "            Conv2d-8           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
      "             ReLU-10           [-1, 64, 56, 56]               0\n",
      "           Conv2d-11          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-12          [-1, 256, 56, 56]             512\n",
      "           Conv2d-13          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-14          [-1, 256, 56, 56]             512\n",
      "             ReLU-15          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-16          [-1, 256, 56, 56]               0\n",
      "           Conv2d-17           [-1, 64, 56, 56]          16,384\n",
      "      BatchNorm2d-18           [-1, 64, 56, 56]             128\n",
      "             ReLU-19           [-1, 64, 56, 56]               0\n",
      "           Conv2d-20           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-21           [-1, 64, 56, 56]             128\n",
      "             ReLU-22           [-1, 64, 56, 56]               0\n",
      "           Conv2d-23          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-24          [-1, 256, 56, 56]             512\n",
      "             ReLU-25          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-26          [-1, 256, 56, 56]               0\n",
      "           Conv2d-27           [-1, 64, 56, 56]          16,384\n",
      "      BatchNorm2d-28           [-1, 64, 56, 56]             128\n",
      "             ReLU-29           [-1, 64, 56, 56]               0\n",
      "           Conv2d-30           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-31           [-1, 64, 56, 56]             128\n",
      "             ReLU-32           [-1, 64, 56, 56]               0\n",
      "           Conv2d-33          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-34          [-1, 256, 56, 56]             512\n",
      "             ReLU-35          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-36          [-1, 256, 56, 56]               0\n",
      "           Conv2d-37          [-1, 128, 56, 56]          32,768\n",
      "      BatchNorm2d-38          [-1, 128, 56, 56]             256\n",
      "             ReLU-39          [-1, 128, 56, 56]               0\n",
      "           Conv2d-40          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-41          [-1, 128, 28, 28]             256\n",
      "             ReLU-42          [-1, 128, 28, 28]               0\n",
      "           Conv2d-43          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-44          [-1, 512, 28, 28]           1,024\n",
      "           Conv2d-45          [-1, 512, 28, 28]         131,072\n",
      "      BatchNorm2d-46          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-47          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-48          [-1, 512, 28, 28]               0\n",
      "           Conv2d-49          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-50          [-1, 128, 28, 28]             256\n",
      "             ReLU-51          [-1, 128, 28, 28]               0\n",
      "           Conv2d-52          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-53          [-1, 128, 28, 28]             256\n",
      "             ReLU-54          [-1, 128, 28, 28]               0\n",
      "           Conv2d-55          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-56          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-57          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-58          [-1, 512, 28, 28]               0\n",
      "           Conv2d-59          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-60          [-1, 128, 28, 28]             256\n",
      "             ReLU-61          [-1, 128, 28, 28]               0\n",
      "           Conv2d-62          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-63          [-1, 128, 28, 28]             256\n",
      "             ReLU-64          [-1, 128, 28, 28]               0\n",
      "           Conv2d-65          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-66          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-67          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-68          [-1, 512, 28, 28]               0\n",
      "           Conv2d-69          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-70          [-1, 128, 28, 28]             256\n",
      "             ReLU-71          [-1, 128, 28, 28]               0\n",
      "           Conv2d-72          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-73          [-1, 128, 28, 28]             256\n",
      "             ReLU-74          [-1, 128, 28, 28]               0\n",
      "           Conv2d-75          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-76          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-77          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-78          [-1, 512, 28, 28]               0\n",
      "           Conv2d-79          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-80          [-1, 128, 28, 28]             256\n",
      "             ReLU-81          [-1, 128, 28, 28]               0\n",
      "           Conv2d-82          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-83          [-1, 128, 28, 28]             256\n",
      "             ReLU-84          [-1, 128, 28, 28]               0\n",
      "           Conv2d-85          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-86          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-87          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-88          [-1, 512, 28, 28]               0\n",
      "           Conv2d-89          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-90          [-1, 128, 28, 28]             256\n",
      "             ReLU-91          [-1, 128, 28, 28]               0\n",
      "           Conv2d-92          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-93          [-1, 128, 28, 28]             256\n",
      "             ReLU-94          [-1, 128, 28, 28]               0\n",
      "           Conv2d-95          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-96          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-97          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-98          [-1, 512, 28, 28]               0\n",
      "           Conv2d-99          [-1, 128, 28, 28]          65,536\n",
      "     BatchNorm2d-100          [-1, 128, 28, 28]             256\n",
      "            ReLU-101          [-1, 128, 28, 28]               0\n",
      "          Conv2d-102          [-1, 128, 28, 28]         147,456\n",
      "     BatchNorm2d-103          [-1, 128, 28, 28]             256\n",
      "            ReLU-104          [-1, 128, 28, 28]               0\n",
      "          Conv2d-105          [-1, 512, 28, 28]          65,536\n",
      "     BatchNorm2d-106          [-1, 512, 28, 28]           1,024\n",
      "            ReLU-107          [-1, 512, 28, 28]               0\n",
      "      Bottleneck-108          [-1, 512, 28, 28]               0\n",
      "          Conv2d-109          [-1, 128, 28, 28]          65,536\n",
      "     BatchNorm2d-110          [-1, 128, 28, 28]             256\n",
      "            ReLU-111          [-1, 128, 28, 28]               0\n",
      "          Conv2d-112          [-1, 128, 28, 28]         147,456\n",
      "     BatchNorm2d-113          [-1, 128, 28, 28]             256\n",
      "            ReLU-114          [-1, 128, 28, 28]               0\n",
      "          Conv2d-115          [-1, 512, 28, 28]          65,536\n",
      "     BatchNorm2d-116          [-1, 512, 28, 28]           1,024\n",
      "            ReLU-117          [-1, 512, 28, 28]               0\n",
      "      Bottleneck-118          [-1, 512, 28, 28]               0\n",
      "          Conv2d-119          [-1, 256, 28, 28]         131,072\n",
      "     BatchNorm2d-120          [-1, 256, 28, 28]             512\n",
      "            ReLU-121          [-1, 256, 28, 28]               0\n",
      "          Conv2d-122          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-123          [-1, 256, 14, 14]             512\n",
      "            ReLU-124          [-1, 256, 14, 14]               0\n",
      "          Conv2d-125         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-126         [-1, 1024, 14, 14]           2,048\n",
      "          Conv2d-127         [-1, 1024, 14, 14]         524,288\n",
      "     BatchNorm2d-128         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-129         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-130         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-131          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-132          [-1, 256, 14, 14]             512\n",
      "            ReLU-133          [-1, 256, 14, 14]               0\n",
      "          Conv2d-134          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-135          [-1, 256, 14, 14]             512\n",
      "            ReLU-136          [-1, 256, 14, 14]               0\n",
      "          Conv2d-137         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-138         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-139         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-140         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-141          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-142          [-1, 256, 14, 14]             512\n",
      "            ReLU-143          [-1, 256, 14, 14]               0\n",
      "          Conv2d-144          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-145          [-1, 256, 14, 14]             512\n",
      "            ReLU-146          [-1, 256, 14, 14]               0\n",
      "          Conv2d-147         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-148         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-149         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-150         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-151          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-152          [-1, 256, 14, 14]             512\n",
      "            ReLU-153          [-1, 256, 14, 14]               0\n",
      "          Conv2d-154          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-155          [-1, 256, 14, 14]             512\n",
      "            ReLU-156          [-1, 256, 14, 14]               0\n",
      "          Conv2d-157         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-158         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-159         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-160         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-161          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-162          [-1, 256, 14, 14]             512\n",
      "            ReLU-163          [-1, 256, 14, 14]               0\n",
      "          Conv2d-164          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-165          [-1, 256, 14, 14]             512\n",
      "            ReLU-166          [-1, 256, 14, 14]               0\n",
      "          Conv2d-167         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-168         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-169         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-170         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-171          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-172          [-1, 256, 14, 14]             512\n",
      "            ReLU-173          [-1, 256, 14, 14]               0\n",
      "          Conv2d-174          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-175          [-1, 256, 14, 14]             512\n",
      "            ReLU-176          [-1, 256, 14, 14]               0\n",
      "          Conv2d-177         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-178         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-179         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-180         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-181          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-182          [-1, 256, 14, 14]             512\n",
      "            ReLU-183          [-1, 256, 14, 14]               0\n",
      "          Conv2d-184          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-185          [-1, 256, 14, 14]             512\n",
      "            ReLU-186          [-1, 256, 14, 14]               0\n",
      "          Conv2d-187         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-188         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-189         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-190         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-191          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-192          [-1, 256, 14, 14]             512\n",
      "            ReLU-193          [-1, 256, 14, 14]               0\n",
      "          Conv2d-194          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-195          [-1, 256, 14, 14]             512\n",
      "            ReLU-196          [-1, 256, 14, 14]               0\n",
      "          Conv2d-197         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-198         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-199         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-200         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-201          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-202          [-1, 256, 14, 14]             512\n",
      "            ReLU-203          [-1, 256, 14, 14]               0\n",
      "          Conv2d-204          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-205          [-1, 256, 14, 14]             512\n",
      "            ReLU-206          [-1, 256, 14, 14]               0\n",
      "          Conv2d-207         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-208         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-209         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-210         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-211          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-212          [-1, 256, 14, 14]             512\n",
      "            ReLU-213          [-1, 256, 14, 14]               0\n",
      "          Conv2d-214          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-215          [-1, 256, 14, 14]             512\n",
      "            ReLU-216          [-1, 256, 14, 14]               0\n",
      "          Conv2d-217         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-218         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-219         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-220         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-221          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-222          [-1, 256, 14, 14]             512\n",
      "            ReLU-223          [-1, 256, 14, 14]               0\n",
      "          Conv2d-224          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-225          [-1, 256, 14, 14]             512\n",
      "            ReLU-226          [-1, 256, 14, 14]               0\n",
      "          Conv2d-227         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-228         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-229         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-230         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-231          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-232          [-1, 256, 14, 14]             512\n",
      "            ReLU-233          [-1, 256, 14, 14]               0\n",
      "          Conv2d-234          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-235          [-1, 256, 14, 14]             512\n",
      "            ReLU-236          [-1, 256, 14, 14]               0\n",
      "          Conv2d-237         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-238         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-239         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-240         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-241          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-242          [-1, 256, 14, 14]             512\n",
      "            ReLU-243          [-1, 256, 14, 14]               0\n",
      "          Conv2d-244          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-245          [-1, 256, 14, 14]             512\n",
      "            ReLU-246          [-1, 256, 14, 14]               0\n",
      "          Conv2d-247         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-248         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-249         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-250         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-251          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-252          [-1, 256, 14, 14]             512\n",
      "            ReLU-253          [-1, 256, 14, 14]               0\n",
      "          Conv2d-254          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-255          [-1, 256, 14, 14]             512\n",
      "            ReLU-256          [-1, 256, 14, 14]               0\n",
      "          Conv2d-257         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-258         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-259         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-260         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-261          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-262          [-1, 256, 14, 14]             512\n",
      "            ReLU-263          [-1, 256, 14, 14]               0\n",
      "          Conv2d-264          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-265          [-1, 256, 14, 14]             512\n",
      "            ReLU-266          [-1, 256, 14, 14]               0\n",
      "          Conv2d-267         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-268         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-269         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-270         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-271          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-272          [-1, 256, 14, 14]             512\n",
      "            ReLU-273          [-1, 256, 14, 14]               0\n",
      "          Conv2d-274          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-275          [-1, 256, 14, 14]             512\n",
      "            ReLU-276          [-1, 256, 14, 14]               0\n",
      "          Conv2d-277         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-278         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-279         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-280         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-281          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-282          [-1, 256, 14, 14]             512\n",
      "            ReLU-283          [-1, 256, 14, 14]               0\n",
      "          Conv2d-284          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-285          [-1, 256, 14, 14]             512\n",
      "            ReLU-286          [-1, 256, 14, 14]               0\n",
      "          Conv2d-287         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-288         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-289         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-290         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-291          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-292          [-1, 256, 14, 14]             512\n",
      "            ReLU-293          [-1, 256, 14, 14]               0\n",
      "          Conv2d-294          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-295          [-1, 256, 14, 14]             512\n",
      "            ReLU-296          [-1, 256, 14, 14]               0\n",
      "          Conv2d-297         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-298         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-299         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-300         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-301          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-302          [-1, 256, 14, 14]             512\n",
      "            ReLU-303          [-1, 256, 14, 14]               0\n",
      "          Conv2d-304          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-305          [-1, 256, 14, 14]             512\n",
      "            ReLU-306          [-1, 256, 14, 14]               0\n",
      "          Conv2d-307         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-308         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-309         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-310         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-311          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-312          [-1, 256, 14, 14]             512\n",
      "            ReLU-313          [-1, 256, 14, 14]               0\n",
      "          Conv2d-314          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-315          [-1, 256, 14, 14]             512\n",
      "            ReLU-316          [-1, 256, 14, 14]               0\n",
      "          Conv2d-317         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-318         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-319         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-320         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-321          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-322          [-1, 256, 14, 14]             512\n",
      "            ReLU-323          [-1, 256, 14, 14]               0\n",
      "          Conv2d-324          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-325          [-1, 256, 14, 14]             512\n",
      "            ReLU-326          [-1, 256, 14, 14]               0\n",
      "          Conv2d-327         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-328         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-329         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-330         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-331          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-332          [-1, 256, 14, 14]             512\n",
      "            ReLU-333          [-1, 256, 14, 14]               0\n",
      "          Conv2d-334          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-335          [-1, 256, 14, 14]             512\n",
      "            ReLU-336          [-1, 256, 14, 14]               0\n",
      "          Conv2d-337         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-338         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-339         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-340         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-341          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-342          [-1, 256, 14, 14]             512\n",
      "            ReLU-343          [-1, 256, 14, 14]               0\n",
      "          Conv2d-344          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-345          [-1, 256, 14, 14]             512\n",
      "            ReLU-346          [-1, 256, 14, 14]               0\n",
      "          Conv2d-347         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-348         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-349         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-350         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-351          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-352          [-1, 256, 14, 14]             512\n",
      "            ReLU-353          [-1, 256, 14, 14]               0\n",
      "          Conv2d-354          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-355          [-1, 256, 14, 14]             512\n",
      "            ReLU-356          [-1, 256, 14, 14]               0\n",
      "          Conv2d-357         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-358         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-359         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-360         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-361          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-362          [-1, 256, 14, 14]             512\n",
      "            ReLU-363          [-1, 256, 14, 14]               0\n",
      "          Conv2d-364          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-365          [-1, 256, 14, 14]             512\n",
      "            ReLU-366          [-1, 256, 14, 14]               0\n",
      "          Conv2d-367         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-368         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-369         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-370         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-371          [-1, 256, 14, 14]         262,144\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     BatchNorm2d-372          [-1, 256, 14, 14]             512\n",
      "            ReLU-373          [-1, 256, 14, 14]               0\n",
      "          Conv2d-374          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-375          [-1, 256, 14, 14]             512\n",
      "            ReLU-376          [-1, 256, 14, 14]               0\n",
      "          Conv2d-377         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-378         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-379         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-380         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-381          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-382          [-1, 256, 14, 14]             512\n",
      "            ReLU-383          [-1, 256, 14, 14]               0\n",
      "          Conv2d-384          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-385          [-1, 256, 14, 14]             512\n",
      "            ReLU-386          [-1, 256, 14, 14]               0\n",
      "          Conv2d-387         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-388         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-389         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-390         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-391          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-392          [-1, 256, 14, 14]             512\n",
      "            ReLU-393          [-1, 256, 14, 14]               0\n",
      "          Conv2d-394          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-395          [-1, 256, 14, 14]             512\n",
      "            ReLU-396          [-1, 256, 14, 14]               0\n",
      "          Conv2d-397         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-398         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-399         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-400         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-401          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-402          [-1, 256, 14, 14]             512\n",
      "            ReLU-403          [-1, 256, 14, 14]               0\n",
      "          Conv2d-404          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-405          [-1, 256, 14, 14]             512\n",
      "            ReLU-406          [-1, 256, 14, 14]               0\n",
      "          Conv2d-407         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-408         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-409         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-410         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-411          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-412          [-1, 256, 14, 14]             512\n",
      "            ReLU-413          [-1, 256, 14, 14]               0\n",
      "          Conv2d-414          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-415          [-1, 256, 14, 14]             512\n",
      "            ReLU-416          [-1, 256, 14, 14]               0\n",
      "          Conv2d-417         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-418         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-419         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-420         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-421          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-422          [-1, 256, 14, 14]             512\n",
      "            ReLU-423          [-1, 256, 14, 14]               0\n",
      "          Conv2d-424          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-425          [-1, 256, 14, 14]             512\n",
      "            ReLU-426          [-1, 256, 14, 14]               0\n",
      "          Conv2d-427         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-428         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-429         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-430         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-431          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-432          [-1, 256, 14, 14]             512\n",
      "            ReLU-433          [-1, 256, 14, 14]               0\n",
      "          Conv2d-434          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-435          [-1, 256, 14, 14]             512\n",
      "            ReLU-436          [-1, 256, 14, 14]               0\n",
      "          Conv2d-437         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-438         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-439         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-440         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-441          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-442          [-1, 256, 14, 14]             512\n",
      "            ReLU-443          [-1, 256, 14, 14]               0\n",
      "          Conv2d-444          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-445          [-1, 256, 14, 14]             512\n",
      "            ReLU-446          [-1, 256, 14, 14]               0\n",
      "          Conv2d-447         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-448         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-449         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-450         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-451          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-452          [-1, 256, 14, 14]             512\n",
      "            ReLU-453          [-1, 256, 14, 14]               0\n",
      "          Conv2d-454          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-455          [-1, 256, 14, 14]             512\n",
      "            ReLU-456          [-1, 256, 14, 14]               0\n",
      "          Conv2d-457         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-458         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-459         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-460         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-461          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-462          [-1, 256, 14, 14]             512\n",
      "            ReLU-463          [-1, 256, 14, 14]               0\n",
      "          Conv2d-464          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-465          [-1, 256, 14, 14]             512\n",
      "            ReLU-466          [-1, 256, 14, 14]               0\n",
      "          Conv2d-467         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-468         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-469         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-470         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-471          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-472          [-1, 256, 14, 14]             512\n",
      "            ReLU-473          [-1, 256, 14, 14]               0\n",
      "          Conv2d-474          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-475          [-1, 256, 14, 14]             512\n",
      "            ReLU-476          [-1, 256, 14, 14]               0\n",
      "          Conv2d-477         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-478         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-479         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-480         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-481          [-1, 512, 14, 14]         524,288\n",
      "     BatchNorm2d-482          [-1, 512, 14, 14]           1,024\n",
      "            ReLU-483          [-1, 512, 14, 14]               0\n",
      "          Conv2d-484            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-485            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-486            [-1, 512, 7, 7]               0\n",
      "          Conv2d-487           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-488           [-1, 2048, 7, 7]           4,096\n",
      "          Conv2d-489           [-1, 2048, 7, 7]       2,097,152\n",
      "     BatchNorm2d-490           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-491           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-492           [-1, 2048, 7, 7]               0\n",
      "          Conv2d-493            [-1, 512, 7, 7]       1,048,576\n",
      "     BatchNorm2d-494            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-495            [-1, 512, 7, 7]               0\n",
      "          Conv2d-496            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-497            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-498            [-1, 512, 7, 7]               0\n",
      "          Conv2d-499           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-500           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-501           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-502           [-1, 2048, 7, 7]               0\n",
      "          Conv2d-503            [-1, 512, 7, 7]       1,048,576\n",
      "     BatchNorm2d-504            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-505            [-1, 512, 7, 7]               0\n",
      "          Conv2d-506            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-507            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-508            [-1, 512, 7, 7]               0\n",
      "          Conv2d-509           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-510           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-511           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-512           [-1, 2048, 7, 7]               0\n",
      "AdaptiveAvgPool2d-513           [-1, 2048, 1, 1]               0\n",
      "AdaptiveAvgPool2d-514           [-1, 2048, 1, 1]               0\n",
      "AdaptiveAvgPool2d-515           [-1, 2048, 1, 1]               0\n",
      "AdaptiveAvgPool2d-516           [-1, 2048, 1, 1]               0\n",
      "         Flatten-517                 [-1, 2048]               0\n",
      "================================================================\n",
      "Total params: 58,143,808\n",
      "Trainable params: 58,143,808\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 606.64\n",
      "Params size (MB): 221.80\n",
      "Estimated Total Size (MB): 829.02\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "resnet_backbone = TransferLearningBackbone(resnet_pretrained).to(device)\n",
    "summary(resnet_backbone, input_size=(3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-10T01:50:40.080359Z",
     "start_time": "2022-12-10T01:50:40.078450Z"
    }
   },
   "outputs": [],
   "source": [
    "resnet_backbone_output_shape = 2048"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-10T01:50:40.084791Z",
     "start_time": "2022-12-10T01:50:40.081571Z"
    }
   },
   "outputs": [],
   "source": [
    "class ResNetClassifier(nn.Module):\n",
    "    def __init__(self, input_size: int, n_classes: int):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.n_classes = n_classes\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(in_features = self.input_size, out_features=1024), # Shape transformation: (2.048) -> (1.024)\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(in_features = 1024, out_features=128), # Shape transformation: (1.024) -> (128)\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(in_features = 128, out_features = self.n_classes), # Shape transformation: (128) -> (10)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 57,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-10T01:50:40.100868Z",
     "start_time": "2022-12-10T01:50:40.085932Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "           Dropout-1                 [-1, 2048]               0\n",
      "            Linear-2                 [-1, 1024]       2,098,176\n",
      "       BatchNorm1d-3                 [-1, 1024]           2,048\n",
      "           Dropout-4                 [-1, 1024]               0\n",
      "            Linear-5                  [-1, 128]         131,200\n",
      "       BatchNorm1d-6                  [-1, 128]             256\n",
      "           Dropout-7                  [-1, 128]               0\n",
      "            Linear-8                   [-1, 10]           1,290\n",
      "================================================================\n",
      "Total params: 2,232,970\n",
      "Trainable params: 2,232,970\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 0.04\n",
      "Params size (MB): 8.52\n",
      "Estimated Total Size (MB): 8.57\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "resnet_classifier = ResNetClassifier(input_size=resnet_backbone_output_shape, n_classes=config_dict['num_classes']).to(device)\n",
    "summary(resnet_classifier, input_size=(resnet_backbone_output_shape,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-10T01:50:40.106677Z",
     "start_time": "2022-12-10T01:50:40.103193Z"
    }
   },
   "outputs": [],
   "source": [
    "class ResNetRegressor(nn.Module):\n",
    "    def __init__(self, input_size: int):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(in_features = self.input_size, out_features=1024), # Shape transformation: (2048) -> (1024)\n",
    "            nn.BatchNorm1d(1024),\n",
    "            # nn.Dropout(0.4),\n",
    "            nn.Linear(in_features = 1024, out_features=512), # Shape transformation: (1024) -> (512)\n",
    "            nn.BatchNorm1d(512),\n",
    "            # nn.Dropout(0.4),\n",
    "            nn.Linear(in_features = 512, out_features=256), # Shape transformation: (512) -> (256)\n",
    "            nn.BatchNorm1d(256),\n",
    "            # nn.Dropout(0.4),\n",
    "            nn.Linear(in_features = 256, out_features=128), # Shape transformation: (256) -> (128)\n",
    "            nn.BatchNorm1d(128),\n",
    "            # nn.Dropout(0.4),\n",
    "            nn.Linear(in_features = 128, out_features = 4), # Shape transformation: (128) -> (4)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-10T01:50:40.126656Z",
     "start_time": "2022-12-10T01:50:40.108008Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "           Dropout-1                 [-1, 2048]               0\n",
      "            Linear-2                 [-1, 1024]       2,098,176\n",
      "       BatchNorm1d-3                 [-1, 1024]           2,048\n",
      "           Dropout-4                 [-1, 1024]               0\n",
      "            Linear-5                  [-1, 128]         131,200\n",
      "       BatchNorm1d-6                  [-1, 128]             256\n",
      "           Dropout-7                  [-1, 128]               0\n",
      "            Linear-8                   [-1, 10]           1,290\n",
      "================================================================\n",
      "Total params: 2,232,970\n",
      "Trainable params: 2,232,970\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.01\n",
      "Forward/backward pass size (MB): 0.04\n",
      "Params size (MB): 8.52\n",
      "Estimated Total Size (MB): 8.57\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "resnet_regressor = ResNetRegressor(input_size=resnet_backbone_output_shape).to(device)\n",
    "summary(resnet_classifier, input_size=(resnet_backbone_output_shape,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-09T23:02:36.376480Z",
     "start_time": "2022-12-09T23:02:36.373097Z"
    }
   },
   "source": [
    "Definimos nuestro modelo para la clasificación y la regresion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-10T01:50:40.258800Z",
     "start_time": "2022-12-10T01:50:40.127718Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1         [-1, 64, 112, 112]           9,408\n",
      "       BatchNorm2d-2         [-1, 64, 112, 112]             128\n",
      "              ReLU-3         [-1, 64, 112, 112]               0\n",
      "         MaxPool2d-4           [-1, 64, 56, 56]               0\n",
      "            Conv2d-5           [-1, 64, 56, 56]           4,096\n",
      "       BatchNorm2d-6           [-1, 64, 56, 56]             128\n",
      "              ReLU-7           [-1, 64, 56, 56]               0\n",
      "            Conv2d-8           [-1, 64, 56, 56]          36,864\n",
      "       BatchNorm2d-9           [-1, 64, 56, 56]             128\n",
      "             ReLU-10           [-1, 64, 56, 56]               0\n",
      "           Conv2d-11          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-12          [-1, 256, 56, 56]             512\n",
      "           Conv2d-13          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-14          [-1, 256, 56, 56]             512\n",
      "             ReLU-15          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-16          [-1, 256, 56, 56]               0\n",
      "           Conv2d-17           [-1, 64, 56, 56]          16,384\n",
      "      BatchNorm2d-18           [-1, 64, 56, 56]             128\n",
      "             ReLU-19           [-1, 64, 56, 56]               0\n",
      "           Conv2d-20           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-21           [-1, 64, 56, 56]             128\n",
      "             ReLU-22           [-1, 64, 56, 56]               0\n",
      "           Conv2d-23          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-24          [-1, 256, 56, 56]             512\n",
      "             ReLU-25          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-26          [-1, 256, 56, 56]               0\n",
      "           Conv2d-27           [-1, 64, 56, 56]          16,384\n",
      "      BatchNorm2d-28           [-1, 64, 56, 56]             128\n",
      "             ReLU-29           [-1, 64, 56, 56]               0\n",
      "           Conv2d-30           [-1, 64, 56, 56]          36,864\n",
      "      BatchNorm2d-31           [-1, 64, 56, 56]             128\n",
      "             ReLU-32           [-1, 64, 56, 56]               0\n",
      "           Conv2d-33          [-1, 256, 56, 56]          16,384\n",
      "      BatchNorm2d-34          [-1, 256, 56, 56]             512\n",
      "             ReLU-35          [-1, 256, 56, 56]               0\n",
      "       Bottleneck-36          [-1, 256, 56, 56]               0\n",
      "           Conv2d-37          [-1, 128, 56, 56]          32,768\n",
      "      BatchNorm2d-38          [-1, 128, 56, 56]             256\n",
      "             ReLU-39          [-1, 128, 56, 56]               0\n",
      "           Conv2d-40          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-41          [-1, 128, 28, 28]             256\n",
      "             ReLU-42          [-1, 128, 28, 28]               0\n",
      "           Conv2d-43          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-44          [-1, 512, 28, 28]           1,024\n",
      "           Conv2d-45          [-1, 512, 28, 28]         131,072\n",
      "      BatchNorm2d-46          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-47          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-48          [-1, 512, 28, 28]               0\n",
      "           Conv2d-49          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-50          [-1, 128, 28, 28]             256\n",
      "             ReLU-51          [-1, 128, 28, 28]               0\n",
      "           Conv2d-52          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-53          [-1, 128, 28, 28]             256\n",
      "             ReLU-54          [-1, 128, 28, 28]               0\n",
      "           Conv2d-55          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-56          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-57          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-58          [-1, 512, 28, 28]               0\n",
      "           Conv2d-59          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-60          [-1, 128, 28, 28]             256\n",
      "             ReLU-61          [-1, 128, 28, 28]               0\n",
      "           Conv2d-62          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-63          [-1, 128, 28, 28]             256\n",
      "             ReLU-64          [-1, 128, 28, 28]               0\n",
      "           Conv2d-65          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-66          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-67          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-68          [-1, 512, 28, 28]               0\n",
      "           Conv2d-69          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-70          [-1, 128, 28, 28]             256\n",
      "             ReLU-71          [-1, 128, 28, 28]               0\n",
      "           Conv2d-72          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-73          [-1, 128, 28, 28]             256\n",
      "             ReLU-74          [-1, 128, 28, 28]               0\n",
      "           Conv2d-75          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-76          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-77          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-78          [-1, 512, 28, 28]               0\n",
      "           Conv2d-79          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-80          [-1, 128, 28, 28]             256\n",
      "             ReLU-81          [-1, 128, 28, 28]               0\n",
      "           Conv2d-82          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-83          [-1, 128, 28, 28]             256\n",
      "             ReLU-84          [-1, 128, 28, 28]               0\n",
      "           Conv2d-85          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-86          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-87          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-88          [-1, 512, 28, 28]               0\n",
      "           Conv2d-89          [-1, 128, 28, 28]          65,536\n",
      "      BatchNorm2d-90          [-1, 128, 28, 28]             256\n",
      "             ReLU-91          [-1, 128, 28, 28]               0\n",
      "           Conv2d-92          [-1, 128, 28, 28]         147,456\n",
      "      BatchNorm2d-93          [-1, 128, 28, 28]             256\n",
      "             ReLU-94          [-1, 128, 28, 28]               0\n",
      "           Conv2d-95          [-1, 512, 28, 28]          65,536\n",
      "      BatchNorm2d-96          [-1, 512, 28, 28]           1,024\n",
      "             ReLU-97          [-1, 512, 28, 28]               0\n",
      "       Bottleneck-98          [-1, 512, 28, 28]               0\n",
      "           Conv2d-99          [-1, 128, 28, 28]          65,536\n",
      "     BatchNorm2d-100          [-1, 128, 28, 28]             256\n",
      "            ReLU-101          [-1, 128, 28, 28]               0\n",
      "          Conv2d-102          [-1, 128, 28, 28]         147,456\n",
      "     BatchNorm2d-103          [-1, 128, 28, 28]             256\n",
      "            ReLU-104          [-1, 128, 28, 28]               0\n",
      "          Conv2d-105          [-1, 512, 28, 28]          65,536\n",
      "     BatchNorm2d-106          [-1, 512, 28, 28]           1,024\n",
      "            ReLU-107          [-1, 512, 28, 28]               0\n",
      "      Bottleneck-108          [-1, 512, 28, 28]               0\n",
      "          Conv2d-109          [-1, 128, 28, 28]          65,536\n",
      "     BatchNorm2d-110          [-1, 128, 28, 28]             256\n",
      "            ReLU-111          [-1, 128, 28, 28]               0\n",
      "          Conv2d-112          [-1, 128, 28, 28]         147,456\n",
      "     BatchNorm2d-113          [-1, 128, 28, 28]             256\n",
      "            ReLU-114          [-1, 128, 28, 28]               0\n",
      "          Conv2d-115          [-1, 512, 28, 28]          65,536\n",
      "     BatchNorm2d-116          [-1, 512, 28, 28]           1,024\n",
      "            ReLU-117          [-1, 512, 28, 28]               0\n",
      "      Bottleneck-118          [-1, 512, 28, 28]               0\n",
      "          Conv2d-119          [-1, 256, 28, 28]         131,072\n",
      "     BatchNorm2d-120          [-1, 256, 28, 28]             512\n",
      "            ReLU-121          [-1, 256, 28, 28]               0\n",
      "          Conv2d-122          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-123          [-1, 256, 14, 14]             512\n",
      "            ReLU-124          [-1, 256, 14, 14]               0\n",
      "          Conv2d-125         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-126         [-1, 1024, 14, 14]           2,048\n",
      "          Conv2d-127         [-1, 1024, 14, 14]         524,288\n",
      "     BatchNorm2d-128         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-129         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-130         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-131          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-132          [-1, 256, 14, 14]             512\n",
      "            ReLU-133          [-1, 256, 14, 14]               0\n",
      "          Conv2d-134          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-135          [-1, 256, 14, 14]             512\n",
      "            ReLU-136          [-1, 256, 14, 14]               0\n",
      "          Conv2d-137         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-138         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-139         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-140         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-141          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-142          [-1, 256, 14, 14]             512\n",
      "            ReLU-143          [-1, 256, 14, 14]               0\n",
      "          Conv2d-144          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-145          [-1, 256, 14, 14]             512\n",
      "            ReLU-146          [-1, 256, 14, 14]               0\n",
      "          Conv2d-147         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-148         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-149         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-150         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-151          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-152          [-1, 256, 14, 14]             512\n",
      "            ReLU-153          [-1, 256, 14, 14]               0\n",
      "          Conv2d-154          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-155          [-1, 256, 14, 14]             512\n",
      "            ReLU-156          [-1, 256, 14, 14]               0\n",
      "          Conv2d-157         [-1, 1024, 14, 14]         262,144\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     BatchNorm2d-158         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-159         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-160         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-161          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-162          [-1, 256, 14, 14]             512\n",
      "            ReLU-163          [-1, 256, 14, 14]               0\n",
      "          Conv2d-164          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-165          [-1, 256, 14, 14]             512\n",
      "            ReLU-166          [-1, 256, 14, 14]               0\n",
      "          Conv2d-167         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-168         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-169         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-170         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-171          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-172          [-1, 256, 14, 14]             512\n",
      "            ReLU-173          [-1, 256, 14, 14]               0\n",
      "          Conv2d-174          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-175          [-1, 256, 14, 14]             512\n",
      "            ReLU-176          [-1, 256, 14, 14]               0\n",
      "          Conv2d-177         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-178         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-179         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-180         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-181          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-182          [-1, 256, 14, 14]             512\n",
      "            ReLU-183          [-1, 256, 14, 14]               0\n",
      "          Conv2d-184          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-185          [-1, 256, 14, 14]             512\n",
      "            ReLU-186          [-1, 256, 14, 14]               0\n",
      "          Conv2d-187         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-188         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-189         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-190         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-191          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-192          [-1, 256, 14, 14]             512\n",
      "            ReLU-193          [-1, 256, 14, 14]               0\n",
      "          Conv2d-194          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-195          [-1, 256, 14, 14]             512\n",
      "            ReLU-196          [-1, 256, 14, 14]               0\n",
      "          Conv2d-197         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-198         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-199         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-200         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-201          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-202          [-1, 256, 14, 14]             512\n",
      "            ReLU-203          [-1, 256, 14, 14]               0\n",
      "          Conv2d-204          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-205          [-1, 256, 14, 14]             512\n",
      "            ReLU-206          [-1, 256, 14, 14]               0\n",
      "          Conv2d-207         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-208         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-209         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-210         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-211          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-212          [-1, 256, 14, 14]             512\n",
      "            ReLU-213          [-1, 256, 14, 14]               0\n",
      "          Conv2d-214          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-215          [-1, 256, 14, 14]             512\n",
      "            ReLU-216          [-1, 256, 14, 14]               0\n",
      "          Conv2d-217         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-218         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-219         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-220         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-221          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-222          [-1, 256, 14, 14]             512\n",
      "            ReLU-223          [-1, 256, 14, 14]               0\n",
      "          Conv2d-224          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-225          [-1, 256, 14, 14]             512\n",
      "            ReLU-226          [-1, 256, 14, 14]               0\n",
      "          Conv2d-227         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-228         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-229         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-230         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-231          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-232          [-1, 256, 14, 14]             512\n",
      "            ReLU-233          [-1, 256, 14, 14]               0\n",
      "          Conv2d-234          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-235          [-1, 256, 14, 14]             512\n",
      "            ReLU-236          [-1, 256, 14, 14]               0\n",
      "          Conv2d-237         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-238         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-239         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-240         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-241          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-242          [-1, 256, 14, 14]             512\n",
      "            ReLU-243          [-1, 256, 14, 14]               0\n",
      "          Conv2d-244          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-245          [-1, 256, 14, 14]             512\n",
      "            ReLU-246          [-1, 256, 14, 14]               0\n",
      "          Conv2d-247         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-248         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-249         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-250         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-251          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-252          [-1, 256, 14, 14]             512\n",
      "            ReLU-253          [-1, 256, 14, 14]               0\n",
      "          Conv2d-254          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-255          [-1, 256, 14, 14]             512\n",
      "            ReLU-256          [-1, 256, 14, 14]               0\n",
      "          Conv2d-257         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-258         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-259         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-260         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-261          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-262          [-1, 256, 14, 14]             512\n",
      "            ReLU-263          [-1, 256, 14, 14]               0\n",
      "          Conv2d-264          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-265          [-1, 256, 14, 14]             512\n",
      "            ReLU-266          [-1, 256, 14, 14]               0\n",
      "          Conv2d-267         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-268         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-269         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-270         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-271          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-272          [-1, 256, 14, 14]             512\n",
      "            ReLU-273          [-1, 256, 14, 14]               0\n",
      "          Conv2d-274          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-275          [-1, 256, 14, 14]             512\n",
      "            ReLU-276          [-1, 256, 14, 14]               0\n",
      "          Conv2d-277         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-278         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-279         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-280         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-281          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-282          [-1, 256, 14, 14]             512\n",
      "            ReLU-283          [-1, 256, 14, 14]               0\n",
      "          Conv2d-284          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-285          [-1, 256, 14, 14]             512\n",
      "            ReLU-286          [-1, 256, 14, 14]               0\n",
      "          Conv2d-287         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-288         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-289         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-290         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-291          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-292          [-1, 256, 14, 14]             512\n",
      "            ReLU-293          [-1, 256, 14, 14]               0\n",
      "          Conv2d-294          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-295          [-1, 256, 14, 14]             512\n",
      "            ReLU-296          [-1, 256, 14, 14]               0\n",
      "          Conv2d-297         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-298         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-299         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-300         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-301          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-302          [-1, 256, 14, 14]             512\n",
      "            ReLU-303          [-1, 256, 14, 14]               0\n",
      "          Conv2d-304          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-305          [-1, 256, 14, 14]             512\n",
      "            ReLU-306          [-1, 256, 14, 14]               0\n",
      "          Conv2d-307         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-308         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-309         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-310         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-311          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-312          [-1, 256, 14, 14]             512\n",
      "            ReLU-313          [-1, 256, 14, 14]               0\n",
      "          Conv2d-314          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-315          [-1, 256, 14, 14]             512\n",
      "            ReLU-316          [-1, 256, 14, 14]               0\n",
      "          Conv2d-317         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-318         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-319         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-320         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-321          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-322          [-1, 256, 14, 14]             512\n",
      "            ReLU-323          [-1, 256, 14, 14]               0\n",
      "          Conv2d-324          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-325          [-1, 256, 14, 14]             512\n",
      "            ReLU-326          [-1, 256, 14, 14]               0\n",
      "          Conv2d-327         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-328         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-329         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-330         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-331          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-332          [-1, 256, 14, 14]             512\n",
      "            ReLU-333          [-1, 256, 14, 14]               0\n",
      "          Conv2d-334          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-335          [-1, 256, 14, 14]             512\n",
      "            ReLU-336          [-1, 256, 14, 14]               0\n",
      "          Conv2d-337         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-338         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-339         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-340         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-341          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-342          [-1, 256, 14, 14]             512\n",
      "            ReLU-343          [-1, 256, 14, 14]               0\n",
      "          Conv2d-344          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-345          [-1, 256, 14, 14]             512\n",
      "            ReLU-346          [-1, 256, 14, 14]               0\n",
      "          Conv2d-347         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-348         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-349         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-350         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-351          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-352          [-1, 256, 14, 14]             512\n",
      "            ReLU-353          [-1, 256, 14, 14]               0\n",
      "          Conv2d-354          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-355          [-1, 256, 14, 14]             512\n",
      "            ReLU-356          [-1, 256, 14, 14]               0\n",
      "          Conv2d-357         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-358         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-359         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-360         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-361          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-362          [-1, 256, 14, 14]             512\n",
      "            ReLU-363          [-1, 256, 14, 14]               0\n",
      "          Conv2d-364          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-365          [-1, 256, 14, 14]             512\n",
      "            ReLU-366          [-1, 256, 14, 14]               0\n",
      "          Conv2d-367         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-368         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-369         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-370         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-371          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-372          [-1, 256, 14, 14]             512\n",
      "            ReLU-373          [-1, 256, 14, 14]               0\n",
      "          Conv2d-374          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-375          [-1, 256, 14, 14]             512\n",
      "            ReLU-376          [-1, 256, 14, 14]               0\n",
      "          Conv2d-377         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-378         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-379         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-380         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-381          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-382          [-1, 256, 14, 14]             512\n",
      "            ReLU-383          [-1, 256, 14, 14]               0\n",
      "          Conv2d-384          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-385          [-1, 256, 14, 14]             512\n",
      "            ReLU-386          [-1, 256, 14, 14]               0\n",
      "          Conv2d-387         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-388         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-389         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-390         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-391          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-392          [-1, 256, 14, 14]             512\n",
      "            ReLU-393          [-1, 256, 14, 14]               0\n",
      "          Conv2d-394          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-395          [-1, 256, 14, 14]             512\n",
      "            ReLU-396          [-1, 256, 14, 14]               0\n",
      "          Conv2d-397         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-398         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-399         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-400         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-401          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-402          [-1, 256, 14, 14]             512\n",
      "            ReLU-403          [-1, 256, 14, 14]               0\n",
      "          Conv2d-404          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-405          [-1, 256, 14, 14]             512\n",
      "            ReLU-406          [-1, 256, 14, 14]               0\n",
      "          Conv2d-407         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-408         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-409         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-410         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-411          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-412          [-1, 256, 14, 14]             512\n",
      "            ReLU-413          [-1, 256, 14, 14]               0\n",
      "          Conv2d-414          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-415          [-1, 256, 14, 14]             512\n",
      "            ReLU-416          [-1, 256, 14, 14]               0\n",
      "          Conv2d-417         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-418         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-419         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-420         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-421          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-422          [-1, 256, 14, 14]             512\n",
      "            ReLU-423          [-1, 256, 14, 14]               0\n",
      "          Conv2d-424          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-425          [-1, 256, 14, 14]             512\n",
      "            ReLU-426          [-1, 256, 14, 14]               0\n",
      "          Conv2d-427         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-428         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-429         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-430         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-431          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-432          [-1, 256, 14, 14]             512\n",
      "            ReLU-433          [-1, 256, 14, 14]               0\n",
      "          Conv2d-434          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-435          [-1, 256, 14, 14]             512\n",
      "            ReLU-436          [-1, 256, 14, 14]               0\n",
      "          Conv2d-437         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-438         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-439         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-440         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-441          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-442          [-1, 256, 14, 14]             512\n",
      "            ReLU-443          [-1, 256, 14, 14]               0\n",
      "          Conv2d-444          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-445          [-1, 256, 14, 14]             512\n",
      "            ReLU-446          [-1, 256, 14, 14]               0\n",
      "          Conv2d-447         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-448         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-449         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-450         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-451          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-452          [-1, 256, 14, 14]             512\n",
      "            ReLU-453          [-1, 256, 14, 14]               0\n",
      "          Conv2d-454          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-455          [-1, 256, 14, 14]             512\n",
      "            ReLU-456          [-1, 256, 14, 14]               0\n",
      "          Conv2d-457         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-458         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-459         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-460         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-461          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-462          [-1, 256, 14, 14]             512\n",
      "            ReLU-463          [-1, 256, 14, 14]               0\n",
      "          Conv2d-464          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-465          [-1, 256, 14, 14]             512\n",
      "            ReLU-466          [-1, 256, 14, 14]               0\n",
      "          Conv2d-467         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-468         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-469         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-470         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-471          [-1, 256, 14, 14]         262,144\n",
      "     BatchNorm2d-472          [-1, 256, 14, 14]             512\n",
      "            ReLU-473          [-1, 256, 14, 14]               0\n",
      "          Conv2d-474          [-1, 256, 14, 14]         589,824\n",
      "     BatchNorm2d-475          [-1, 256, 14, 14]             512\n",
      "            ReLU-476          [-1, 256, 14, 14]               0\n",
      "          Conv2d-477         [-1, 1024, 14, 14]         262,144\n",
      "     BatchNorm2d-478         [-1, 1024, 14, 14]           2,048\n",
      "            ReLU-479         [-1, 1024, 14, 14]               0\n",
      "      Bottleneck-480         [-1, 1024, 14, 14]               0\n",
      "          Conv2d-481          [-1, 512, 14, 14]         524,288\n",
      "     BatchNorm2d-482          [-1, 512, 14, 14]           1,024\n",
      "            ReLU-483          [-1, 512, 14, 14]               0\n",
      "          Conv2d-484            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-485            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-486            [-1, 512, 7, 7]               0\n",
      "          Conv2d-487           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-488           [-1, 2048, 7, 7]           4,096\n",
      "          Conv2d-489           [-1, 2048, 7, 7]       2,097,152\n",
      "     BatchNorm2d-490           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-491           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-492           [-1, 2048, 7, 7]               0\n",
      "          Conv2d-493            [-1, 512, 7, 7]       1,048,576\n",
      "     BatchNorm2d-494            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-495            [-1, 512, 7, 7]               0\n",
      "          Conv2d-496            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-497            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-498            [-1, 512, 7, 7]               0\n",
      "          Conv2d-499           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-500           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-501           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-502           [-1, 2048, 7, 7]               0\n",
      "          Conv2d-503            [-1, 512, 7, 7]       1,048,576\n",
      "     BatchNorm2d-504            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-505            [-1, 512, 7, 7]               0\n",
      "          Conv2d-506            [-1, 512, 7, 7]       2,359,296\n",
      "     BatchNorm2d-507            [-1, 512, 7, 7]           1,024\n",
      "            ReLU-508            [-1, 512, 7, 7]               0\n",
      "          Conv2d-509           [-1, 2048, 7, 7]       1,048,576\n",
      "     BatchNorm2d-510           [-1, 2048, 7, 7]           4,096\n",
      "            ReLU-511           [-1, 2048, 7, 7]               0\n",
      "      Bottleneck-512           [-1, 2048, 7, 7]               0\n",
      "AdaptiveAvgPool2d-513           [-1, 2048, 1, 1]               0\n",
      "AdaptiveAvgPool2d-514           [-1, 2048, 1, 1]               0\n",
      "AdaptiveAvgPool2d-515           [-1, 2048, 1, 1]               0\n",
      "AdaptiveAvgPool2d-516           [-1, 2048, 1, 1]               0\n",
      "         Flatten-517                 [-1, 2048]               0\n",
      "TransferLearningBackbone-518                 [-1, 2048]               0\n",
      "         Dropout-519                 [-1, 2048]               0\n",
      "          Linear-520                 [-1, 1024]       2,098,176\n",
      "     BatchNorm1d-521                 [-1, 1024]           2,048\n",
      "         Dropout-522                 [-1, 1024]               0\n",
      "          Linear-523                  [-1, 128]         131,200\n",
      "     BatchNorm1d-524                  [-1, 128]             256\n",
      "         Dropout-525                  [-1, 128]               0\n",
      "          Linear-526                   [-1, 10]           1,290\n",
      "ResNetClassifier-527                   [-1, 10]               0\n",
      "          Linear-528                 [-1, 1024]       2,098,176\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "     BatchNorm1d-529                 [-1, 1024]           2,048\n",
      "          Linear-530                  [-1, 512]         524,800\n",
      "     BatchNorm1d-531                  [-1, 512]           1,024\n",
      "          Linear-532                  [-1, 256]         131,328\n",
      "     BatchNorm1d-533                  [-1, 256]             512\n",
      "          Linear-534                  [-1, 128]          32,896\n",
      "     BatchNorm1d-535                  [-1, 128]             256\n",
      "          Linear-536                    [-1, 4]             516\n",
      " ResNetRegressor-537                    [-1, 4]               0\n",
      "================================================================\n",
      "Total params: 63,168,334\n",
      "Trainable params: 63,168,334\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 606.73\n",
      "Params size (MB): 240.97\n",
      "Estimated Total Size (MB): 848.27\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "restnet_model = Model(backbone=resnet_backbone, classifier=resnet_classifier, regressor=resnet_regressor).to(device)\n",
    "summary(restnet_model, input_size=(3, 224, 224))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_ds = MNISTDataset(train_df, gray=False, root_dir=config_dict['train_images_dir'], transform=train_transforms)\n",
    "test_ds = MNISTDataset(test_df, gray=False, root_dir=config_dict['train_images_dir'], transform=eval_transforms)\n",
    "\n",
    "train_data = DataLoader(train_ds, batch_size=config_dict['batch_size'], shuffle=True, num_workers=cpu_count())\n",
    "test_data = DataLoader(test_ds, batch_size=config_dict['batch_size'], num_workers=cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_result = train(\n",
    "    restnet_model,\n",
    "    optimizer,\n",
    "    train_data,\n",
    "    eval_datasets=[('val', test_data)],\n",
    "    loss_fn=loss_fn,\n",
    "    metrics={\n",
    "        'bbox': [('iou', iou)],\n",
    "        'class_id': [('accuracy', accuracy)]\n",
    "    },\n",
    "    callbacks=[printer],\n",
    "    device=device,\n",
    "    train_steps=config_dict['num_epochs'],\n",
    "    eval_steps=5,\n",
    ")\n",
    "\n",
    "model = train_result['model']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AlexNet"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-10T21:29:52.842761Z",
     "start_time": "2022-12-10T21:29:35.244077Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Downloading: \"https://download.pytorch.org/models/alexnet-owt-7be5be79.pth\" to /root/.cache/torch/hub/checkpoints/alexnet-owt-7be5be79.pth\n"
     ]
    },
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "112657d47da0446bb394594800f491f0",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "  0%|          | 0.00/233M [00:00<?, ?B/s]"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "alexnet_pretrained = alexnet(pretrained=True, progress=True).to(device)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-10T21:29:52.890785Z",
     "start_time": "2022-12-10T21:29:52.867533Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 55, 55]          23,296\n",
      "              ReLU-2           [-1, 64, 55, 55]               0\n",
      "         MaxPool2d-3           [-1, 64, 27, 27]               0\n",
      "            Conv2d-4          [-1, 192, 27, 27]         307,392\n",
      "              ReLU-5          [-1, 192, 27, 27]               0\n",
      "         MaxPool2d-6          [-1, 192, 13, 13]               0\n",
      "            Conv2d-7          [-1, 384, 13, 13]         663,936\n",
      "              ReLU-8          [-1, 384, 13, 13]               0\n",
      "            Conv2d-9          [-1, 256, 13, 13]         884,992\n",
      "             ReLU-10          [-1, 256, 13, 13]               0\n",
      "           Conv2d-11          [-1, 256, 13, 13]         590,080\n",
      "             ReLU-12          [-1, 256, 13, 13]               0\n",
      "        MaxPool2d-13            [-1, 256, 6, 6]               0\n",
      "AdaptiveAvgPool2d-14            [-1, 256, 6, 6]               0\n",
      "          Dropout-15                 [-1, 9216]               0\n",
      "           Linear-16                 [-1, 4096]      37,752,832\n",
      "             ReLU-17                 [-1, 4096]               0\n",
      "          Dropout-18                 [-1, 4096]               0\n",
      "           Linear-19                 [-1, 4096]      16,781,312\n",
      "             ReLU-20                 [-1, 4096]               0\n",
      "           Linear-21                 [-1, 1000]       4,097,000\n",
      "================================================================\n",
      "Total params: 61,100,840\n",
      "Trainable params: 61,100,840\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 8.38\n",
      "Params size (MB): 233.08\n",
      "Estimated Total Size (MB): 242.03\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "summary(alexnet_pretrained, input_size=(3,224,224))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Model for classification and regression using transfer learning"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-10T21:32:24.675231Z",
     "start_time": "2022-12-10T21:32:24.665027Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 55, 55]          23,296\n",
      "              ReLU-2           [-1, 64, 55, 55]               0\n",
      "         MaxPool2d-3           [-1, 64, 27, 27]               0\n",
      "            Conv2d-4          [-1, 192, 27, 27]         307,392\n",
      "              ReLU-5          [-1, 192, 27, 27]               0\n",
      "         MaxPool2d-6          [-1, 192, 13, 13]               0\n",
      "            Conv2d-7          [-1, 384, 13, 13]         663,936\n",
      "              ReLU-8          [-1, 384, 13, 13]               0\n",
      "            Conv2d-9          [-1, 256, 13, 13]         884,992\n",
      "             ReLU-10          [-1, 256, 13, 13]               0\n",
      "           Conv2d-11          [-1, 256, 13, 13]         590,080\n",
      "             ReLU-12          [-1, 256, 13, 13]               0\n",
      "        MaxPool2d-13            [-1, 256, 6, 6]               0\n",
      "AdaptiveAvgPool2d-14            [-1, 256, 6, 6]               0\n",
      "AdaptiveAvgPool2d-15            [-1, 256, 6, 6]               0\n",
      "AdaptiveAvgPool2d-16            [-1, 256, 6, 6]               0\n",
      "AdaptiveAvgPool2d-17            [-1, 256, 6, 6]               0\n",
      "          Flatten-18                 [-1, 9216]               0\n",
      "================================================================\n",
      "Total params: 2,469,696\n",
      "Trainable params: 2,469,696\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 8.43\n",
      "Params size (MB): 9.42\n",
      "Estimated Total Size (MB): 18.42\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "alexnet_backbone = TransferLearningBackbone(alexnet_pretrained).to(device)\n",
    "summary(alexnet_backbone, input_size=(3, 224, 224))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 56,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-10T21:37:12.407522Z",
     "start_time": "2022-12-10T21:37:12.405743Z"
    }
   },
   "outputs": [],
   "source": [
    "alexnet_backbone_output_shape = 9216"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 58,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-10T21:37:29.671243Z",
     "start_time": "2022-12-10T21:37:29.667383Z"
    }
   },
   "outputs": [],
   "source": [
    "class AlexNetClassifier(nn.Module):\n",
    "    def __init__(self, input_size: int, n_classes: int):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.n_classes = n_classes\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(in_features = self.input_size, out_features=4096), # Shape transformation: (9216) -> (4096)\n",
    "            nn.BatchNorm1d(4096),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(in_features = 4096, out_features=2048), # Shape transformation: (4096) -> (2048)\n",
    "            nn.BatchNorm1d(2048),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(in_features = 2048, out_features=1024), # Shape transformation: (2048) -> (1024)\n",
    "            nn.BatchNorm1d(1024),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(in_features = 1024, out_features=512), # Shape transformation: (1024) -> (512)\n",
    "            nn.BatchNorm1d(512),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(in_features = 512, out_features=256), # Shape transformation: (512) -> (256)\n",
    "            nn.BatchNorm1d(256),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(in_features = 256, out_features=128), # Shape transformation: (256) -> (128)\n",
    "            nn.BatchNorm1d(128),\n",
    "            nn.Dropout(0.4),\n",
    "            nn.Linear(in_features = 128, out_features = self.n_classes), # Shape transformation: (128) -> (10)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-10T21:37:30.938478Z",
     "start_time": "2022-12-10T21:37:30.751254Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "           Dropout-1                 [-1, 9216]               0\n",
      "            Linear-2                 [-1, 4096]      37,752,832\n",
      "       BatchNorm1d-3                 [-1, 4096]           8,192\n",
      "           Dropout-4                 [-1, 4096]               0\n",
      "            Linear-5                 [-1, 2048]       8,390,656\n",
      "       BatchNorm1d-6                 [-1, 2048]           4,096\n",
      "           Dropout-7                 [-1, 2048]               0\n",
      "            Linear-8                 [-1, 1024]       2,098,176\n",
      "       BatchNorm1d-9                 [-1, 1024]           2,048\n",
      "          Dropout-10                 [-1, 1024]               0\n",
      "           Linear-11                  [-1, 512]         524,800\n",
      "      BatchNorm1d-12                  [-1, 512]           1,024\n",
      "          Dropout-13                  [-1, 512]               0\n",
      "           Linear-14                  [-1, 256]         131,328\n",
      "      BatchNorm1d-15                  [-1, 256]             512\n",
      "          Dropout-16                  [-1, 256]               0\n",
      "           Linear-17                  [-1, 128]          32,896\n",
      "      BatchNorm1d-18                  [-1, 128]             256\n",
      "          Dropout-19                  [-1, 128]               0\n",
      "           Linear-20                   [-1, 10]           1,290\n",
      "================================================================\n",
      "Total params: 48,948,106\n",
      "Trainable params: 48,948,106\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.04\n",
      "Forward/backward pass size (MB): 0.25\n",
      "Params size (MB): 186.72\n",
      "Estimated Total Size (MB): 187.01\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "alexnet_classifier = AlexNetClassifier(input_size=alexnet_backbone_output_shape, n_classes=config_dict['num_classes']).to(device)\n",
    "summary(alexnet_classifier, input_size=(alexnet_backbone_output_shape,))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 60,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-10T21:39:02.701696Z",
     "start_time": "2022-12-10T21:39:02.697912Z"
    }
   },
   "outputs": [],
   "source": [
    "class AlexNetRegressor(nn.Module):\n",
    "    def __init__(self, input_size: int):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(in_features = self.input_size, out_features=2048), # Shape transformation: (9.216) -> (4.096)\n",
    "            nn.BatchNorm1d(2048),\n",
    "            nn.Linear(in_features = 2048, out_features=1024), # Shape transformation: (9.216) -> (4.096)\n",
    "            nn.BatchNorm1d(1024),\n",
    "            # nn.Dropout(0.4),\n",
    "            nn.Linear(in_features = 1024, out_features=512), # Shape transformation: (4.096) -> (2.048)\n",
    "            nn.BatchNorm1d(512),\n",
    "            # nn.Dropout(0.4),\n",
    "            nn.Linear(in_features = 512, out_features=256), # Shape transformation: (2.048) -> (1.024)\n",
    "            nn.BatchNorm1d(256),\n",
    "            # nn.Dropout(0.4),\n",
    "            nn.Linear(in_features = 256, out_features=128), # Shape transformation: (1.024) -> (128)\n",
    "            nn.BatchNorm1d(128),\n",
    "            # nn.Dropout(0.4),\n",
    "            nn.Linear(in_features = 128, out_features = 4), # Shape transformation: (128) -> (4)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 62,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-10T21:39:14.701399Z",
     "start_time": "2022-12-10T21:39:14.582133Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Linear-1                 [-1, 2048]      18,876,416\n",
      "       BatchNorm1d-2                 [-1, 2048]           4,096\n",
      "            Linear-3                 [-1, 1024]       2,098,176\n",
      "       BatchNorm1d-4                 [-1, 1024]           2,048\n",
      "            Linear-5                  [-1, 512]         524,800\n",
      "       BatchNorm1d-6                  [-1, 512]           1,024\n",
      "            Linear-7                  [-1, 256]         131,328\n",
      "       BatchNorm1d-8                  [-1, 256]             512\n",
      "            Linear-9                  [-1, 128]          32,896\n",
      "      BatchNorm1d-10                  [-1, 128]             256\n",
      "           Linear-11                    [-1, 4]             516\n",
      "================================================================\n",
      "Total params: 21,672,068\n",
      "Trainable params: 21,672,068\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.04\n",
      "Forward/backward pass size (MB): 0.06\n",
      "Params size (MB): 82.67\n",
      "Estimated Total Size (MB): 82.77\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "alexnet_regressor = AlexNetRegressor(input_size=alexnet_backbone_output_shape).to(device)\n",
    "summary(alexnet_regressor, input_size=(alexnet_backbone_output_shape,))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-09T23:02:36.376480Z",
     "start_time": "2022-12-09T23:02:36.373097Z"
    }
   },
   "source": [
    "Definimos nuestro modelo para la clasificación y la regresion"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-10T21:39:41.687080Z",
     "start_time": "2022-12-10T21:39:41.669467Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 64, 55, 55]          23,296\n",
      "              ReLU-2           [-1, 64, 55, 55]               0\n",
      "         MaxPool2d-3           [-1, 64, 27, 27]               0\n",
      "            Conv2d-4          [-1, 192, 27, 27]         307,392\n",
      "              ReLU-5          [-1, 192, 27, 27]               0\n",
      "         MaxPool2d-6          [-1, 192, 13, 13]               0\n",
      "            Conv2d-7          [-1, 384, 13, 13]         663,936\n",
      "              ReLU-8          [-1, 384, 13, 13]               0\n",
      "            Conv2d-9          [-1, 256, 13, 13]         884,992\n",
      "             ReLU-10          [-1, 256, 13, 13]               0\n",
      "           Conv2d-11          [-1, 256, 13, 13]         590,080\n",
      "             ReLU-12          [-1, 256, 13, 13]               0\n",
      "        MaxPool2d-13            [-1, 256, 6, 6]               0\n",
      "AdaptiveAvgPool2d-14            [-1, 256, 6, 6]               0\n",
      "AdaptiveAvgPool2d-15            [-1, 256, 6, 6]               0\n",
      "AdaptiveAvgPool2d-16            [-1, 256, 6, 6]               0\n",
      "AdaptiveAvgPool2d-17            [-1, 256, 6, 6]               0\n",
      "          Flatten-18                 [-1, 9216]               0\n",
      "TransferLearningBackbone-19                 [-1, 9216]               0\n",
      "          Dropout-20                 [-1, 9216]               0\n",
      "           Linear-21                 [-1, 4096]      37,752,832\n",
      "      BatchNorm1d-22                 [-1, 4096]           8,192\n",
      "          Dropout-23                 [-1, 4096]               0\n",
      "           Linear-24                 [-1, 2048]       8,390,656\n",
      "      BatchNorm1d-25                 [-1, 2048]           4,096\n",
      "          Dropout-26                 [-1, 2048]               0\n",
      "           Linear-27                 [-1, 1024]       2,098,176\n",
      "      BatchNorm1d-28                 [-1, 1024]           2,048\n",
      "          Dropout-29                 [-1, 1024]               0\n",
      "           Linear-30                  [-1, 512]         524,800\n",
      "      BatchNorm1d-31                  [-1, 512]           1,024\n",
      "          Dropout-32                  [-1, 512]               0\n",
      "           Linear-33                  [-1, 256]         131,328\n",
      "      BatchNorm1d-34                  [-1, 256]             512\n",
      "          Dropout-35                  [-1, 256]               0\n",
      "           Linear-36                  [-1, 128]          32,896\n",
      "      BatchNorm1d-37                  [-1, 128]             256\n",
      "          Dropout-38                  [-1, 128]               0\n",
      "           Linear-39                   [-1, 10]           1,290\n",
      "AlexNetClassifier-40                   [-1, 10]               0\n",
      "           Linear-41                 [-1, 2048]      18,876,416\n",
      "      BatchNorm1d-42                 [-1, 2048]           4,096\n",
      "           Linear-43                 [-1, 1024]       2,098,176\n",
      "      BatchNorm1d-44                 [-1, 1024]           2,048\n",
      "           Linear-45                  [-1, 512]         524,800\n",
      "      BatchNorm1d-46                  [-1, 512]           1,024\n",
      "           Linear-47                  [-1, 256]         131,328\n",
      "      BatchNorm1d-48                  [-1, 256]             512\n",
      "           Linear-49                  [-1, 128]          32,896\n",
      "      BatchNorm1d-50                  [-1, 128]             256\n",
      "           Linear-51                    [-1, 4]             516\n",
      " AlexNetRegressor-52                    [-1, 4]               0\n",
      "================================================================\n",
      "Total params: 73,089,870\n",
      "Trainable params: 73,089,870\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.57\n",
      "Forward/backward pass size (MB): 8.81\n",
      "Params size (MB): 278.82\n",
      "Estimated Total Size (MB): 288.20\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "alexnet_model = Model(backbone=alexnet_backbone, classifier=alexnet_classifier, regressor=alexnet_regressor).to(device)\n",
    "summary(alexnet_model, input_size=(3, 224, 224))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 64,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-10T21:39:51.413327Z",
     "start_time": "2022-12-10T21:39:51.410283Z"
    }
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    }
   ],
   "source": [
    "train_ds = MNISTDataset(train_df, gray=False, root_dir=config_dict['train_images_dir'], transform=train_transforms)\n",
    "test_ds = MNISTDataset(test_df, gray=False, root_dir=config_dict['train_images_dir'], transform=eval_transforms)\n",
    "\n",
    "train_data = DataLoader(train_ds, batch_size=config_dict['batch_size'], shuffle=True, num_workers=cpu_count())\n",
    "test_data = DataLoader(test_ds, batch_size=config_dict['batch_size'], num_workers=cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 65,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-10T21:40:02.535897Z",
     "start_time": "2022-12-10T21:40:02.533458Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 66,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-10T21:47:38.401041Z",
     "start_time": "2022-12-10T21:40:15.928434Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration #:  0\n",
      "\talpha = 0.5\n",
      "\ttrain_loss = 17.216299057006836\n",
      "\ttrain_reg_loss = 32.0\n",
      "\ttrain_cls_loss = 2.4326999187469482\n",
      "\ttrain_iou = 0.0\n",
      "\ttrain_accuracy = 0.125\n",
      "\tval_loss = 9.079400062561035\n",
      "\tval_reg_loss = 15.864800453186035\n",
      "\tval_cls_loss = 2.2939999103546143\n",
      "\tval_iou = 0.0085\n",
      "\tval_accuracy = 0.125\n",
      "\n",
      "Iteration #:  5\n",
      "\talpha = 0.519\n",
      "\ttrain_loss = 17.72879981994629\n",
      "\ttrain_reg_loss = 31.768299102783203\n",
      "\ttrain_cls_loss = 2.5773000717163086\n",
      "\ttrain_iou = 0.0072\n",
      "\ttrain_accuracy = 0.0625\n",
      "\tval_loss = 9.37559986114502\n",
      "\tval_reg_loss = 15.934000015258789\n",
      "\tval_cls_loss = 2.2976999282836914\n",
      "\tval_iou = 0.0041\n",
      "\tval_accuracy = 0.125\n",
      "\n",
      "Iteration #:  10\n",
      "\talpha = 0.5364\n",
      "\ttrain_loss = 18.29680061340332\n",
      "\ttrain_reg_loss = 31.99650001525879\n",
      "\ttrain_cls_loss = 2.4481000900268555\n",
      "\ttrain_iou = 0.0001\n",
      "\ttrain_accuracy = 0.0625\n",
      "\tval_loss = 9.553600311279297\n",
      "\tval_reg_loss = 15.834500312805176\n",
      "\tval_cls_loss = 2.287400007247925\n",
      "\tval_iou = 0.0103\n",
      "\tval_accuracy = 0.125\n",
      "\n",
      "Iteration #:  15\n",
      "\talpha = 0.5522\n",
      "\ttrain_loss = 18.66629981994629\n",
      "\ttrain_reg_loss = 31.857200622558594\n",
      "\ttrain_cls_loss = 2.4017999172210693\n",
      "\ttrain_iou = 0.0045\n",
      "\ttrain_accuracy = 0.15620000660419464\n",
      "\tval_loss = 9.790499687194824\n",
      "\tval_reg_loss = 15.86970043182373\n",
      "\tval_cls_loss = 2.2948999404907227\n",
      "\tval_iou = 0.0081\n",
      "\tval_accuracy = 0.1875\n",
      "\n",
      "Iteration #:  20\n",
      "\talpha = 0.5667\n",
      "\ttrain_loss = 19.260000228881836\n",
      "\ttrain_reg_loss = 32.0\n",
      "\ttrain_cls_loss = 2.5999999046325684\n",
      "\ttrain_iou = 0.0\n",
      "\ttrain_accuracy = 0.125\n",
      "\tval_loss = 10.040200233459473\n",
      "\tval_reg_loss = 15.96150016784668\n",
      "\tval_cls_loss = 2.2969000339508057\n",
      "\tval_iou = 0.0024\n",
      "\tval_accuracy = 0.1875\n",
      "\n",
      "Iteration #:  25\n",
      "\talpha = 0.58\n",
      "\ttrain_loss = 19.70490074157715\n",
      "\ttrain_reg_loss = 32.0\n",
      "\ttrain_cls_loss = 2.7260000705718994\n",
      "\ttrain_iou = 0.0\n",
      "\ttrain_accuracy = 0.0625\n",
      "\tval_loss = 10.246700286865234\n",
      "\tval_reg_loss = 16.0\n",
      "\tval_cls_loss = 2.301500082015991\n",
      "\tval_iou = 0.0\n",
      "\tval_accuracy = 0.1875\n",
      "\n",
      "Iteration #:  30\n",
      "\talpha = 0.5923\n",
      "\ttrain_loss = 19.948699951171875\n",
      "\ttrain_reg_loss = 32.0\n",
      "\ttrain_cls_loss = 2.440200090408325\n",
      "\ttrain_iou = 0.0\n",
      "\ttrain_accuracy = 0.125\n",
      "\tval_loss = 10.413999557495117\n",
      "\tval_reg_loss = 16.0\n",
      "\tval_cls_loss = 2.2985000610351562\n",
      "\tval_iou = 0.0\n",
      "\tval_accuracy = 0.125\n",
      "\n",
      "Iteration #:  35\n",
      "\talpha = 0.6037\n",
      "\ttrain_loss = 20.237300872802734\n",
      "\ttrain_reg_loss = 31.962799072265625\n",
      "\ttrain_cls_loss = 2.3750998973846436\n",
      "\ttrain_iou = 0.0012\n",
      "\ttrain_accuracy = 0.125\n",
      "\tval_loss = 10.572400093078613\n",
      "\tval_reg_loss = 16.0\n",
      "\tval_cls_loss = 2.3041999340057373\n",
      "\tval_iou = 0.0\n",
      "\tval_accuracy = 0.125\n",
      "\n",
      "Iteration #:  40\n",
      "\talpha = 0.6143\n",
      "\ttrain_loss = 20.46649932861328\n",
      "\ttrain_reg_loss = 31.778900146484375\n",
      "\ttrain_cls_loss = 2.450500011444092\n",
      "\ttrain_iou = 0.0069\n",
      "\ttrain_accuracy = 0.125\n",
      "\tval_loss = 10.705599784851074\n",
      "\tval_reg_loss = 15.980600357055664\n",
      "\tval_cls_loss = 2.304800033569336\n",
      "\tval_iou = 0.0012\n",
      "\tval_accuracy = 0.125\n",
      "\n",
      "Iteration #:  45\n",
      "\talpha = 0.6241\n",
      "\ttrain_loss = 20.776899337768555\n",
      "\ttrain_reg_loss = 31.701499938964844\n",
      "\ttrain_cls_loss = 2.6359000205993652\n",
      "\ttrain_iou = 0.0093\n",
      "\ttrain_accuracy = 0.0625\n",
      "\tval_loss = 10.853099822998047\n",
      "\tval_reg_loss = 16.0\n",
      "\tval_cls_loss = 2.30649995803833\n",
      "\tval_iou = 0.0\n",
      "\tval_accuracy = 0.1875\n",
      "\n",
      "Iteration #:  50\n",
      "\talpha = 0.6333\n",
      "\ttrain_loss = 21.16790008544922\n",
      "\ttrain_reg_loss = 32.0\n",
      "\ttrain_cls_loss = 2.4579999446868896\n",
      "\ttrain_iou = 0.0\n",
      "\ttrain_accuracy = 0.125\n",
      "\tval_loss = 10.981300354003906\n",
      "\tval_reg_loss = 16.0\n",
      "\tval_cls_loss = 2.3125998973846436\n",
      "\tval_iou = 0.0\n",
      "\tval_accuracy = 0.125\n",
      "\n",
      "Iteration #:  55\n",
      "\talpha = 0.6419\n",
      "\ttrain_loss = 21.192800521850586\n",
      "\ttrain_reg_loss = 31.68239974975586\n",
      "\ttrain_cls_loss = 2.38700008392334\n",
      "\ttrain_iou = 0.0099\n",
      "\ttrain_accuracy = 0.15620000660419464\n",
      "\tval_loss = 11.098699569702148\n",
      "\tval_reg_loss = 16.0\n",
      "\tval_cls_loss = 2.3115999698638916\n",
      "\tval_iou = 0.0\n",
      "\tval_accuracy = 0.125\n",
      "\n",
      "Iteration #:  60\n",
      "\talpha = 0.65\n",
      "\ttrain_loss = 21.573400497436523\n",
      "\ttrain_reg_loss = 31.87299919128418\n",
      "\ttrain_cls_loss = 2.4453999996185303\n",
      "\ttrain_iou = 0.004\n",
      "\ttrain_accuracy = 0.125\n",
      "\tval_loss = 11.208499908447266\n",
      "\tval_reg_loss = 16.0\n",
      "\tval_cls_loss = 2.3099000453948975\n",
      "\tval_iou = 0.0\n",
      "\tval_accuracy = 0.1875\n",
      "\n",
      "Iteration #:  65\n",
      "\talpha = 0.6576\n",
      "\ttrain_loss = 21.768800735473633\n",
      "\ttrain_reg_loss = 31.889999389648438\n",
      "\ttrain_cls_loss = 2.3324999809265137\n",
      "\ttrain_iou = 0.0034\n",
      "\ttrain_accuracy = 0.125\n",
      "\tval_loss = 11.312299728393555\n",
      "\tval_reg_loss = 16.0\n",
      "\tval_cls_loss = 2.31030011177063\n",
      "\tval_iou = 0.0\n",
      "\tval_accuracy = 0.1875\n",
      "\n",
      "Iteration #:  70\n",
      "\talpha = 0.6647\n",
      "\ttrain_loss = 22.141300201416016\n",
      "\ttrain_reg_loss = 32.0\n",
      "\ttrain_cls_loss = 2.5968000888824463\n",
      "\ttrain_iou = 0.0\n",
      "\ttrain_accuracy = 0.09380000084638596\n",
      "\tval_loss = 11.40880012512207\n",
      "\tval_reg_loss = 16.0\n",
      "\tval_cls_loss = 2.306999921798706\n",
      "\tval_iou = 0.0\n",
      "\tval_accuracy = 0.1875\n",
      "\n",
      "Iteration #:  75\n",
      "\talpha = 0.6714\n",
      "\ttrain_loss = 22.28969955444336\n",
      "\ttrain_reg_loss = 31.909500122070312\n",
      "\ttrain_cls_loss = 2.631999969482422\n",
      "\ttrain_iou = 0.0028\n",
      "\ttrain_accuracy = 0.09380000084638596\n",
      "\tval_loss = 11.50100040435791\n",
      "\tval_reg_loss = 16.0\n",
      "\tval_cls_loss = 2.307300090789795\n",
      "\tval_iou = 0.0\n",
      "\tval_accuracy = 0.1875\n",
      "\n",
      "Iteration #:  80\n",
      "\talpha = 0.6778\n",
      "\ttrain_loss = 22.37929916381836\n",
      "\ttrain_reg_loss = 31.83489990234375\n",
      "\ttrain_cls_loss = 2.490000009536743\n",
      "\ttrain_iou = 0.0052\n",
      "\ttrain_accuracy = 0.09380000084638596\n",
      "\tval_loss = 11.585100173950195\n",
      "\tval_reg_loss = 16.0\n",
      "\tval_cls_loss = 2.2987000942230225\n",
      "\tval_iou = 0.0\n",
      "\tval_accuracy = 0.25\n",
      "\n",
      "Iteration #:  85\n",
      "\talpha = 0.6838\n",
      "\ttrain_loss = 22.634700775146484\n",
      "\ttrain_reg_loss = 31.87700080871582\n",
      "\ttrain_cls_loss = 2.6493000984191895\n",
      "\ttrain_iou = 0.0038\n",
      "\ttrain_accuracy = 0.09380000084638596\n",
      "\tval_loss = 11.653499603271484\n",
      "\tval_reg_loss = 15.97819995880127\n",
      "\tval_cls_loss = 2.302000045776367\n",
      "\tval_iou = 0.0014\n",
      "\tval_accuracy = 0.1875\n",
      "\n",
      "Iteration #:  90\n",
      "\talpha = 0.6895\n",
      "\ttrain_loss = 22.7632999420166\n",
      "\ttrain_reg_loss = 31.84980010986328\n",
      "\ttrain_cls_loss = 2.5880000591278076\n",
      "\ttrain_iou = 0.0047\n",
      "\ttrain_accuracy = 0.09380000084638596\n",
      "\tval_loss = 11.745599746704102\n",
      "\tval_reg_loss = 16.0\n",
      "\tval_cls_loss = 2.299299955368042\n",
      "\tval_iou = 0.0\n",
      "\tval_accuracy = 0.25\n",
      "\n",
      "Iteration #:  95\n",
      "\talpha = 0.6949\n",
      "\ttrain_loss = 22.612499237060547\n",
      "\ttrain_reg_loss = 31.400999069213867\n",
      "\ttrain_cls_loss = 2.5982000827789307\n",
      "\ttrain_iou = 0.0187\n",
      "\ttrain_accuracy = 0.15620000660419464\n",
      "\tval_loss = 11.816499710083008\n",
      "\tval_reg_loss = 16.0\n",
      "\tval_cls_loss = 2.289400100708008\n",
      "\tval_iou = 0.0\n",
      "\tval_accuracy = 0.25\n",
      "\n",
      "Iteration #:  100\n",
      "\talpha = 0.7\n",
      "\ttrain_loss = 23.133399963378906\n",
      "\ttrain_reg_loss = 32.0\n",
      "\ttrain_cls_loss = 2.4447999000549316\n",
      "\ttrain_iou = 0.0\n",
      "\ttrain_accuracy = 0.125\n",
      "\tval_loss = 11.885000228881836\n",
      "\tval_reg_loss = 15.996800422668457\n",
      "\tval_cls_loss = 2.2906999588012695\n",
      "\tval_iou = 0.0002\n",
      "\tval_accuracy = 0.125\n",
      "\n",
      "Iteration #:  105\n",
      "\talpha = 0.7049\n",
      "\ttrain_loss = 23.153799057006836\n",
      "\ttrain_reg_loss = 31.710599899291992\n",
      "\ttrain_cls_loss = 2.7167000770568848\n",
      "\ttrain_iou = 0.009\n",
      "\ttrain_accuracy = 0.09380000084638596\n",
      "\tval_loss = 11.939299583435059\n",
      "\tval_reg_loss = 15.976900100708008\n",
      "\tval_cls_loss = 2.2959001064300537\n",
      "\tval_iou = 0.0014\n",
      "\tval_accuracy = 0.125\n",
      "\n",
      "Iteration #:  110\n",
      "\talpha = 0.7095\n",
      "\ttrain_loss = 23.42840003967285\n",
      "\ttrain_reg_loss = 31.935300827026367\n",
      "\ttrain_cls_loss = 2.649199962615967\n",
      "\ttrain_iou = 0.002\n",
      "\ttrain_accuracy = 0.09380000084638596\n",
      "\tval_loss = 12.022000312805176\n",
      "\tval_reg_loss = 16.0\n",
      "\tval_cls_loss = 2.3050999641418457\n",
      "\tval_iou = 0.0\n",
      "\tval_accuracy = 0.125\n",
      "\n",
      "Iteration #:  115\n",
      "\talpha = 0.714\n",
      "\ttrain_loss = 23.621200561523438\n",
      "\ttrain_reg_loss = 32.0\n",
      "\ttrain_cls_loss = 2.7083001136779785\n",
      "\ttrain_iou = 0.0\n",
      "\ttrain_accuracy = 0.031199999153614044\n",
      "\tval_loss = 12.077799797058105\n",
      "\tval_reg_loss = 15.991900444030762\n",
      "\tval_cls_loss = 2.308500051498413\n",
      "\tval_iou = 0.0005\n",
      "\tval_accuracy = 0.1875\n",
      "\n",
      "Iteration #:  120\n",
      "\talpha = 0.7182\n",
      "\ttrain_loss = 23.486799240112305\n",
      "\ttrain_reg_loss = 31.831199645996094\n",
      "\ttrain_cls_loss = 2.2221999168395996\n",
      "\ttrain_iou = 0.0053\n",
      "\ttrain_accuracy = 0.15620000660419464\n",
      "\tval_loss = 12.07960033416748\n",
      "\tval_reg_loss = 15.91759967803955\n",
      "\tval_cls_loss = 2.2985999584198\n",
      "\tval_iou = 0.0051\n",
      "\tval_accuracy = 0.1875\n",
      "\n",
      "Iteration #:  125\n",
      "\talpha = 0.7222\n",
      "\ttrain_loss = 23.164600372314453\n",
      "\ttrain_reg_loss = 31.053300857543945\n",
      "\ttrain_cls_loss = 2.6538000106811523\n",
      "\ttrain_iou = 0.0296\n",
      "\ttrain_accuracy = 0.125\n",
      "\tval_loss = 12.115900039672852\n",
      "\tval_reg_loss = 15.892000198364258\n",
      "\tval_cls_loss = 2.2978999614715576\n",
      "\tval_iou = 0.0067\n",
      "\tval_accuracy = 0.25\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration #:  130\n",
      "\talpha = 0.7261\n",
      "\ttrain_loss = 23.673999786376953\n",
      "\ttrain_reg_loss = 31.628799438476562\n",
      "\ttrain_cls_loss = 2.5876998901367188\n",
      "\ttrain_iou = 0.0116\n",
      "\ttrain_accuracy = 0.09380000084638596\n",
      "\tval_loss = 12.199299812316895\n",
      "\tval_reg_loss = 15.933699607849121\n",
      "\tval_cls_loss = 2.2999000549316406\n",
      "\tval_iou = 0.0041\n",
      "\tval_accuracy = 0.1875\n",
      "\n",
      "Iteration #:  135\n",
      "\talpha = 0.7298\n",
      "\ttrain_loss = 23.944700241088867\n",
      "\ttrain_reg_loss = 31.854400634765625\n",
      "\ttrain_cls_loss = 2.5820000171661377\n",
      "\ttrain_iou = 0.0045\n",
      "\ttrain_accuracy = 0.15620000660419464\n",
      "\tval_loss = 12.2923002243042\n",
      "\tval_reg_loss = 15.992500305175781\n",
      "\tval_cls_loss = 2.2988998889923096\n",
      "\tval_iou = 0.0005\n",
      "\tval_accuracy = 0.1875\n",
      "\n",
      "Iteration #:  140\n",
      "\talpha = 0.7333\n",
      "\ttrain_loss = 24.110599517822266\n",
      "\ttrain_reg_loss = 31.926799774169922\n",
      "\ttrain_cls_loss = 2.6161999702453613\n",
      "\ttrain_iou = 0.0023\n",
      "\ttrain_accuracy = 0.09380000084638596\n",
      "\tval_loss = 12.309300422668457\n",
      "\tval_reg_loss = 15.949899673461914\n",
      "\tval_cls_loss = 2.2980000972747803\n",
      "\tval_iou = 0.0031\n",
      "\tval_accuracy = 0.125\n",
      "\n",
      "Iteration #:  145\n",
      "\talpha = 0.7367\n",
      "\ttrain_loss = 24.16830062866211\n",
      "\ttrain_reg_loss = 31.904699325561523\n",
      "\ttrain_cls_loss = 2.5185000896453857\n",
      "\ttrain_iou = 0.003\n",
      "\ttrain_accuracy = 0.15620000660419464\n",
      "\tval_loss = 12.390899658203125\n",
      "\tval_reg_loss = 16.0\n",
      "\tval_cls_loss = 2.291100025177002\n",
      "\tval_iou = 0.0\n",
      "\tval_accuracy = 0.125\n",
      "\n",
      "Iteration #:  150\n",
      "\talpha = 0.74\n",
      "\ttrain_loss = 24.125\n",
      "\ttrain_reg_loss = 31.729799270629883\n",
      "\ttrain_cls_loss = 2.480799913406372\n",
      "\ttrain_iou = 0.0084\n",
      "\ttrain_accuracy = 0.15620000660419464\n",
      "\tval_loss = 12.437000274658203\n",
      "\tval_reg_loss = 16.0\n",
      "\tval_cls_loss = 2.2962000370025635\n",
      "\tval_iou = 0.0\n",
      "\tval_accuracy = 0.1875\n",
      "\n",
      "Iteration #:  155\n",
      "\talpha = 0.7431\n",
      "\ttrain_loss = 24.32740020751953\n",
      "\ttrain_reg_loss = 31.853900909423828\n",
      "\ttrain_cls_loss = 2.5522000789642334\n",
      "\ttrain_iou = 0.0046\n",
      "\ttrain_accuracy = 0.125\n",
      "\tval_loss = 12.480600357055664\n",
      "\tval_reg_loss = 16.0\n",
      "\tval_cls_loss = 2.2985000610351562\n",
      "\tval_iou = 0.0\n",
      "\tval_accuracy = 0.1875\n",
      "\n",
      "Iteration #:  160\n",
      "\talpha = 0.7462\n",
      "\ttrain_loss = 24.402700424194336\n",
      "\ttrain_reg_loss = 31.80470085144043\n",
      "\ttrain_cls_loss = 2.6452999114990234\n",
      "\ttrain_iou = 0.0061\n",
      "\ttrain_accuracy = 0.125\n",
      "\tval_loss = 12.522500038146973\n",
      "\tval_reg_loss = 16.0\n",
      "\tval_cls_loss = 2.300800085067749\n",
      "\tval_iou = 0.0\n",
      "\tval_accuracy = 0.125\n",
      "\n",
      "Iteration #:  165\n",
      "\talpha = 0.7491\n",
      "\ttrain_loss = 24.489500045776367\n",
      "\ttrain_reg_loss = 31.880699157714844\n",
      "\ttrain_cls_loss = 2.427000045776367\n",
      "\ttrain_iou = 0.0037\n",
      "\ttrain_accuracy = 0.125\n",
      "\tval_loss = 12.562299728393555\n",
      "\tval_reg_loss = 16.0\n",
      "\tval_cls_loss = 2.3010001182556152\n",
      "\tval_iou = 0.0\n",
      "\tval_accuracy = 0.125\n",
      "\n",
      "Iteration #:  170\n",
      "\talpha = 0.7519\n",
      "\ttrain_loss = 24.590900421142578\n",
      "\ttrain_reg_loss = 31.8700008392334\n",
      "\ttrain_cls_loss = 2.536400079727173\n",
      "\ttrain_iou = 0.0041\n",
      "\ttrain_accuracy = 0.031199999153614044\n",
      "\tval_loss = 12.600299835205078\n",
      "\tval_reg_loss = 16.0\n",
      "\tval_cls_loss = 2.2995998859405518\n",
      "\tval_iou = 0.0\n",
      "\tval_accuracy = 0.125\n",
      "\n",
      "Iteration #:  175\n",
      "\talpha = 0.7545\n",
      "\ttrain_loss = 24.588499069213867\n",
      "\ttrain_reg_loss = 31.822099685668945\n",
      "\ttrain_cls_loss = 2.3517000675201416\n",
      "\ttrain_iou = 0.0056\n",
      "\ttrain_accuracy = 0.15620000660419464\n",
      "\tval_loss = 12.637200355529785\n",
      "\tval_reg_loss = 16.0\n",
      "\tval_cls_loss = 2.299799919128418\n",
      "\tval_iou = 0.0\n",
      "\tval_accuracy = 0.125\n",
      "\n",
      "Iteration #:  180\n",
      "\talpha = 0.7571\n",
      "\ttrain_loss = 24.82469940185547\n",
      "\ttrain_reg_loss = 31.922100067138672\n",
      "\ttrain_cls_loss = 2.697499990463257\n",
      "\ttrain_iou = 0.0024\n",
      "\ttrain_accuracy = 0.09380000084638596\n",
      "\tval_loss = 12.672800064086914\n",
      "\tval_reg_loss = 16.0\n",
      "\tval_cls_loss = 2.2997000217437744\n",
      "\tval_iou = 0.0\n",
      "\tval_accuracy = 0.125\n",
      "\n",
      "Iteration #:  185\n",
      "\talpha = 0.7596\n",
      "\ttrain_loss = 24.802200317382812\n",
      "\ttrain_reg_loss = 31.803800582885742\n",
      "\ttrain_cls_loss = 2.673099994659424\n",
      "\ttrain_iou = 0.0061\n",
      "\ttrain_accuracy = 0.125\n",
      "\tval_loss = 12.706500053405762\n",
      "\tval_reg_loss = 16.0\n",
      "\tval_cls_loss = 2.296999931335449\n",
      "\tval_iou = 0.0\n",
      "\tval_accuracy = 0.125\n",
      "\n",
      "Iteration #:  190\n",
      "\talpha = 0.7621\n",
      "\ttrain_loss = 24.78860092163086\n",
      "\ttrain_reg_loss = 31.748899459838867\n",
      "\ttrain_cls_loss = 2.495300054550171\n",
      "\ttrain_iou = 0.0078\n",
      "\ttrain_accuracy = 0.125\n",
      "\tval_loss = 12.729700088500977\n",
      "\tval_reg_loss = 15.98740005493164\n",
      "\tval_cls_loss = 2.2957000732421875\n",
      "\tval_iou = 0.0008\n",
      "\tval_accuracy = 0.1875\n",
      "\n",
      "Iteration #:  195\n",
      "\talpha = 0.7644\n",
      "\ttrain_loss = 24.81879997253418\n",
      "\ttrain_reg_loss = 31.606800079345703\n",
      "\ttrain_cls_loss = 2.794600009918213\n",
      "\ttrain_iou = 0.0123\n",
      "\ttrain_accuracy = 0.0625\n",
      "\tval_loss = 12.772000312805176\n",
      "\tval_reg_loss = 16.0\n",
      "\tval_cls_loss = 2.2983999252319336\n",
      "\tval_iou = 0.0\n",
      "\tval_accuracy = 0.125\n",
      "\n",
      "Iteration #:  200\n",
      "\talpha = 0.7667\n",
      "\ttrain_loss = 24.9512996673584\n",
      "\ttrain_reg_loss = 31.80109977722168\n",
      "\ttrain_cls_loss = 2.4446001052856445\n",
      "\ttrain_iou = 0.0062\n",
      "\ttrain_accuracy = 0.0625\n",
      "\tval_loss = 12.802900314331055\n",
      "\tval_reg_loss = 16.0\n",
      "\tval_cls_loss = 2.29830002784729\n",
      "\tval_iou = 0.0\n",
      "\tval_accuracy = 0.125\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_result = train(\n",
    "    alexnet_model,\n",
    "    optimizer,\n",
    "    train_data,\n",
    "    eval_datasets=[('val', test_data)],\n",
    "    loss_fn=loss_fn,\n",
    "    metrics={\n",
    "        'bbox': [('iou', iou)],\n",
    "        'class_id': [('accuracy', accuracy)]\n",
    "    },\n",
    "    callbacks=[printer],\n",
    "    device=device,\n",
    "    train_steps=config_dict['num_epochs'],\n",
    "    eval_steps=5,\n",
    ")\n",
    "\n",
    "model = train_result['model']"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Data Augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Realizaremos data augmentation con el fin de mejorar los resultados de los modelos, al tener un dataset mucho más grande."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### AlbumentationsWrapper"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-10T22:12:21.152184Z",
     "start_time": "2022-12-10T22:12:21.149390Z"
    }
   },
   "outputs": [],
   "source": [
    "class AlbumentationsWrapper(object):\n",
    "    \n",
    "    def __init__(self, transform):\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __call__(self, sample):\n",
    "        transformed = self.transform(\n",
    "            image=sample['image'], \n",
    "            bboxes=sample['bbox'],\n",
    "            category=sample['class_id']\n",
    "        )\n",
    "        sample['image'] = transformed['image']\n",
    "        sample['bbox'] = np.array(transformed['bboxes'])\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Train data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-10T22:15:36.938243Z",
     "start_time": "2022-12-10T22:15:36.935305Z"
    }
   },
   "outputs": [],
   "source": [
    "train_data_augmentations = A.Compose([\n",
    "        A.RandomScale(scale_limit=0.01, p=1),\n",
    "        A.ImageCompression(p=1),\n",
    "        A.Superpixels(p=1, n_segments=30, max_size=None),\n",
    "        A.Rotate(limit=(-20, 20), p=1),\n",
    "        A.Resize(height=config_dict['img_size'], width=config_dict['img_size'], p=1) # p=1 means always apply\n",
    "    ],\n",
    "    bbox_params=A.BboxParams(\n",
    "        format='albumentations', \n",
    "        label_fields=['category'],\n",
    "    )\n",
    ")\n",
    "\n",
    "train_transforms_da = torchvision.transforms.Compose(\n",
    "    [\n",
    "        AlbumentationsWrapper(train_data_augmentations),\n",
    "    ] + common_transforms\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Train Models with Data augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-10T22:15:39.500427Z",
     "start_time": "2022-12-10T22:15:39.497399Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n"
     ]
    }
   ],
   "source": [
    "train_ds = MNISTDataset(train_df, gray=False, root_dir=config_dict['train_images_dir'], transform=train_transforms_da)\n",
    "test_ds = MNISTDataset(test_df, gray=False, root_dir=config_dict['train_images_dir'], transform=eval_transforms)\n",
    "\n",
    "train_data = DataLoader(train_ds, batch_size=config_dict['batch_size'], shuffle=True, num_workers=cpu_count())\n",
    "test_data = DataLoader(test_ds, batch_size=config_dict['batch_size'], num_workers=cpu_count())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 74,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-10T22:16:11.572572Z",
     "start_time": "2022-12-10T22:16:11.565395Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 75,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-10T22:24:05.406215Z",
     "start_time": "2022-12-10T22:16:14.066656Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torch/utils/data/dataloader.py:478: UserWarning: This DataLoader will create 24 worker processes in total. Our suggested max number of worker in current system is 1, which is smaller than what this DataLoader is going to create. Please be aware that excessive worker creation might get DataLoader running slow or even freeze, lower the worker number to avoid potential slowness/freeze if necessary.\n",
      "  warnings.warn(_create_warning_msg(\n",
      "/opt/conda/lib/python3.8/site-packages/albumentations/augmentations/functional.py:1232: FutureWarning: skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
      "  segments = skimage.segmentation.slic(image, n_segments=n_segments, compactness=10)\n",
      "/opt/conda/lib/python3.8/site-packages/albumentations/augmentations/functional.py:1232: FutureWarning: skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
      "  segments = skimage.segmentation.slic(image, n_segments=n_segments, compactness=10)\n",
      "/opt/conda/lib/python3.8/site-packages/albumentations/augmentations/functional.py:1232: FutureWarning: skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
      "  segments = skimage.segmentation.slic(image, n_segments=n_segments, compactness=10)\n",
      "/opt/conda/lib/python3.8/site-packages/albumentations/augmentations/functional.py:1232: FutureWarning: skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
      "  segments = skimage.segmentation.slic(image, n_segments=n_segments, compactness=10)\n",
      "/opt/conda/lib/python3.8/site-packages/albumentations/augmentations/functional.py:1232: FutureWarning: skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
      "  segments = skimage.segmentation.slic(image, n_segments=n_segments, compactness=10)\n",
      "/opt/conda/lib/python3.8/site-packages/albumentations/augmentations/functional.py:1232: FutureWarning: skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
      "  segments = skimage.segmentation.slic(image, n_segments=n_segments, compactness=10)\n",
      "/opt/conda/lib/python3.8/site-packages/albumentations/augmentations/functional.py:1232: FutureWarning: skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
      "  segments = skimage.segmentation.slic(image, n_segments=n_segments, compactness=10)\n",
      "/opt/conda/lib/python3.8/site-packages/albumentations/augmentations/functional.py:1232: FutureWarning: skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
      "  segments = skimage.segmentation.slic(image, n_segments=n_segments, compactness=10)\n",
      "/opt/conda/lib/python3.8/site-packages/albumentations/augmentations/functional.py:1232: FutureWarning: skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
      "  segments = skimage.segmentation.slic(image, n_segments=n_segments, compactness=10)\n",
      "/opt/conda/lib/python3.8/site-packages/albumentations/augmentations/functional.py:1232: FutureWarning: skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
      "  segments = skimage.segmentation.slic(image, n_segments=n_segments, compactness=10)\n",
      "/opt/conda/lib/python3.8/site-packages/albumentations/augmentations/functional.py:1232: FutureWarning: skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
      "  segments = skimage.segmentation.slic(image, n_segments=n_segments, compactness=10)\n",
      "/opt/conda/lib/python3.8/site-packages/albumentations/augmentations/functional.py:1232: FutureWarning: skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
      "  segments = skimage.segmentation.slic(image, n_segments=n_segments, compactness=10)\n",
      "/opt/conda/lib/python3.8/site-packages/albumentations/augmentations/functional.py:1232: FutureWarning: skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
      "  segments = skimage.segmentation.slic(image, n_segments=n_segments, compactness=10)\n",
      "/opt/conda/lib/python3.8/site-packages/albumentations/augmentations/functional.py:1232: FutureWarning: skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
      "  segments = skimage.segmentation.slic(image, n_segments=n_segments, compactness=10)\n",
      "/opt/conda/lib/python3.8/site-packages/albumentations/augmentations/functional.py:1232: FutureWarning: skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
      "  segments = skimage.segmentation.slic(image, n_segments=n_segments, compactness=10)\n",
      "/opt/conda/lib/python3.8/site-packages/albumentations/augmentations/functional.py:1232: FutureWarning: skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
      "  segments = skimage.segmentation.slic(image, n_segments=n_segments, compactness=10)\n",
      "/opt/conda/lib/python3.8/site-packages/albumentations/augmentations/functional.py:1232: FutureWarning: skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
      "  segments = skimage.segmentation.slic(image, n_segments=n_segments, compactness=10)\n",
      "/opt/conda/lib/python3.8/site-packages/albumentations/augmentations/functional.py:1232: FutureWarning: skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
      "  segments = skimage.segmentation.slic(image, n_segments=n_segments, compactness=10)\n",
      "/opt/conda/lib/python3.8/site-packages/albumentations/augmentations/functional.py:1232: FutureWarning: skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
      "  segments = skimage.segmentation.slic(image, n_segments=n_segments, compactness=10)\n",
      "/opt/conda/lib/python3.8/site-packages/albumentations/augmentations/functional.py:1232: FutureWarning: skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
      "  segments = skimage.segmentation.slic(image, n_segments=n_segments, compactness=10)\n",
      "/opt/conda/lib/python3.8/site-packages/albumentations/augmentations/functional.py:1232: FutureWarning: skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
      "  segments = skimage.segmentation.slic(image, n_segments=n_segments, compactness=10)\n",
      "/opt/conda/lib/python3.8/site-packages/albumentations/augmentations/functional.py:1232: FutureWarning: skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
      "  segments = skimage.segmentation.slic(image, n_segments=n_segments, compactness=10)\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/albumentations/augmentations/functional.py:1232: FutureWarning: skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
      "  segments = skimage.segmentation.slic(image, n_segments=n_segments, compactness=10)\n",
      "/opt/conda/lib/python3.8/site-packages/albumentations/augmentations/functional.py:1232: FutureWarning: skimage.measure.label's indexing starts from 0. In future version it will start from 1. To disable this warning, explicitely set the `start_label` parameter to 1.\n",
      "  segments = skimage.segmentation.slic(image, n_segments=n_segments, compactness=10)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration #:  0\n",
      "\talpha = 0.5\n",
      "\ttrain_loss = 17.10420036315918\n",
      "\ttrain_reg_loss = 31.66510009765625\n",
      "\ttrain_cls_loss = 2.5434000492095947\n",
      "\ttrain_iou = 0.0105\n",
      "\ttrain_accuracy = 0.125\n",
      "\tval_loss = 9.150899887084961\n",
      "\tval_reg_loss = 16.0\n",
      "\tval_cls_loss = 2.301800012588501\n",
      "\tval_iou = 0.0\n",
      "\tval_accuracy = 0.125\n",
      "\n",
      "Iteration #:  5\n",
      "\talpha = 0.519\n",
      "\ttrain_loss = 17.797000885009766\n",
      "\ttrain_reg_loss = 31.975400924682617\n",
      "\ttrain_cls_loss = 2.495500087738037\n",
      "\ttrain_iou = 0.0008\n",
      "\ttrain_accuracy = 0.125\n",
      "\tval_loss = 9.413299560546875\n",
      "\tval_reg_loss = 16.0\n",
      "\tval_cls_loss = 2.304800033569336\n",
      "\tval_iou = 0.0\n",
      "\tval_accuracy = 0.125\n",
      "\n",
      "Iteration #:  10\n",
      "\talpha = 0.5364\n",
      "\ttrain_loss = 18.24090003967285\n",
      "\ttrain_reg_loss = 31.811199188232422\n",
      "\ttrain_cls_loss = 2.5420000553131104\n",
      "\ttrain_iou = 0.0059\n",
      "\ttrain_accuracy = 0.125\n",
      "\tval_loss = 9.635299682617188\n",
      "\tval_reg_loss = 15.978300094604492\n",
      "\tval_cls_loss = 2.297300100326538\n",
      "\tval_iou = 0.0014\n",
      "\tval_accuracy = 0.125\n",
      "\n",
      "Iteration #:  15\n",
      "\talpha = 0.5522\n",
      "\ttrain_loss = 18.81920051574707\n",
      "\ttrain_reg_loss = 31.9955997467041\n",
      "\ttrain_cls_loss = 2.5724000930786133\n",
      "\ttrain_iou = 0.0001\n",
      "\ttrain_accuracy = 0.0625\n",
      "\tval_loss = 9.864899635314941\n",
      "\tval_reg_loss = 16.0\n",
      "\tval_cls_loss = 2.300299882888794\n",
      "\tval_iou = 0.0\n",
      "\tval_accuracy = 0.125\n",
      "\n",
      "Iteration #:  20\n",
      "\talpha = 0.5667\n",
      "\ttrain_loss = 19.218399047851562\n",
      "\ttrain_reg_loss = 31.80590057373047\n",
      "\ttrain_cls_loss = 2.7578999996185303\n",
      "\ttrain_iou = 0.0061\n",
      "\ttrain_accuracy = 0.031199999153614044\n",
      "\tval_loss = 10.067999839782715\n",
      "\tval_reg_loss = 16.0\n",
      "\tval_cls_loss = 2.310800075531006\n",
      "\tval_iou = 0.0\n",
      "\tval_accuracy = 0.1875\n",
      "\n",
      "Iteration #:  25\n",
      "\talpha = 0.58\n",
      "\ttrain_loss = 19.639999389648438\n",
      "\ttrain_reg_loss = 31.906400680541992\n",
      "\ttrain_cls_loss = 2.700700044631958\n",
      "\ttrain_iou = 0.0029\n",
      "\ttrain_accuracy = 0.15620000660419464\n",
      "\tval_loss = 10.247099876403809\n",
      "\tval_reg_loss = 15.997900009155273\n",
      "\tval_cls_loss = 2.3055999279022217\n",
      "\tval_iou = 0.0001\n",
      "\tval_accuracy = 0.1875\n",
      "\n",
      "Iteration #:  30\n",
      "\talpha = 0.5923\n",
      "\ttrain_loss = 19.9060001373291\n",
      "\ttrain_reg_loss = 31.814300537109375\n",
      "\ttrain_cls_loss = 2.6054000854492188\n",
      "\ttrain_iou = 0.0058\n",
      "\ttrain_accuracy = 0.15620000660419464\n",
      "\tval_loss = 10.419400215148926\n",
      "\tval_reg_loss = 16.0\n",
      "\tval_cls_loss = 2.3115999698638916\n",
      "\tval_iou = 0.0\n",
      "\tval_accuracy = 0.1875\n",
      "\n",
      "Iteration #:  35\n",
      "\talpha = 0.6037\n",
      "\ttrain_loss = 20.224700927734375\n",
      "\ttrain_reg_loss = 31.940799713134766\n",
      "\ttrain_cls_loss = 2.376800060272217\n",
      "\ttrain_iou = 0.0018\n",
      "\ttrain_accuracy = 0.125\n",
      "\tval_loss = 10.574199676513672\n",
      "\tval_reg_loss = 16.0\n",
      "\tval_cls_loss = 2.3087000846862793\n",
      "\tval_iou = 0.0\n",
      "\tval_accuracy = 0.1875\n",
      "\n",
      "Iteration #:  40\n",
      "\talpha = 0.6143\n",
      "\ttrain_loss = 20.407800674438477\n",
      "\ttrain_reg_loss = 31.71579933166504\n",
      "\ttrain_cls_loss = 2.3987998962402344\n",
      "\ttrain_iou = 0.0089\n",
      "\ttrain_accuracy = 0.0625\n",
      "\tval_loss = 10.697699546813965\n",
      "\tval_reg_loss = 15.965999603271484\n",
      "\tval_cls_loss = 2.307300090789795\n",
      "\tval_iou = 0.0021\n",
      "\tval_accuracy = 0.1875\n",
      "\n",
      "Iteration #:  45\n",
      "\talpha = 0.6241\n",
      "\ttrain_loss = 20.811899185180664\n",
      "\ttrain_reg_loss = 31.825300216674805\n",
      "\ttrain_cls_loss = 2.5234999656677246\n",
      "\ttrain_iou = 0.0055\n",
      "\ttrain_accuracy = 0.1875\n",
      "\tval_loss = 10.850600242614746\n",
      "\tval_reg_loss = 16.0\n",
      "\tval_cls_loss = 2.299799919128418\n",
      "\tval_iou = 0.0\n",
      "\tval_accuracy = 0.1875\n",
      "\n",
      "Iteration #:  50\n",
      "\talpha = 0.6333\n",
      "\ttrain_loss = 21.265399932861328\n",
      "\ttrain_reg_loss = 31.977699279785156\n",
      "\ttrain_cls_loss = 2.7623000144958496\n",
      "\ttrain_iou = 0.0007\n",
      "\ttrain_accuracy = 0.031199999153614044\n",
      "\tval_loss = 10.977800369262695\n",
      "\tval_reg_loss = 16.0\n",
      "\tval_cls_loss = 2.303100109100342\n",
      "\tval_iou = 0.0\n",
      "\tval_accuracy = 0.1875\n",
      "\n",
      "Iteration #:  55\n",
      "\talpha = 0.6419\n",
      "\ttrain_loss = 21.33099937438965\n",
      "\ttrain_reg_loss = 31.92770004272461\n",
      "\ttrain_cls_loss = 2.3331000804901123\n",
      "\ttrain_iou = 0.0023\n",
      "\ttrain_accuracy = 0.15620000660419464\n",
      "\tval_loss = 11.075799942016602\n",
      "\tval_reg_loss = 15.967900276184082\n",
      "\tval_cls_loss = 2.305299997329712\n",
      "\tval_iou = 0.002\n",
      "\tval_accuracy = 0.1875\n",
      "\n",
      "Iteration #:  60\n",
      "\talpha = 0.65\n",
      "\ttrain_loss = 21.544300079345703\n",
      "\ttrain_reg_loss = 31.68079948425293\n",
      "\ttrain_cls_loss = 2.7195000648498535\n",
      "\ttrain_iou = 0.01\n",
      "\ttrain_accuracy = 0.031199999153614044\n",
      "\tval_loss = 11.206299781799316\n",
      "\tval_reg_loss = 16.0\n",
      "\tval_cls_loss = 2.3036000728607178\n",
      "\tval_iou = 0.0\n",
      "\tval_accuracy = 0.1875\n",
      "\n",
      "Iteration #:  65\n",
      "\talpha = 0.6576\n",
      "\ttrain_loss = 21.5137996673584\n",
      "\ttrain_reg_loss = 31.42300033569336\n",
      "\ttrain_cls_loss = 2.4846999645233154\n",
      "\ttrain_iou = 0.018\n",
      "\ttrain_accuracy = 0.125\n",
      "\tval_loss = 11.307700157165527\n",
      "\tval_reg_loss = 16.0\n",
      "\tval_cls_loss = 2.2967000007629395\n",
      "\tval_iou = 0.0\n",
      "\tval_accuracy = 0.1875\n",
      "\n",
      "Iteration #:  70\n",
      "\talpha = 0.6647\n",
      "\ttrain_loss = 22.184900283813477\n",
      "\ttrain_reg_loss = 31.992900848388672\n",
      "\ttrain_cls_loss = 2.740799903869629\n",
      "\ttrain_iou = 0.0002\n",
      "\ttrain_accuracy = 0.0625\n",
      "\tval_loss = 11.40410041809082\n",
      "\tval_reg_loss = 16.0\n",
      "\tval_cls_loss = 2.2929999828338623\n",
      "\tval_iou = 0.0\n",
      "\tval_accuracy = 0.1875\n",
      "\n",
      "Iteration #:  75\n",
      "\talpha = 0.6714\n",
      "\ttrain_loss = 22.24449920654297\n",
      "\ttrain_reg_loss = 31.901100158691406\n",
      "\ttrain_cls_loss = 2.511399984359741\n",
      "\ttrain_iou = 0.0031\n",
      "\ttrain_accuracy = 0.15620000660419464\n",
      "\tval_loss = 11.497300148010254\n",
      "\tval_reg_loss = 16.0\n",
      "\tval_cls_loss = 2.296299934387207\n",
      "\tval_iou = 0.0\n",
      "\tval_accuracy = 0.1875\n",
      "\n",
      "Iteration #:  80\n",
      "\talpha = 0.6778\n",
      "\ttrain_loss = 22.503799438476562\n",
      "\ttrain_reg_loss = 32.0\n",
      "\ttrain_cls_loss = 2.5290000438690186\n",
      "\ttrain_iou = 0.0\n",
      "\ttrain_accuracy = 0.09380000084638596\n",
      "\tval_loss = 11.586999893188477\n",
      "\tval_reg_loss = 16.0\n",
      "\tval_cls_loss = 2.3046000003814697\n",
      "\tval_iou = 0.0\n",
      "\tval_accuracy = 0.1875\n",
      "\n",
      "Iteration #:  85\n",
      "\talpha = 0.6838\n",
      "\ttrain_loss = 22.720199584960938\n",
      "\ttrain_reg_loss = 32.0\n",
      "\ttrain_cls_loss = 2.6535000801086426\n",
      "\ttrain_iou = 0.0\n",
      "\ttrain_accuracy = 0.031199999153614044\n",
      "\tval_loss = 11.667099952697754\n",
      "\tval_reg_loss = 16.0\n",
      "\tval_cls_loss = 2.297800064086914\n",
      "\tval_iou = 0.0\n",
      "\tval_accuracy = 0.1875\n",
      "\n",
      "Iteration #:  90\n",
      "\talpha = 0.6895\n",
      "\ttrain_loss = 22.861299514770508\n",
      "\ttrain_reg_loss = 32.0\n",
      "\ttrain_cls_loss = 2.5703999996185303\n",
      "\ttrain_iou = 0.0\n",
      "\ttrain_accuracy = 0.0625\n",
      "\tval_loss = 11.745599746704102\n",
      "\tval_reg_loss = 16.0\n",
      "\tval_cls_loss = 2.2992000579833984\n",
      "\tval_iou = 0.0\n",
      "\tval_accuracy = 0.125\n",
      "\n",
      "Iteration #:  95\n",
      "\talpha = 0.6949\n",
      "\ttrain_loss = 22.408300399780273\n",
      "\ttrain_reg_loss = 31.2539005279541\n",
      "\ttrain_cls_loss = 2.2639999389648438\n",
      "\ttrain_iou = 0.0233\n",
      "\ttrain_accuracy = 0.125\n",
      "\tval_loss = 11.818599700927734\n",
      "\tval_reg_loss = 16.0\n",
      "\tval_cls_loss = 2.296099901199341\n",
      "\tval_iou = 0.0\n",
      "\tval_accuracy = 0.1875\n",
      "\n",
      "Iteration #:  100\n",
      "\talpha = 0.7\n",
      "\ttrain_loss = 23.107799530029297\n",
      "\ttrain_reg_loss = 31.914400100708008\n",
      "\ttrain_cls_loss = 2.559000015258789\n",
      "\ttrain_iou = 0.0027\n",
      "\ttrain_accuracy = 0.125\n",
      "\tval_loss = 11.859800338745117\n",
      "\tval_reg_loss = 15.958499908447266\n",
      "\tval_cls_loss = 2.296299934387207\n",
      "\tval_iou = 0.0026\n",
      "\tval_accuracy = 0.1875\n",
      "\n",
      "Iteration #:  105\n",
      "\talpha = 0.7049\n",
      "\ttrain_loss = 23.192699432373047\n",
      "\ttrain_reg_loss = 31.773799896240234\n",
      "\ttrain_cls_loss = 2.697499990463257\n",
      "\ttrain_iou = 0.0071\n",
      "\ttrain_accuracy = 0.031199999153614044\n",
      "\tval_loss = 11.95110034942627\n",
      "\tval_reg_loss = 15.993599891662598\n",
      "\tval_cls_loss = 2.295799970626831\n",
      "\tval_iou = 0.0004\n",
      "\tval_accuracy = 0.1875\n",
      "\n",
      "Iteration #:  110\n",
      "\talpha = 0.7095\n",
      "\ttrain_loss = 23.353500366210938\n",
      "\ttrain_reg_loss = 31.916200637817383\n",
      "\ttrain_cls_loss = 2.4379000663757324\n",
      "\ttrain_iou = 0.0026\n",
      "\ttrain_accuracy = 0.0625\n",
      "\tval_loss = 11.989899635314941\n",
      "\tval_reg_loss = 15.959799766540527\n",
      "\tval_cls_loss = 2.2927000522613525\n",
      "\tval_iou = 0.0025\n",
      "\tval_accuracy = 0.1875\n",
      "\n",
      "Iteration #:  115\n",
      "\talpha = 0.714\n",
      "\ttrain_loss = 23.41659927368164\n",
      "\ttrain_reg_loss = 31.766000747680664\n",
      "\ttrain_cls_loss = 2.5771000385284424\n",
      "\ttrain_iou = 0.0073\n",
      "\ttrain_accuracy = 0.09380000084638596\n",
      "\tval_loss = 12.082099914550781\n",
      "\tval_reg_loss = 16.0\n",
      "\tval_cls_loss = 2.3032000064849854\n",
      "\tval_iou = 0.0\n",
      "\tval_accuracy = 0.1875\n",
      "\n",
      "Iteration #:  120\n",
      "\talpha = 0.7182\n",
      "\ttrain_loss = 23.537799835205078\n",
      "\ttrain_reg_loss = 31.733699798583984\n",
      "\ttrain_cls_loss = 2.651700019836426\n",
      "\ttrain_iou = 0.0083\n",
      "\ttrain_accuracy = 0.0625\n",
      "\tval_loss = 12.14050006866455\n",
      "\tval_reg_loss = 16.0\n",
      "\tval_cls_loss = 2.3048999309539795\n",
      "\tval_iou = 0.0\n",
      "\tval_accuracy = 0.1875\n",
      "\n",
      "Iteration #:  125\n",
      "\talpha = 0.7222\n",
      "\ttrain_loss = 23.495399475097656\n",
      "\ttrain_reg_loss = 31.5674991607666\n",
      "\ttrain_cls_loss = 2.5078999996185303\n",
      "\ttrain_iou = 0.0135\n",
      "\ttrain_accuracy = 0.1875\n",
      "\tval_loss = 12.196000099182129\n",
      "\tval_reg_loss = 16.0\n",
      "\tval_cls_loss = 2.3055999279022217\n",
      "\tval_iou = 0.0\n",
      "\tval_accuracy = 0.1875\n",
      "\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration #:  130\n",
      "\talpha = 0.7261\n",
      "\ttrain_loss = 23.54599952697754\n",
      "\ttrain_reg_loss = 31.466699600219727\n",
      "\ttrain_cls_loss = 2.550100088119507\n",
      "\ttrain_iou = 0.0167\n",
      "\ttrain_accuracy = 0.031199999153614044\n",
      "\tval_loss = 12.250300407409668\n",
      "\tval_reg_loss = 16.0\n",
      "\tval_cls_loss = 2.310699939727783\n",
      "\tval_iou = 0.0\n",
      "\tval_accuracy = 0.125\n",
      "\n",
      "Iteration #:  135\n",
      "\talpha = 0.7298\n",
      "\ttrain_loss = 23.875200271606445\n",
      "\ttrain_reg_loss = 31.804000854492188\n",
      "\ttrain_cls_loss = 2.4612998962402344\n",
      "\ttrain_iou = 0.0061\n",
      "\ttrain_accuracy = 0.09380000084638596\n",
      "\tval_loss = 12.30049991607666\n",
      "\tval_reg_loss = 16.0\n",
      "\tval_cls_loss = 2.309000015258789\n",
      "\tval_iou = 0.0\n",
      "\tval_accuracy = 0.1875\n",
      "\n",
      "Iteration #:  140\n",
      "\talpha = 0.7333\n",
      "\ttrain_loss = 23.939599990844727\n",
      "\ttrain_reg_loss = 31.729400634765625\n",
      "\ttrain_cls_loss = 2.517699956893921\n",
      "\ttrain_iou = 0.0085\n",
      "\ttrain_accuracy = 0.1875\n",
      "\tval_loss = 12.349300384521484\n",
      "\tval_reg_loss = 16.0\n",
      "\tval_cls_loss = 2.3099000453948975\n",
      "\tval_iou = 0.0\n",
      "\tval_accuracy = 0.1875\n",
      "\n",
      "Iteration #:  145\n",
      "\talpha = 0.7367\n",
      "\ttrain_loss = 24.031299591064453\n",
      "\ttrain_reg_loss = 31.741300582885742\n",
      "\ttrain_cls_loss = 2.4553000926971436\n",
      "\ttrain_iou = 0.0081\n",
      "\ttrain_accuracy = 0.031199999153614044\n",
      "\tval_loss = 12.393899917602539\n",
      "\tval_reg_loss = 16.0\n",
      "\tval_cls_loss = 2.302500009536743\n",
      "\tval_iou = 0.0\n",
      "\tval_accuracy = 0.1875\n",
      "\n",
      "Iteration #:  150\n",
      "\talpha = 0.74\n",
      "\ttrain_loss = 24.160900115966797\n",
      "\ttrain_reg_loss = 31.755599975585938\n",
      "\ttrain_cls_loss = 2.5453999042510986\n",
      "\ttrain_iou = 0.0076\n",
      "\ttrain_accuracy = 0.031199999153614044\n",
      "\tval_loss = 12.43649959564209\n",
      "\tval_reg_loss = 16.0\n",
      "\tval_cls_loss = 2.2943999767303467\n",
      "\tval_iou = 0.0\n",
      "\tval_accuracy = 0.1875\n",
      "\n",
      "Iteration #:  155\n",
      "\talpha = 0.7431\n",
      "\ttrain_loss = 24.31279945373535\n",
      "\ttrain_reg_loss = 31.861600875854492\n",
      "\ttrain_cls_loss = 2.472899913787842\n",
      "\ttrain_iou = 0.0043\n",
      "\ttrain_accuracy = 0.031199999153614044\n",
      "\tval_loss = 12.478500366210938\n",
      "\tval_reg_loss = 16.0\n",
      "\tval_cls_loss = 2.290299892425537\n",
      "\tval_iou = 0.0\n",
      "\tval_accuracy = 0.25\n",
      "\n",
      "Iteration #:  160\n",
      "\talpha = 0.7462\n",
      "\ttrain_loss = 24.362699508666992\n",
      "\ttrain_reg_loss = 31.761999130249023\n",
      "\ttrain_cls_loss = 2.6135001182556152\n",
      "\ttrain_iou = 0.0074\n",
      "\ttrain_accuracy = 0.09380000084638596\n",
      "\tval_loss = 12.520700454711914\n",
      "\tval_reg_loss = 16.0\n",
      "\tval_cls_loss = 2.293800115585327\n",
      "\tval_iou = 0.0\n",
      "\tval_accuracy = 0.125\n",
      "\n",
      "Iteration #:  165\n",
      "\talpha = 0.7491\n",
      "\ttrain_loss = 24.436599731445312\n",
      "\ttrain_reg_loss = 31.803300857543945\n",
      "\ttrain_cls_loss = 2.4470999240875244\n",
      "\ttrain_iou = 0.0061\n",
      "\ttrain_accuracy = 0.0625\n",
      "\tval_loss = 12.560600280761719\n",
      "\tval_reg_loss = 16.0\n",
      "\tval_cls_loss = 2.2941999435424805\n",
      "\tval_iou = 0.0\n",
      "\tval_accuracy = 0.1875\n",
      "\n",
      "Iteration #:  170\n",
      "\talpha = 0.7519\n",
      "\ttrain_loss = 24.52239990234375\n",
      "\ttrain_reg_loss = 31.80940055847168\n",
      "\ttrain_cls_loss = 2.4439001083374023\n",
      "\ttrain_iou = 0.006\n",
      "\ttrain_accuracy = 0.15620000660419464\n",
      "\tval_loss = 12.600600242614746\n",
      "\tval_reg_loss = 16.0\n",
      "\tval_cls_loss = 2.3010001182556152\n",
      "\tval_iou = 0.0\n",
      "\tval_accuracy = 0.1875\n",
      "\n",
      "Iteration #:  175\n",
      "\talpha = 0.7545\n",
      "\ttrain_loss = 24.368600845336914\n",
      "\ttrain_reg_loss = 31.44099998474121\n",
      "\ttrain_cls_loss = 2.6275999546051025\n",
      "\ttrain_iou = 0.0175\n",
      "\ttrain_accuracy = 0.09380000084638596\n",
      "\tval_loss = 12.638299942016602\n",
      "\tval_reg_loss = 16.0\n",
      "\tval_cls_loss = 2.30430006980896\n",
      "\tval_iou = 0.0\n",
      "\tval_accuracy = 0.125\n",
      "\n",
      "Iteration #:  180\n",
      "\talpha = 0.7571\n",
      "\ttrain_loss = 24.635700225830078\n",
      "\ttrain_reg_loss = 31.696300506591797\n",
      "\ttrain_cls_loss = 2.6231000423431396\n",
      "\ttrain_iou = 0.0095\n",
      "\ttrain_accuracy = 0.09380000084638596\n",
      "\tval_loss = 12.674099922180176\n",
      "\tval_reg_loss = 16.0\n",
      "\tval_cls_loss = 2.3052000999450684\n",
      "\tval_iou = 0.0\n",
      "\tval_accuracy = 0.125\n",
      "\n",
      "Iteration #:  185\n",
      "\talpha = 0.7596\n",
      "\ttrain_loss = 24.625900268554688\n",
      "\ttrain_reg_loss = 31.637699127197266\n",
      "\ttrain_cls_loss = 2.464600086212158\n",
      "\ttrain_iou = 0.0113\n",
      "\ttrain_accuracy = 0.1875\n",
      "\tval_loss = 12.708700180053711\n",
      "\tval_reg_loss = 16.0\n",
      "\tval_cls_loss = 2.306299924850464\n",
      "\tval_iou = 0.0\n",
      "\tval_accuracy = 0.125\n",
      "\n",
      "Iteration #:  190\n",
      "\talpha = 0.7621\n",
      "\ttrain_loss = 24.8705997467041\n",
      "\ttrain_reg_loss = 31.915700912475586\n",
      "\ttrain_cls_loss = 2.305799961090088\n",
      "\ttrain_iou = 0.0026\n",
      "\ttrain_accuracy = 0.1875\n",
      "\tval_loss = 12.743000030517578\n",
      "\tval_reg_loss = 16.0\n",
      "\tval_cls_loss = 2.3111000061035156\n",
      "\tval_iou = 0.0\n",
      "\tval_accuracy = 0.1875\n",
      "\n",
      "Iteration #:  195\n",
      "\talpha = 0.7644\n",
      "\ttrain_loss = 25.023099899291992\n",
      "\ttrain_reg_loss = 31.943700790405273\n",
      "\ttrain_cls_loss = 2.5683999061584473\n",
      "\ttrain_iou = 0.0018\n",
      "\ttrain_accuracy = 0.09380000084638596\n",
      "\tval_loss = 12.74940013885498\n",
      "\tval_reg_loss = 15.969200134277344\n",
      "\tval_cls_loss = 2.3022000789642334\n",
      "\tval_iou = 0.0019\n",
      "\tval_accuracy = 0.1875\n",
      "\n",
      "Iteration #:  200\n",
      "\talpha = 0.7667\n",
      "\ttrain_loss = 25.052600860595703\n",
      "\ttrain_reg_loss = 31.880699157714844\n",
      "\ttrain_cls_loss = 2.617300033569336\n",
      "\ttrain_iou = 0.0037\n",
      "\ttrain_accuracy = 0.125\n",
      "\tval_loss = 12.757499694824219\n",
      "\tval_reg_loss = 15.943499565124512\n",
      "\tval_cls_loss = 2.289099931716919\n",
      "\tval_iou = 0.0035\n",
      "\tval_accuracy = 0.1875\n",
      "\n"
     ]
    }
   ],
   "source": [
    "train_result = train(\n",
    "    alexnet_model,\n",
    "    optimizer,\n",
    "    train_data,\n",
    "    eval_datasets=[('val', test_data)],\n",
    "    loss_fn=loss_fn,\n",
    "    metrics={\n",
    "        'bbox': [('iou', iou)],\n",
    "        'class_id': [('accuracy', accuracy)]\n",
    "    },\n",
    "    callbacks=[printer],\n",
    "    device=device,\n",
    "    train_steps=config_dict['num_epochs'],\n",
    "    eval_steps=5,\n",
    ")\n",
    "\n",
    "model = train_result['model']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-12-09T18:29:27.927Z"
    }
   },
   "outputs": [],
   "source": [
    "# Data\n",
    "train_ds = MNISTDataset(train_df, root_dir=config_dict['train_images_dir'], transform=train_transforms)\n",
    "test_ds = MNISTDataset(test_df, root_dir=config_dict['train_images_dir'], transform=eval_transforms)\n",
    "\n",
    "train_data = DataLoader(train_ds, batch_size=config_dict['batch_size'], shuffle=True, num_workers=cpu_count())\n",
    "test_data = DataLoader(test_ds, batch_size=config_dict['batch_size'], num_workers=cpu_count())\n",
    "\n",
    "# # Model\n",
    "# model = Model(feature_extractor_model, classifier, regressor).to(device)\n",
    "# summary(model, input_size=(3, config_dict['img_size'], config_dict['img_size']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-08T05:54:57.437122Z",
     "start_time": "2022-12-08T05:54:57.374020Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image To Tensor"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Image normalization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-12-09T18:29:27.961Z"
    }
   },
   "outputs": [],
   "source": [
    "train_ds = MNISTDataset(train_df, root_dir=config_dict['train_images_dir'])\n",
    "\n",
    "means = None \n",
    "stds = None\n",
    "\n",
    "if means is None and stds is None:\n",
    "    means, stds = [], []\n",
    "    pixel_values = [\n",
    "        [], # R, size = H * W * num_images \n",
    "        [], # G size = H * W * num_images\n",
    "        [], # B size = H * W * num_images\n",
    "    ]\n",
    "\n",
    "    for x in train_ds:\n",
    "        img = x['image']\n",
    "\n",
    "        for channel in range(config_dict['num_channels']):\n",
    "            channel_pixel_values = list(img[..., channel].flatten())\n",
    "            pixel_values[channel].extend(channel_pixel_values)\n",
    "\n",
    "    for channel in range(config_dict['num_channels']):\n",
    "        means.append(np.mean(pixel_values[channel]))\n",
    "        stds.append(np.std(pixel_values[channel]))\n",
    "    \n",
    "    del pixel_values\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-12-09T18:29:27.986Z"
    }
   },
   "outputs": [],
   "source": [
    "example_img = cv2.imread(config_dict['train_images_dir']+train_df.iloc[0].filename)\n",
    "example_img = cv2.cvtColor(example_img, cv2.COLOR_BGR2RGB)\n",
    "\n",
    "print(example_img.shape)\n",
    "example_img[..., 0] = 0\n",
    "example_img[..., 2] = 0\n",
    "\n",
    "plt.imshow(example_img)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Definimos el transformador que convertirá una imagen en un tensor."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-06T20:36:22.305769Z",
     "start_time": "2022-12-06T20:36:22.302812Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-12-09T18:29:28.024Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-12-09T18:29:28.044Z"
    }
   },
   "outputs": [],
   "source": [
    "class TVTransformWrapper(object):\n",
    "    \"\"\"Torch Vision Transform Wrapper\n",
    "    \"\"\"\n",
    "    def __init__(self, transform: torch.nn.Module):\n",
    "        self.transform = transform\n",
    "        \n",
    "    def __call__(self, sample):\n",
    "        sample['image'] = self.transform(sample['image'])\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-12-09T18:29:28.059Z"
    }
   },
   "outputs": [],
   "source": [
    "class AlbumentationsWrapper(object):\n",
    "    \n",
    "    def __init__(self, transform):\n",
    "        self.transform = transform\n",
    "    \n",
    "    def __call__(self, sample):\n",
    "        transformed = self.transform(\n",
    "            image=sample['image'], \n",
    "            bboxes=sample['bbox']\n",
    "        )\n",
    "        sample['image'] = transformed['image']\n",
    "        sample['bbox'] = np.array(transformed['bboxes'])\n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-12-09T18:29:28.078Z"
    }
   },
   "outputs": [],
   "source": [
    "common_transforms = [\n",
    "    Normalizer(\n",
    "        means=means,\n",
    "        stds=stds,\n",
    "    ),\n",
    "    ToTensor(img_size=config_dict['img_size']),\n",
    "]"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Data augmentations "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-12-09T18:29:28.093Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-12-09T18:29:28.110Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-12-09T18:29:28.125Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-12-09T18:29:28.139Z"
    }
   },
   "outputs": [],
   "source": [
    "train_ds = MNISTDataset(train_df, root_dir=config_dict['train_images_dir'])\n",
    "\n",
    "x = next(iter(train_ds))\n",
    "x_transformed = copy.deepcopy(x)\n",
    "x_transformed = train_transforms(x_transformed)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-12-09T18:29:28.155Z"
    }
   },
   "outputs": [],
   "source": [
    "# def draw_bbox_transformed(img, bbox, color):\n",
    "#     \"\"\"\n",
    "#     Draw the bounding box on the image.\n",
    "\n",
    "#     Source: https://www.kaggle.com/code/sebastingarcaacosta/tutoria-1\n",
    "\n",
    "#     Args:\n",
    "#         img (list): List of images.\n",
    "#         bbox (list): List of bouding boxes.\n",
    "#         color (list): List of colors.\n",
    "\n",
    "#     Returns:\n",
    "#         img (list): List of images with the bounding box.\n",
    "#     \"\"\"\n",
    "#     xmin, ymin, xmax, ymax = bbox\n",
    "#     img = cv2.cvtColor(img, cv2.COLOR_BGR2RGB) \n",
    "#     img = cv2.rectangle(img, (xmin, ymin), (xmax, ymax), color, 2)\n",
    "#     return img"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-12-09T18:29:28.172Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# original_img = x['image']\n",
    "# transformed_img = x_transformed['image'].numpy().transpose(1, 2, 0)\n",
    "\n",
    "# original_img = draw_bbox(\n",
    "#     original_img,\n",
    "#     normalize_bbox(x['bbox'].squeeze()),\n",
    "#     (0, 255, 0)\n",
    "# )\n",
    "\n",
    "# transformed_img = draw_bbox_transformed(\n",
    "#     transformed_img,\n",
    "#     normalize_bbox(x_transformed['bbox'].squeeze()),\n",
    "#     (0, 255, 0)\n",
    "# )\n",
    "\n",
    "# fig, axes = plt.subplots(nrows=1, ncols=2, figsize=(10, 5))\n",
    "\n",
    "# axes[0].imshow(original_img)\n",
    "# axes[0].set_title('Original digit')\n",
    "\n",
    "# axes[1].imshow(transformed_img)\n",
    "# axes[1].set_title('Transformed digit')\n",
    "\n",
    "# plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-06T20:36:42.052169Z",
     "start_time": "2022-12-06T20:36:41.866679Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-05T04:23:09.551458Z",
     "start_time": "2022-12-05T04:23:09.532874Z"
    }
   },
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-06T20:36:43.329812Z",
     "start_time": "2022-12-06T20:36:43.327038Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-06T20:36:44.165035Z",
     "start_time": "2022-12-06T20:36:44.162070Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model for classification and objects location"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-12-09T18:29:28.224Z"
    }
   },
   "outputs": [],
   "source": [
    "def get_output_shape(model: nn.Sequential, image_dim: ty.Tuple[int, int, int]):\n",
    "    return model(torch.rand(*(image_dim)).to(device)).data.shape"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-06T20:36:45.113233Z",
     "start_time": "2022-12-06T20:36:45.110224Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-12-09T18:29:28.279Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-06T20:36:45.717927Z",
     "start_time": "2022-12-06T20:36:45.675379Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-06T20:36:45.971209Z",
     "start_time": "2022-12-06T20:36:45.930931Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-06T20:36:46.216308Z",
     "start_time": "2022-12-06T20:36:46.205769Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-06T20:36:46.878172Z",
     "start_time": "2022-12-06T20:36:46.835801Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-12-09T18:29:28.369Z"
    }
   },
   "outputs": [],
   "source": [
    "print('image', x['image'].size())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-12-09T18:29:28.381Z"
    }
   },
   "outputs": [],
   "source": [
    "x['image'] = x['image'].to(device)\n",
    "preds = model(x['image'])\n",
    "preds"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Metrics"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-06T20:36:48.864849Z",
     "start_time": "2022-12-06T20:36:48.862559Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-06T20:36:49.276700Z",
     "start_time": "2022-12-06T20:36:49.274273Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-06T20:39:00.887004Z",
     "start_time": "2022-12-06T20:39:00.883484Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Callbacks\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-06T20:39:01.518062Z",
     "start_time": "2022-12-06T20:39:01.514667Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training loop"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-12-09T18:29:28.444Z"
    }
   },
   "outputs": [],
   "source": [
    "def evaluate(\n",
    "    logs: ty.Dict[str, ty.Any], \n",
    "    labels: ty.Dict[str, Tensor],\n",
    "    preds: ty.Dict[str, Tensor],\n",
    "    eval_set: str,\n",
    "    metrics: ty.Dict[str, ty.Callable[[Tensor, Tensor], Tensor]],\n",
    "    losses: ty.Optional[ty.Dict[str, Tensor]] = None,\n",
    ") -> ty.Dict[str, ty.Any]:\n",
    "    \n",
    "    if losses is not None:\n",
    "        for loss_name, loss_value in losses.items():\n",
    "            logs[f'{eval_set}_{loss_name}'] = loss_value\n",
    "    \n",
    "    for task_name, label in labels.items():\n",
    "        for metric_name, metric in metrics[task_name]:\n",
    "            value = metric(label, preds[task_name])\n",
    "            logs[f'{eval_set}_{metric_name}'] = value\n",
    "            \n",
    "    return logs\n",
    "\n",
    "def step(\n",
    "    model: Model, \n",
    "    optimizer: Optimizer, \n",
    "    batch: MNISTDataset,\n",
    "    loss_fn: ty.Callable[[ty.Dict[str, torch.Tensor]], torch.Tensor],\n",
    "    device: str,\n",
    "    train: bool = False,\n",
    ") -> ty.Tuple[ty.Dict[str, Tensor], ty.Dict[str, Tensor]]:\n",
    "    \n",
    "    if train:\n",
    "        optimizer.zero_grad()\n",
    "    \n",
    "    img = batch.pop('image').to(device)\n",
    "    \n",
    "    for k in list(batch.keys()):\n",
    "        batch[k] = batch[k].to(device)\n",
    "    \n",
    "    preds = model(img.float())\n",
    "    losses = loss_fn(batch, preds)\n",
    "    final_loss = losses['loss']\n",
    "    if train:\n",
    "        final_loss.backward()\n",
    "        optimizer.step()\n",
    "    \n",
    "    return losses, preds\n",
    "\n",
    "\n",
    "def train(\n",
    "    model: Model, \n",
    "    optimizer: Optimizer, \n",
    "    dataset: DataLoader,\n",
    "    eval_datasets: ty.List[ty.Tuple[str, DataLoader]],\n",
    "    loss_fn: ty.Callable[[ty.Dict[str, torch.Tensor]], torch.Tensor],\n",
    "    metrics: ty.Dict[str, ty.Callable[[Tensor, Tensor], Tensor]],\n",
    "    callbacks: ty.List[ty.Callable[[ty.Dict[ty.Any, ty.Any]], None]],\n",
    "    device: str,\n",
    "    train_steps: 100,\n",
    "    eval_steps: 10,\n",
    ") -> Model:\n",
    "    # Send model to device (GPU or CPU)\n",
    "    model = model.to(device)\n",
    "    iters = 0\n",
    "    iterator = iter(dataset)\n",
    "    assert train_steps > eval_steps, 'Train steps should be greater than the eval steps'\n",
    "    \n",
    "    while iters <= train_steps:\n",
    "        logs = dict()\n",
    "        logs['iters'] = iters\n",
    "        try:\n",
    "            batch = next(iterator)\n",
    "        except StopIteration:\n",
    "            iterator = iter(dataset)\n",
    "            batch = next(iterator)\n",
    "        # Send batch to device \n",
    "        losses, preds = step(model, optimizer, batch, loss_fn, device, train=True)\n",
    "        logs = evaluate(logs, batch, preds, 'train', metrics, losses)\n",
    "        \n",
    "        # Eval every eval_steps iterations\n",
    "        if iters % eval_steps == 0:        \n",
    "            # Evaluate\n",
    "            # Deactives layers that only needed to train\n",
    "            # https://discuss.pytorch.org/t/model-eval-vs-with-torch-no-grad/19615\n",
    "            model.eval()\n",
    "            \n",
    "            # Avoids calculating gradients in evaluation dataset. \n",
    "            with torch.no_grad():\n",
    "\n",
    "                for name, dataset in eval_datasets:\n",
    "                    for batch in dataset:\n",
    "                        losses, preds = step(model, optimizer, batch, loss_fn, device, train=False)            \n",
    "                        logs = evaluate(logs, batch, preds, name, metrics, losses)\n",
    "        \n",
    "        for callback in callbacks:\n",
    "            callback(logs)\n",
    "        \n",
    "        iters += 1\n",
    "    \n",
    "    return model"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-12-09T18:29:28.463Z"
    }
   },
   "outputs": [],
   "source": [
    "# Data\n",
    "train_ds = MNISTDataset(train_df, root_dir=config_dict['train_images_dir'], transform=train_transforms)\n",
    "test_ds = MNISTDataset(test_df, root_dir=config_dict['train_images_dir'], transform=eval_transforms)\n",
    "\n",
    "train_data = DataLoader(train_ds, batch_size=config_dict['batch_size'], shuffle=True, num_workers=cpu_count())\n",
    "test_data = DataLoader(test_ds, batch_size=config_dict['batch_size'], num_workers=cpu_count())\n",
    "\n",
    "# Model\n",
    "model = Model(feature_extractor_model, classifier, regressor).to(device)\n",
    "summary(model, input_size=(config_dict['num_channels'], config_dict['img_size'], config_dict['img_size']))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-12-09T18:29:28.493Z"
    },
    "scrolled": false
   },
   "outputs": [],
   "source": [
    "# Optimizer\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-06T00:39:02.880741Z",
     "start_time": "2022-12-06T00:39:02.877571Z"
    }
   },
   "source": [
    "## Predictions visualization"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-08T20:03:18.204959Z",
     "start_time": "2022-12-08T20:03:14.994Z"
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-08T20:03:18.205480Z",
     "start_time": "2022-12-08T20:03:14.997Z"
    },
    "scrolled": true
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Save Model"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-12-09T18:29:28.570Z"
    }
   },
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "import time\n",
    "from time import localtime"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-12-09T18:29:28.618Z"
    }
   },
   "outputs": [],
   "source": [
    "date = datetime.fromtimestamp(time.time(), tz=None)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-12-09T18:29:28.653Z"
    }
   },
   "outputs": [],
   "source": [
    "date = date.strftime(\"%Y-%m-%d_%H-%M-%S\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-12-09T18:29:28.686Z"
    }
   },
   "outputs": [],
   "source": [
    "torch.save(model, f'models/{date}-pretrained_model.pth')"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-12-09T18:29:28.709Z"
    }
   },
   "outputs": [],
   "source": [
    "# Perform inference on cpu in order to avoid memory problems \n",
    "device = 'cuda'\n",
    "model = model.to(device)\n",
    "\n",
    "test_df = pd.read_csv('datasets/test.csv')\n",
    "\n",
    "test_ds = MNISTDataset(test_df, root_dir='datasets/images/test/', labeled=False, transform=eval_transforms)\n",
    "test_data = DataLoader(test_ds, batch_size=1, num_workers=cpu_count(), shuffle=False)\n",
    "\n",
    "class_preds = []\n",
    "bbox_preds = []\n",
    "\n",
    "for batch in test_data:\n",
    "    batch_preds = model(batch['image'].float().to(device))\n",
    "    \n",
    "    class_pred = batch_preds['class_id'].argmax(-1).detach().cpu().numpy()\n",
    "    bbox_pred = batch_preds['bbox'].detach().cpu().numpy()\n",
    "    \n",
    "    class_preds.append(class_pred.squeeze())\n",
    "    bbox_preds.append(bbox_pred.squeeze())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-12-09T18:29:28.726Z"
    }
   },
   "outputs": [],
   "source": [
    "class_preds = np.array(class_preds)\n",
    "bbox_preds = np.array(bbox_preds)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-12-09T18:29:28.745Z"
    }
   },
   "outputs": [],
   "source": [
    "submission = pd.DataFrame(\n",
    "    index=test_df.filename,\n",
    "    data={\n",
    "        'class': class_preds,\n",
    "        # Descomentar esta línea cuando generen el archivo de submissions final, \n",
    "        # para incluir las predicciones de su modelo para regresión  \n",
    "        #'bbox': bbox_preds\n",
    "    }\n",
    ")\n",
    "submission"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "ExecuteTime": {
     "start_time": "2022-12-09T18:29:28.768Z"
    }
   },
   "outputs": [],
   "source": [
    "submission.to_csv(f'submissions/{date}_submission.csv')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Tabla de Contenido",
   "title_sidebar": "Contenido",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "276.634px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
