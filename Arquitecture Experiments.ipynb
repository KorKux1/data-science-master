{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "fcd5a397",
   "metadata": {},
   "source": [
    "# Arquitecture Experiments "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "5ae5f93c",
   "metadata": {},
   "source": [
    "En este notebook probaremos varias arquitecturas  y haremos experimentos para encontrar la mejor arquitectura.\n",
    "\n",
    "Para estos esperimentos nos basaremos en el articulo de [25 Million Images! [0.99757] MNIST](https://www.kaggle.com/code/cdeotte/25-million-images-0-99757-mnist/notebook) que nos muestra algunos ejemplos de arquitectura y nos referencia a otras fuentes con modelos que funcionan muy bien para la tarea de clasificación. Para los experimentos nos basaremos en el articulo [How to choose CNN Architecture MNIST](https://www.kaggle.com/code/cdeotte/how-to-choose-cnn-architecture-mnist/) que se encuentra referenciado en el primer articulo; usaremos las conclusiones que llegarón, los replicaremos con nuestro conjunto de datos y plantearemos nuevos experimentos.\n",
    "\n",
    "\n",
    "Las arquitecturas las plantearemos en base a los experimentos y las arquitecturas que ya han sido construidas."
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9f5faf7f",
   "metadata": {
    "toc": true
   },
   "source": [
    "<h1>Table of Contents<span class=\"tocSkip\"></span></h1>\n",
    "<div class=\"toc\"><ul class=\"toc-item\"><li><span><a href=\"#Packages-and-Functions\" data-toc-modified-id=\"Packages-and-Functions-1\"><span class=\"toc-item-num\">1&nbsp;&nbsp;</span>Packages and Functions</a></span><ul class=\"toc-item\"><li><span><a href=\"#Packages\" data-toc-modified-id=\"Packages-1.1\"><span class=\"toc-item-num\">1.1&nbsp;&nbsp;</span>Packages</a></span></li><li><span><a href=\"#Functions\" data-toc-modified-id=\"Functions-1.2\"><span class=\"toc-item-num\">1.2&nbsp;&nbsp;</span>Functions</a></span></li></ul></li><li><span><a href=\"#Project-Config\" data-toc-modified-id=\"Project-Config-2\"><span class=\"toc-item-num\">2&nbsp;&nbsp;</span>Project Config</a></span><ul class=\"toc-item\"><li><span><a href=\"#Configuring-GPU-or-CPU-usage-based-on-available-resources\" data-toc-modified-id=\"Configuring-GPU-or-CPU-usage-based-on-available-resources-2.1\"><span class=\"toc-item-num\">2.1&nbsp;&nbsp;</span>Configuring GPU or CPU usage based on available resources</a></span></li><li><span><a href=\"#Seed-Config\" data-toc-modified-id=\"Seed-Config-2.2\"><span class=\"toc-item-num\">2.2&nbsp;&nbsp;</span>Seed Config</a></span></li></ul></li><li><span><a href=\"#Creating-Dataset-Structure\" data-toc-modified-id=\"Creating-Dataset-Structure-3\"><span class=\"toc-item-num\">3&nbsp;&nbsp;</span>Creating Dataset Structure</a></span><ul class=\"toc-item\"><li><span><a href=\"#Load-dataset\" data-toc-modified-id=\"Load-dataset-3.1\"><span class=\"toc-item-num\">3.1&nbsp;&nbsp;</span>Load dataset</a></span></li><li><span><a href=\"#Constantes-del-proyecto\" data-toc-modified-id=\"Constantes-del-proyecto-3.2\"><span class=\"toc-item-num\">3.2&nbsp;&nbsp;</span>Constantes del proyecto</a></span></li><li><span><a href=\"#Manejo-de-imagenes\" data-toc-modified-id=\"Manejo-de-imagenes-3.3\"><span class=\"toc-item-num\">3.3&nbsp;&nbsp;</span>Manejo de imagenes</a></span></li></ul></li><li><span><a href=\"#Experiments\" data-toc-modified-id=\"Experiments-4\"><span class=\"toc-item-num\">4&nbsp;&nbsp;</span>Experiments</a></span><ul class=\"toc-item\"><li><span><a href=\"#How-many-convolution-subsambling-pairs\" data-toc-modified-id=\"How-many-convolution-subsambling-pairs-4.1\"><span class=\"toc-item-num\">4.1&nbsp;&nbsp;</span>How many convolution-subsambling pairs</a></span></li></ul></li></ul></div>"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "7f05dd2f",
   "metadata": {},
   "source": [
    "## Packages and Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "id": "3fff0d7f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-08T22:55:39.033371Z",
     "start_time": "2022-12-08T22:55:39.031382Z"
    }
   },
   "outputs": [],
   "source": [
    "CUDA_LAUNCH_BLOCKING=\"1\""
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91821497",
   "metadata": {},
   "source": [
    "### Packages"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "a95f1407",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-08T22:58:42.855547Z",
     "start_time": "2022-12-08T22:58:42.852557Z"
    }
   },
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import sys\n",
    "import typing as ty\n",
    "from numpy.typing import NDArray\n",
    "import os\n",
    "\n",
    "from skimage import io\n",
    "from torchvision.transforms.functional import resize\n",
    "import cv2\n",
    "import torchvision\n",
    "\n",
    "\n",
    "\n",
    "from sklearn.model_selection import train_test_split\n",
    "\n",
    "\n",
    "import torch\n",
    "from torch import nn\n",
    "from torch.nn import CrossEntropyLoss\n",
    "from torch.utils.data import Dataset\n",
    "from torchsummary import summary\n",
    "from torch import Tensor\n",
    "import torch.nn.functional as F\n",
    "\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d2f9d2c1",
   "metadata": {},
   "source": [
    "### Functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "7ece3203",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-08T22:58:43.724692Z",
     "start_time": "2022-12-08T22:58:43.722346Z"
    }
   },
   "outputs": [],
   "source": [
    "sys.path.append(\"custom_utils/\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "fb3868cc",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-08T22:58:44.816604Z",
     "start_time": "2022-12-08T22:58:44.814126Z"
    }
   },
   "outputs": [],
   "source": [
    "from bounding_boxes import MNISTDataset, normalize_bbox, draw_predictions, draw_bbox\n",
    "from models import FeatureExtractor, ClassificationHead, RegressionHead, train\n",
    "from constants import load_config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 32,
   "id": "e7eee075",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-08T22:58:45.961808Z",
     "start_time": "2022-12-08T22:58:45.957679Z"
    },
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<module 'constants' from '/workspace/study/datascience_master/Analytics Fundamentals 2/challenges/second_challange/constants.py'>"
      ]
     },
     "execution_count": 32,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "import importlib\n",
    "\n",
    "importlib.reload(sys.modules[\"bounding_boxes\"])\n",
    "importlib.reload(sys.modules[\"models\"])\n",
    "importlib.reload(sys.modules[\"constants\"])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9fca054c",
   "metadata": {},
   "source": [
    "## Project Config"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c33f9ca1",
   "metadata": {},
   "source": [
    "### Configuring GPU or CPU usage based on available resources"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "13f20a44",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-08T22:58:47.052281Z",
     "start_time": "2022-12-08T22:58:47.049818Z"
    }
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Using cuda\n"
     ]
    }
   ],
   "source": [
    "device = 'cuda' if torch.cuda.is_available() else 'cpu'\n",
    "print(f'Using {device}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "242804f0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-08T22:58:48.114387Z",
     "start_time": "2022-12-08T22:58:48.111114Z"
    }
   },
   "outputs": [],
   "source": [
    "test = torch.ones((100, 100)).to(device)\n",
    "del test\n",
    "torch.cuda.empty_cache()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cf7ab0d6",
   "metadata": {},
   "source": [
    "### Seed Config"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 35,
   "id": "23571b13",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-08T22:58:49.193458Z",
     "start_time": "2022-12-08T22:58:49.190710Z"
    }
   },
   "outputs": [],
   "source": [
    "seed = 42\n",
    "\n",
    "torch.backends.cudnn.enabled = True\n",
    "torch.manual_seed(seed)\n",
    "np.random.seed(seed)\n",
    "\n",
    "if(device == 'cuda'):\n",
    "    torch.cuda.manual_seed(seed)\n",
    "    torch.cuda.manual_seed_all(seed)\n",
    "    torch.backends.cudnn.deterministic = True\n",
    "    torch.backends.cudnn.benchmark = False"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "cec8f2f4",
   "metadata": {},
   "source": [
    "## Creating Dataset Structure"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a1da509e",
   "metadata": {},
   "source": [
    "### Load dataset"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 36,
   "id": "08d8f13f",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-08T22:58:50.278122Z",
     "start_time": "2022-12-08T22:58:50.270964Z"
    }
   },
   "outputs": [],
   "source": [
    "df = pd.read_csv(\"datasets/train.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 37,
   "id": "c9e63ac1",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-08T22:58:51.389088Z",
     "start_time": "2022-12-08T22:58:51.386668Z"
    }
   },
   "outputs": [],
   "source": [
    "df.rename(columns={\"class\": \"class_id\"}, inplace=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 38,
   "id": "a12d5fd2",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-08T22:58:52.494820Z",
     "start_time": "2022-12-08T22:58:52.489515Z"
    }
   },
   "outputs": [],
   "source": [
    "train_df, test_df = train_test_split(\n",
    "    df, stratify=df['class_id'], test_size=0.15, random_state=seed\n",
    ")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "92241045",
   "metadata": {},
   "source": [
    "### Constantes del proyecto"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 39,
   "id": "fbf5dbe7",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-08T22:58:53.548861Z",
     "start_time": "2022-12-08T22:58:53.547178Z"
    }
   },
   "outputs": [],
   "source": [
    "config_dict = load_config()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "3113acf7",
   "metadata": {},
   "source": [
    "### Manejo de imagenes"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 40,
   "id": "ce77ab11",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-08T22:58:54.617367Z",
     "start_time": "2022-12-08T22:58:54.615377Z"
    }
   },
   "outputs": [],
   "source": [
    "transform_func_inp_signature = ty.Dict[str, NDArray[np.float_]]\n",
    "\n",
    "transform_func_signature = ty.Callable[\n",
    "    [transform_func_inp_signature],\n",
    "    transform_func_inp_signature\n",
    "]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 41,
   "id": "da823710",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-08T22:58:55.692450Z",
     "start_time": "2022-12-08T22:58:55.687294Z"
    }
   },
   "outputs": [],
   "source": [
    "class MNISTDataset(Dataset):\n",
    "    \"\"\"\n",
    "    Location MNIST dataset.\n",
    "\n",
    "    This class is used to load the MNIST dataset and to apply the transformations to the images.\n",
    "\n",
    "    Source: https://www.kaggle.com/code/sebastingarcaacosta/tutoria-1\n",
    "    \n",
    "    Args:\n",
    "        df (pandas.DataFrame): DataFrame with the data.\n",
    "        root_dir (string): Root directory of dataset where directory\n",
    "            ``train`` and  ``test`` exist.\n",
    "        labeled (bool): If True, the dataset is labeled.\n",
    "        transform (callable, optional): A function/transform that  takes in an PIL image\n",
    "            and returns a transformed version.\n",
    "    \"\"\"\n",
    "    def __init__(\n",
    "        self, \n",
    "        df: pd.DataFrame, \n",
    "        root_dir: str, \n",
    "        labeled: bool = True,\n",
    "        transform: ty.Optional[ty.List[transform_func_signature]] = None,\n",
    "        gray: bool= False\n",
    "    ) -> None:\n",
    "        self.df = df\n",
    "        self.root_dir = root_dir\n",
    "        self.transform = transform\n",
    "        self.labeled = labeled\n",
    "        self.gray = gray\n",
    "        \n",
    "    def __len__(self):\n",
    "        return self.df.shape[0]\n",
    "    \n",
    "    def __getitem__(self, idx: int) -> transform_func_signature: \n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx.tolist()\n",
    "        \n",
    "        # Read image\n",
    "        img_name = os.path.join(self.root_dir, self.df.filename.iloc[idx])\n",
    "        image = io.imread(img_name)\n",
    "        \n",
    "        # Convert from gray to RGB\n",
    "        if not self.gray:\n",
    "            image = cv2.cvtColor(image,cv2.COLOR_GRAY2RGB)\n",
    "\n",
    "        sample = {'image': image}\n",
    "        \n",
    "        if self.labeled:\n",
    "            # Read labels\n",
    "            img_class = self.df.class_id.iloc[idx]\n",
    "            img_bbox = self.df.iloc[idx, 2:]\n",
    "\n",
    "            img_bbox = np.array([img_bbox]).astype('float')\n",
    "            img_class = np.array([img_class]).astype('int')\n",
    "            sample.update({'bbox': img_bbox, 'class_id': img_class})\n",
    "        \n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "        \n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "107ea97b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-08T22:58:56.790787Z",
     "start_time": "2022-12-08T22:58:56.788028Z"
    }
   },
   "outputs": [],
   "source": [
    "class ToTensor(object):\n",
    "    \"\"\"Convert ndarrays in sample to Tensors.\"\"\"\n",
    "    \n",
    "    def __init__(self, img_size, gray: False):\n",
    "        self.img_size = img_size\n",
    "        self.gray = gray\n",
    "\n",
    "    def __call__(self, sample):\n",
    "        image = sample['image']\n",
    "        # swap color axis because\n",
    "        # numpy image: H x W x C\n",
    "        # torch image: C x H x W\n",
    "        if(self.gray):\n",
    "            image = np.expand_dims(image, axis=2)\n",
    "            \n",
    "        image = image.transpose((2, 0, 1))\n",
    "        image = torch.from_numpy(image).float()\n",
    "        image = resize(image, (self.img_size, self.img_size))\n",
    "        sample.update({'image': image})\n",
    "        return sample\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "e863308b",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-08T22:58:57.862655Z",
     "start_time": "2022-12-08T22:58:57.860913Z"
    }
   },
   "outputs": [],
   "source": [
    "gray_images = True"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "dba957cf",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-08T22:58:58.962906Z",
     "start_time": "2022-12-08T22:58:58.942644Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "torch.Size([32, 1, 28, 28])\n"
     ]
    }
   ],
   "source": [
    "train_ds = MNISTDataset(train_df, root_dir=config_dict['train_images_dir'], gray=gray_images, transform=ToTensor(img_size=config_dict['img_size'], gray=gray_images))\n",
    "train_data = torch.utils.data.DataLoader(train_ds, batch_size=config_dict['batch_size'])\n",
    "\n",
    "test_ds = MNISTDataset(test_df, root_dir=config_dict['train_images_dir'], gray=gray_images, transform=ToTensor(img_size=config_dict['img_size'], gray=gray_images))\n",
    "test_data = torch.utils.data.DataLoader(test_ds, batch_size=config_dict['batch_size'])\n",
    "\n",
    "for x in train_data:\n",
    "    print(x['image'].size())\n",
    "    break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "4088de0d",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-08T22:59:00.023557Z",
     "start_time": "2022-12-08T22:59:00.020846Z"
    }
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<torch.utils.data.dataloader.DataLoader at 0x7f605ffbbd00>"
      ]
     },
     "execution_count": 45,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_data"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "ecf7f25c",
   "metadata": {},
   "source": [
    "## Experiments"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "06a288dc",
   "metadata": {},
   "source": [
    "### How many convolution-subsambling pairs"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "1b566dd0",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-08T22:59:01.124654Z",
     "start_time": "2022-12-08T22:59:01.118388Z"
    }
   },
   "outputs": [],
   "source": [
    "nets = 3\n",
    "models = [0] *nets\n",
    "\n",
    "for j in range(nets): \n",
    "    modules = []\n",
    "    modules.append(nn.Conv2d(1, 24, kernel_size=5, padding=(2,2)))\n",
    "    modules.append(nn.ReLU())\n",
    "    modules.append(nn.MaxPool2d(kernel_size=5))\n",
    "    out_shape = 600\n",
    "\n",
    "    if(j > 0):\n",
    "        modules.append(nn.Conv2d(24, 48, kernel_size=5, padding=(2,2)))\n",
    "        modules.append(nn.ReLU())\n",
    "        modules.append(nn.MaxPool2d(kernel_size=5))\n",
    "        out_shape = 48\n",
    "    if(j > 1):\n",
    "        modules.append(nn.Conv2d(48, 64, kernel_size=5, padding=(2,2)))\n",
    "        modules.append(nn.ReLU())\n",
    "        modules.append(nn.MaxPool2d(kernel_size=5, padding=(2,2)))\n",
    "        out_shape = 64\n",
    "    modules.append(nn.Flatten()) \n",
    "    model = nn.Sequential(*modules)    \n",
    "    models[j] = {'model': model, 'output_shape': out_shape}\n",
    "\n",
    "\n",
    "    \n",
    "#     model[j] = Sequential()\n",
    "#     model[j].add(Conv2D(24,kernel_size=5,padding='same',activation='relu',\n",
    "#             input_shape=(28,28,1)))\n",
    "#     model[j].add(MaxPool2D())\n",
    "#     if j>0:\n",
    "#         model[j].add(Conv2D(48,kernel_size=5,padding='same',activation='relu'))\n",
    "#         model[j].add(MaxPool2D())\n",
    "#     if j>1:\n",
    "#         model[j].add(Conv2D(64,kernel_size=5,padding='same',activation='relu'))\n",
    "#         model[j].add(MaxPool2D(padding='same'))\n",
    "#     model[j].add(Flatten())\n",
    "#     model[j].add(Dense(256, activation='relu'))\n",
    "#     model[j].add(Dense(10, activation='softmax'))\n",
    "#     model[j].compile(optimizer=\"adam\", loss=\"categorical_crossentropy\", metrics=[\"accuracy\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 47,
   "id": "061a5095",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-08T22:59:02.324012Z",
     "start_time": "2022-12-08T22:59:02.307010Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(C-P)x1\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 24, 28, 28]             624\n",
      "              ReLU-2           [-1, 24, 28, 28]               0\n",
      "         MaxPool2d-3             [-1, 24, 5, 5]               0\n",
      "           Flatten-4                  [-1, 600]               0\n",
      "================================================================\n",
      "Total params: 624\n",
      "Trainable params: 624\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.30\n",
      "Params size (MB): 0.00\n",
      "Estimated Total Size (MB): 0.30\n",
      "----------------------------------------------------------------\n",
      "(C-P)x2\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 24, 28, 28]             624\n",
      "              ReLU-2           [-1, 24, 28, 28]               0\n",
      "         MaxPool2d-3             [-1, 24, 5, 5]               0\n",
      "            Conv2d-4             [-1, 48, 5, 5]          28,848\n",
      "              ReLU-5             [-1, 48, 5, 5]               0\n",
      "         MaxPool2d-6             [-1, 48, 1, 1]               0\n",
      "           Flatten-7                   [-1, 48]               0\n",
      "================================================================\n",
      "Total params: 29,472\n",
      "Trainable params: 29,472\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.31\n",
      "Params size (MB): 0.11\n",
      "Estimated Total Size (MB): 0.43\n",
      "----------------------------------------------------------------\n",
      "(C-P)x3\n",
      "----------------------------------------------------------------\n",
      "        Layer (type)               Output Shape         Param #\n",
      "================================================================\n",
      "            Conv2d-1           [-1, 24, 28, 28]             624\n",
      "              ReLU-2           [-1, 24, 28, 28]               0\n",
      "         MaxPool2d-3             [-1, 24, 5, 5]               0\n",
      "            Conv2d-4             [-1, 48, 5, 5]          28,848\n",
      "              ReLU-5             [-1, 48, 5, 5]               0\n",
      "         MaxPool2d-6             [-1, 48, 1, 1]               0\n",
      "            Conv2d-7             [-1, 64, 1, 1]          76,864\n",
      "              ReLU-8             [-1, 64, 1, 1]               0\n",
      "         MaxPool2d-9             [-1, 64, 1, 1]               0\n",
      "          Flatten-10                   [-1, 64]               0\n",
      "================================================================\n",
      "Total params: 106,336\n",
      "Trainable params: 106,336\n",
      "Non-trainable params: 0\n",
      "----------------------------------------------------------------\n",
      "Input size (MB): 0.00\n",
      "Forward/backward pass size (MB): 0.31\n",
      "Params size (MB): 0.41\n",
      "Estimated Total Size (MB): 0.72\n",
      "----------------------------------------------------------------\n"
     ]
    }
   ],
   "source": [
    "names = [\"(C-P)x1\",\"(C-P)x2\",\"(C-P)x3\"]\n",
    "\n",
    "for j in range(nets):\n",
    "    print(names[j])\n",
    "    summary(models[j]['model'].to(device), input_size=(1,28,28))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 48,
   "id": "74b824b9",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-08T22:59:03.464016Z",
     "start_time": "2022-12-08T22:59:03.460901Z"
    }
   },
   "outputs": [],
   "source": [
    "def loss_fn(\n",
    "    y_true, \n",
    "    y_preds, \n",
    "    cls_loss_fn: CrossEntropyLoss, \n",
    "    bbox_loss_fn: ty.Callable[[ty.Dict[str, torch.Tensor]], torch.Tensor],  \n",
    "    alpha: float = 0.5\n",
    "):\n",
    "    cls_y_true, cls_y_pred = y_true['class_id'].long(), y_preds['class_id'].float().unsqueeze(-1)\n",
    "    reg_y_true, reg_y_pred = y_true['bbox'].float().squeeze(), y_preds['bbox'].float().squeeze()\n",
    "    \n",
    "    cls_loss = F.cross_entropy(cls_y_pred, cls_y_true)\n",
    "    reg_loss = F.mse_loss(reg_y_pred, reg_y_true)\n",
    "    \n",
    "    # Adds weights to both tasks\n",
    "    total_loss = (1 - alpha) * cls_loss + alpha * reg_loss\n",
    "    return dict(loss=total_loss, reg_loss=reg_loss,cls_loss=cls_loss)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 49,
   "id": "96fa0eb4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-08T22:59:04.586430Z",
     "start_time": "2022-12-08T22:59:04.584339Z"
    }
   },
   "outputs": [],
   "source": [
    "def iou(y_true: Tensor, y_pred: Tensor):\n",
    "    pairwise_iou = torchvision.ops.box_iou(y_true.squeeze(), y_pred.squeeze())\n",
    "    result = torch.trace(pairwise_iou) / pairwise_iou.size()[0]\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "87275f54",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-08T22:59:05.670525Z",
     "start_time": "2022-12-08T22:59:05.668116Z"
    }
   },
   "outputs": [],
   "source": [
    "def accuracy(y_true: Tensor, y_pred: Tensor):\n",
    "    pred = torch.argmax(y_pred, axis=-1)\n",
    "    y_true = y_true.squeeze()\n",
    "    correct = torch.eq(pred, y_true).float()\n",
    "    total = torch.ones_like(correct)\n",
    "    result = torch.divide(torch.sum(correct), torch.sum(total))\n",
    "    return result"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 51,
   "id": "ecb05c31",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-08T22:59:06.752868Z",
     "start_time": "2022-12-08T22:59:06.749962Z"
    }
   },
   "outputs": [],
   "source": [
    "def printer(logs: ty.Dict[str, ty.Any]):\n",
    "    # print every 5 steps\n",
    "    if logs['iters'] % 5 != 0:\n",
    "        return\n",
    "    print('Iteration #: ',logs['iters'])\n",
    "    for name, value in logs.items():\n",
    "        if name == 'iters':\n",
    "            continue\n",
    "        \n",
    "        if type(value) in [float, int]:\n",
    "            value = round(value, 4)\n",
    "        elif type(value) is torch.Tensor:\n",
    "            value = value.detach().cpu().numpy()\n",
    "            value = np.round(value, 4)\n",
    "            value = torch.from_numpy(np.asarray(value))\n",
    "            value.to(device)\n",
    "            \n",
    "#             value = torch.round(value, decimals=4)\n",
    "        \n",
    "        print(f'\\t{name} = {value}')\n",
    "    print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 52,
   "id": "460dd086",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-08T22:59:07.821022Z",
     "start_time": "2022-12-08T22:59:07.818159Z"
    }
   },
   "outputs": [],
   "source": [
    "class RegressionHead(nn.Module):\n",
    "    \"\"\"Regression head for the model.\"\"\"\n",
    "    def __init__(self, input_size: int):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.model = nn.Sequential(\n",
    "#             nn.Linear(self.input_size, 768),\n",
    "#             nn.ReLU(),\n",
    "            nn.Linear(self.input_size, 256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, 4)\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 53,
   "id": "71583303",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-08T22:59:08.957729Z",
     "start_time": "2022-12-08T22:59:08.955101Z"
    }
   },
   "outputs": [],
   "source": [
    "class ClassificationHead(nn.Module):\n",
    "    \"\"\"Classification head for the model.\"\"\"\n",
    "    def __init__(self, input_size: int, n_classes: int):\n",
    "        super().__init__()\n",
    "        self.input_size = input_size\n",
    "        self.n_classes = n_classes\n",
    "        \n",
    "        self.model = nn.Sequential(\n",
    "            nn.Linear(in_features=input_size, out_features=256),\n",
    "            nn.ReLU(),\n",
    "            nn.Linear(256, config_dict['num_classes']),\n",
    "            nn.Softmax()\n",
    "        )\n",
    "    \n",
    "    def forward(self, x):\n",
    "        return self.model(x)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 54,
   "id": "6ba62ed4",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-08T22:59:10.049924Z",
     "start_time": "2022-12-08T22:59:10.047320Z"
    }
   },
   "outputs": [],
   "source": [
    "class Model(nn.Module):\n",
    "    def __init__(self, backbone: FeatureExtractor, classifier: ClassificationHead, regressor: RegressionHead):\n",
    "        super().__init__()\n",
    "        self.backbone = backbone\n",
    "        self.cls_head = classifier\n",
    "        self.reg_head = regressor\n",
    "        \n",
    "    def forward(self, x):\n",
    "        features = self.backbone(x)\n",
    "        cls_logits = self.cls_head(features)\n",
    "        pred_bbox = self.reg_head(features)\n",
    "        predictions = {'bbox': pred_bbox, 'class_id': cls_logits}\n",
    "        return predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6a35295c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "68f7975c",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 55,
   "id": "11a19c65",
   "metadata": {
    "ExecuteTime": {
     "end_time": "2022-12-08T23:00:10.350459Z",
     "start_time": "2022-12-08T22:59:11.213445Z"
    },
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/opt/conda/lib/python3.8/site-packages/torch/nn/modules/container.py:139: UserWarning: Implicit dimension choice for softmax has been deprecated. Change the call to include dim=X as an argument.\n",
      "  input = module(input)\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Iteration #:  0\n",
      "\ttrain_loss = 19.970699310302734\n",
      "\ttrain_reg_loss = 37.71860122680664\n",
      "\ttrain_cls_loss = 2.2228000164031982\n",
      "\ttrain_iou = 0.0\n",
      "\ttrain_accuracy = 0.21879999339580536\n",
      "\tval_loss = 18.432100296020508\n",
      "\tval_reg_loss = 34.496700286865234\n",
      "\tval_cls_loss = 2.3673999309539795\n",
      "\tval_iou = 0.0\n",
      "\tval_accuracy = 0.0625\n",
      "\n",
      "Iteration #:  5\n",
      "\ttrain_loss = 20.339500427246094\n",
      "\ttrain_reg_loss = 38.38479995727539\n",
      "\ttrain_cls_loss = 2.2941999435424805\n",
      "\ttrain_iou = 0.0001\n",
      "\ttrain_accuracy = 0.15620000660419464\n",
      "\tval_loss = 18.41670036315918\n",
      "\tval_reg_loss = 34.46609878540039\n",
      "\tval_cls_loss = 2.3673999309539795\n",
      "\tval_iou = 0.0\n",
      "\tval_accuracy = 0.0625\n",
      "\n",
      "Iteration #:  10\n",
      "\ttrain_loss = 22.706300735473633\n",
      "\ttrain_reg_loss = 43.1161003112793\n",
      "\ttrain_cls_loss = 2.2964000701904297\n",
      "\ttrain_iou = 0.0011\n",
      "\ttrain_accuracy = 0.15620000660419464\n",
      "\tval_loss = 18.394399642944336\n",
      "\tval_reg_loss = 34.42129898071289\n",
      "\tval_cls_loss = 2.367500066757202\n",
      "\tval_iou = 0.0\n",
      "\tval_accuracy = 0.0625\n",
      "\n",
      "Iteration #:  15\n",
      "\ttrain_loss = 14.381799697875977\n",
      "\ttrain_reg_loss = 26.521299362182617\n",
      "\ttrain_cls_loss = 2.242300033569336\n",
      "\ttrain_iou = 0.0001\n",
      "\ttrain_accuracy = 0.21879999339580536\n",
      "\tval_loss = 18.375499725341797\n",
      "\tval_reg_loss = 34.38359832763672\n",
      "\tval_cls_loss = 2.367500066757202\n",
      "\tval_iou = 0.0\n",
      "\tval_accuracy = 0.0625\n",
      "\n",
      "Iteration #:  20\n",
      "\ttrain_loss = 16.03230094909668\n",
      "\ttrain_reg_loss = 29.631500244140625\n",
      "\ttrain_cls_loss = 2.433199882507324\n",
      "\ttrain_iou = 0.0003\n",
      "\ttrain_accuracy = 0.0\n",
      "\tval_loss = 18.3533992767334\n",
      "\tval_reg_loss = 34.33919906616211\n",
      "\tval_cls_loss = 2.3675999641418457\n",
      "\tval_iou = 0.0\n",
      "\tval_accuracy = 0.0625\n",
      "\n",
      "Iteration #:  25\n",
      "\ttrain_loss = 16.809099197387695\n",
      "\ttrain_reg_loss = 31.263900756835938\n",
      "\ttrain_cls_loss = 2.354300022125244\n",
      "\ttrain_iou = 0.0003\n",
      "\ttrain_accuracy = 0.09380000084638596\n",
      "\tval_loss = 18.337400436401367\n",
      "\tval_reg_loss = 34.30730056762695\n",
      "\tval_cls_loss = 2.367500066757202\n",
      "\tval_iou = 0.0\n",
      "\tval_accuracy = 0.0625\n",
      "\n",
      "Iteration #:  30\n",
      "\ttrain_loss = 19.034099578857422\n",
      "\ttrain_reg_loss = 35.7489013671875\n",
      "\ttrain_cls_loss = 2.3192999362945557\n",
      "\ttrain_iou = 0.0003\n",
      "\ttrain_accuracy = 0.15620000660419464\n",
      "\tval_loss = 18.313499450683594\n",
      "\tval_reg_loss = 34.259498596191406\n",
      "\tval_cls_loss = 2.3675999641418457\n",
      "\tval_iou = 0.0\n",
      "\tval_accuracy = 0.0625\n",
      "\n",
      "Iteration #:  0\n",
      "\ttrain_loss = 21.505399703979492\n",
      "\ttrain_reg_loss = 40.602500915527344\n",
      "\ttrain_cls_loss = 2.4082999229431152\n",
      "\ttrain_iou = 0.0\n",
      "\ttrain_accuracy = 0.0\n",
      "\tval_loss = 23.11009979248047\n",
      "\tval_reg_loss = 43.90999984741211\n",
      "\tval_cls_loss = 2.3101000785827637\n",
      "\tval_iou = 0.0\n",
      "\tval_accuracy = 0.125\n",
      "\n",
      "Iteration #:  5\n",
      "\ttrain_loss = 21.763399124145508\n",
      "\ttrain_reg_loss = 41.23320007324219\n",
      "\ttrain_cls_loss = 2.2934999465942383\n",
      "\ttrain_iou = 0.0\n",
      "\ttrain_accuracy = 0.15620000660419464\n",
      "\tval_loss = 21.891000747680664\n",
      "\tval_reg_loss = 41.471500396728516\n",
      "\tval_cls_loss = 2.3104000091552734\n",
      "\tval_iou = 0.0\n",
      "\tval_accuracy = 0.125\n",
      "\n",
      "Iteration #:  10\n",
      "\ttrain_loss = 18.756000518798828\n",
      "\ttrain_reg_loss = 35.1864013671875\n",
      "\ttrain_cls_loss = 2.325500011444092\n",
      "\ttrain_iou = 0.0\n",
      "\ttrain_accuracy = 0.125\n",
      "\tval_loss = 20.71940040588379\n",
      "\tval_reg_loss = 39.12820053100586\n",
      "\tval_cls_loss = 2.3106000423431396\n",
      "\tval_iou = 0.0\n",
      "\tval_accuracy = 0.125\n",
      "\n",
      "Iteration #:  15\n",
      "\ttrain_loss = 21.816600799560547\n",
      "\ttrain_reg_loss = 41.292198181152344\n",
      "\ttrain_cls_loss = 2.34089994430542\n",
      "\ttrain_iou = 0.0\n",
      "\ttrain_accuracy = 0.125\n",
      "\tval_loss = 19.596200942993164\n",
      "\tval_reg_loss = 36.88169860839844\n",
      "\tval_cls_loss = 2.3106000423431396\n",
      "\tval_iou = 0.0\n",
      "\tval_accuracy = 0.125\n",
      "\n",
      "Iteration #:  20\n",
      "\ttrain_loss = 17.32939910888672\n",
      "\ttrain_reg_loss = 32.35580062866211\n",
      "\ttrain_cls_loss = 2.302999973297119\n",
      "\ttrain_iou = 0.0\n",
      "\ttrain_accuracy = 0.125\n",
      "\tval_loss = 18.520200729370117\n",
      "\tval_reg_loss = 34.729801177978516\n",
      "\tval_cls_loss = 2.3106000423431396\n",
      "\tval_iou = 0.0\n",
      "\tval_accuracy = 0.125\n",
      "\n",
      "Iteration #:  25\n",
      "\ttrain_loss = 18.325199127197266\n",
      "\ttrain_reg_loss = 34.295799255371094\n",
      "\ttrain_cls_loss = 2.354599952697754\n",
      "\ttrain_iou = 0.0\n",
      "\ttrain_accuracy = 0.0625\n",
      "\tval_loss = 17.505800247192383\n",
      "\tval_reg_loss = 32.700801849365234\n",
      "\tval_cls_loss = 2.310800075531006\n",
      "\tval_iou = 0.0\n",
      "\tval_accuracy = 0.125\n",
      "\n",
      "Iteration #:  30\n",
      "\ttrain_loss = 19.19540023803711\n",
      "\ttrain_reg_loss = 36.09189987182617\n",
      "\ttrain_cls_loss = 2.298799991607666\n",
      "\ttrain_iou = 0.0\n",
      "\ttrain_accuracy = 0.15620000660419464\n",
      "\tval_loss = 16.53849983215332\n",
      "\tval_reg_loss = 30.76609992980957\n",
      "\tval_cls_loss = 2.3108999729156494\n",
      "\tval_iou = 0.0\n",
      "\tval_accuracy = 0.125\n",
      "\n",
      "Iteration #:  0\n",
      "\ttrain_loss = 1.5424000024795532\n",
      "\ttrain_reg_loss = 0.7853999733924866\n",
      "\ttrain_cls_loss = 2.299499988555908\n",
      "\ttrain_iou = 0.0\n",
      "\ttrain_accuracy = 0.15620000660419464\n",
      "\tval_loss = 1.4630000591278076\n",
      "\tval_reg_loss = 0.6240000128746033\n",
      "\tval_cls_loss = 2.302000045776367\n",
      "\tval_iou = 0.0\n",
      "\tval_accuracy = 0.125\n",
      "\n",
      "Iteration #:  5\n",
      "\ttrain_loss = 1.4980000257492065\n",
      "\ttrain_reg_loss = 0.6945000290870667\n",
      "\ttrain_cls_loss = 2.3015999794006348\n",
      "\ttrain_iou = 0.0\n",
      "\ttrain_accuracy = 0.031199999153614044\n",
      "\tval_loss = 1.4377000331878662\n",
      "\tval_reg_loss = 0.574400007724762\n",
      "\tval_cls_loss = 2.3010001182556152\n",
      "\tval_iou = 0.0\n",
      "\tval_accuracy = 0.125\n",
      "\n",
      "Iteration #:  10\n",
      "\ttrain_loss = 1.4407000541687012\n",
      "\ttrain_reg_loss = 0.5817000269889832\n",
      "\ttrain_cls_loss = 2.2997000217437744\n",
      "\ttrain_iou = 0.0\n",
      "\ttrain_accuracy = 0.1875\n",
      "\tval_loss = 1.4142999649047852\n",
      "\tval_reg_loss = 0.5285000205039978\n",
      "\tval_cls_loss = 2.299999952316284\n",
      "\tval_iou = 0.0\n",
      "\tval_accuracy = 0.125\n",
      "\n",
      "Iteration #:  15\n",
      "\ttrain_loss = 1.454699993133545\n",
      "\ttrain_reg_loss = 0.6101999878883362\n",
      "\ttrain_cls_loss = 2.299099922180176\n",
      "\ttrain_iou = 0.0\n",
      "\ttrain_accuracy = 0.0625\n",
      "\tval_loss = 1.391800045967102\n",
      "\tval_reg_loss = 0.4846999943256378\n",
      "\tval_cls_loss = 2.2988998889923096\n",
      "\tval_iou = 0.0\n",
      "\tval_accuracy = 0.125\n",
      "\n",
      "Iteration #:  20\n",
      "\ttrain_loss = 1.434399962425232\n",
      "\ttrain_reg_loss = 0.5692999958992004\n",
      "\ttrain_cls_loss = 2.299499988555908\n",
      "\ttrain_iou = 0.0\n",
      "\ttrain_accuracy = 0.15620000660419464\n",
      "\tval_loss = 1.3708000183105469\n",
      "\tval_reg_loss = 0.4438999891281128\n",
      "\tval_cls_loss = 2.2976999282836914\n",
      "\tval_iou = 0.0\n",
      "\tval_accuracy = 0.125\n",
      "\n",
      "Iteration #:  25\n",
      "\ttrain_loss = 1.4266999959945679\n",
      "\ttrain_reg_loss = 0.5490999817848206\n",
      "\ttrain_cls_loss = 2.30430006980896\n",
      "\ttrain_iou = 0.0\n",
      "\ttrain_accuracy = 0.031199999153614044\n",
      "\tval_loss = 1.3514000177383423\n",
      "\tval_reg_loss = 0.40639999508857727\n",
      "\tval_cls_loss = 2.2964000701904297\n",
      "\tval_iou = 0.0\n",
      "\tval_accuracy = 0.125\n",
      "\n",
      "Iteration #:  30\n",
      "\ttrain_loss = 1.3911999464035034\n",
      "\ttrain_reg_loss = 0.48919999599456787\n",
      "\ttrain_cls_loss = 2.293100118637085\n",
      "\ttrain_iou = 0.0\n",
      "\ttrain_accuracy = 0.125\n",
      "\tval_loss = 1.3339999914169312\n",
      "\tval_reg_loss = 0.3727000057697296\n",
      "\tval_cls_loss = 2.295300006866455\n",
      "\tval_iou = 0.0\n",
      "\tval_accuracy = 0.125\n",
      "\n"
     ]
    }
   ],
   "source": [
    "trained_models = [0] * nets\n",
    "for j in range(nets):\n",
    "    feature_extractor_model =  models[j]['model'].to(device)\n",
    "    classifier = ClassificationHead(input_size=models[j]['output_shape'], n_classes=config_dict['num_classes']).to(device)\n",
    "    regressor = RegressionHead(input_size=models[j]['output_shape']).to(device)\n",
    "    model = Model(feature_extractor_model, classifier, regressor).to(device)\n",
    "    \n",
    "    optimizer = torch.optim.Adam(lr=config_dict['learning_rate'], params=models[j]['model'].parameters(), weight_decay=config_dict['weight_decay'])\n",
    "\n",
    "    trained_models[j] =  train(\n",
    "        model,\n",
    "        optimizer,\n",
    "        train_data,\n",
    "        eval_datasets=[('val', test_data)],\n",
    "        loss_fn=loss_fn,\n",
    "        metrics={\n",
    "            'bbox': [('iou', iou)],\n",
    "            'class_id': [('accuracy', accuracy)]\n",
    "        },\n",
    "        callbacks=[printer],\n",
    "        device=device,\n",
    "        train_steps=30,\n",
    "        eval_steps=1,\n",
    "        alpha=0.5\n",
    "    ) "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "19f0bd97",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d09d30d7",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d5daa7e4",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.10"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": true,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": true,
   "toc_position": {
    "height": "calc(100% - 180px)",
    "left": "10px",
    "top": "150px",
    "width": "314.361px"
   },
   "toc_section_display": true,
   "toc_window_display": true
  },
  "varInspector": {
   "cols": {
    "lenName": 16,
    "lenType": 16,
    "lenVar": 40
   },
   "kernels_config": {
    "python": {
     "delete_cmd_postfix": "",
     "delete_cmd_prefix": "del ",
     "library": "var_list.py",
     "varRefreshCmd": "print(var_dic_list())"
    },
    "r": {
     "delete_cmd_postfix": ") ",
     "delete_cmd_prefix": "rm(",
     "library": "var_list.r",
     "varRefreshCmd": "cat(var_dic_list()) "
    }
   },
   "types_to_exclude": [
    "module",
    "function",
    "builtin_function_or_method",
    "instance",
    "_Feature"
   ],
   "window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
